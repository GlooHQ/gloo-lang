/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/

// This file was generated by BAML: do not edit it. Instead, edit the BAML
// files and re-generate this code.
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code
'use client'

import { useCallback, useMemo, useReducer } from 'react';
import type {
  ServerActionType,
  PartialResponse,
  FinalResponse,
  UseLLMOptions,
  UseLLMReturnType,
  StreamingInputProps,
  NonStreamingInputProps,
  NonStreamableServerActionType,
  StreamableServerActionType
} from './types';
import { RecursivePartialNull } from '../types';
import { Image, Audio } from "@boundaryml/baml"
import * as ServerActions from './server';
import { Check, Checked, RecursivePartialNull } from "../types"

import {BigNumbers, BinaryNode, Blah, BlockConstraint, BlockConstraintForParam, BookOrder, ClassOptionalOutput, ClassOptionalOutput2, ClassToRecAlias, ClassWithImage, CompoundBigNumbers, ContactInfo, CustomTaskResult, DummyOutput, DynInputOutput, DynamicClassOne, DynamicClassTwo, DynamicOutput, Earthling, Education, Email, EmailAddress, Event, FakeImage, FlightConfirmation, FooAny, Forest, FormatterTest0, FormatterTest1, FormatterTest2, FormatterTest3, GroceryReceipt, InnerClass, InnerClass2, InputClass, InputClassNested, LinkedList, LinkedListAliasNode, LiteralClassHello, LiteralClassOne, LiteralClassTwo, MalformedConstraints, MalformedConstraints2, Martian, MergeAttrs, NamedArgsSingleClass, Nested, Nested2, NestedBlockConstraint, NestedBlockConstraintForParam, Node, NodeWithAliasIndirection, OptionalListAndMap, OptionalTest_Prop1, OptionalTest_ReturnType, OrderInfo, OriginalA, OriginalB, Person, PhoneNumber, Quantity, RaysData, ReceiptInfo, ReceiptItem, Recipe, Resume, Schema, SearchParams, SomeClassNestedDynamic, StringToClassEntry, TestClassAlias, TestClassNested, TestClassWithEnum, TestOutputClass, Tree, TwoStoriesOneTitle, UnionTest_ReturnType, UniverseQuestion, UniverseQuestionInput, WithReasoning, AliasedEnum, Category, Category2, Category3, Color, DataType, DynEnumOne, DynEnumTwo, EnumInClass, EnumOutput, Hobby, MapKey, NamedArgsSingleEnum, NamedArgsSingleEnumList, OptionalTest_CategoryType, OrderStatus, Tag, TestEnum} from "../types"

// Type guard functions
function isPartialResponse<T>(obj: any): obj is PartialResponse<T> {
  return obj && 'partial' in obj && !('final' in obj);
}

function isFinalResponse<T>(obj: any): obj is FinalResponse<T> {
  return obj && 'final' in obj && !('partial' in obj);
}

/**
 * Type guard to check if options are for streaming mode
 * @template Output The type of the response data
 */
export function isStreamingOptions<Output>(
  options: UseLLMOptions<Output>
): options is StreamingInputProps<Output> {
  return options.stream === true;
}


interface LLMState<TPartial, TFinal> {
  isLoading: boolean;
  isSuccess: boolean;
  error: Error | null;
  data: TFinal | null;
  partialData: TPartial | null;
}

type LLMAction<TPartial, TFinal> =
  | { type: 'START_REQUEST' }
  | { type: 'SET_ERROR'; payload: Error }
  | { type: 'SET_PARTIAL'; payload: TPartial }
  | { type: 'SET_FINAL'; payload: TFinal }
  | { type: 'RESET' };

function llmReducer<TPartial, TFinal>(
  state: LLMState<TPartial, TFinal>,
  action: LLMAction<TPartial, TFinal>
): LLMState<TPartial, TFinal> {
  switch (action.type) {
    case 'START_REQUEST':
      return {
        isLoading: true,
        isSuccess: false,
        error: null,
        data: null,
        partialData: null,
      };
    case 'SET_ERROR':
      return {
        ...state,
        isLoading: false,
        error: action.payload,
      };
    case 'SET_PARTIAL':
      return {
        ...state,
        partialData: action.payload,
      };
    case 'SET_FINAL':
      return {
        ...state,
        isLoading: false,
        isSuccess: true,
        data: action.payload,
      };
    case 'RESET':
      return {
        isLoading: false,
        isSuccess: false,
        error: null,
        data: null,
        partialData: null,
      };
    default:
      return state;
  }
}

/**
 * A React hook for making BAML function calls with support for both streaming and non-streaming modes.
 * Provides a unified interface for handling loading states, errors, and data updates.
 *
 * @template Input The type of the input parameters
 * @template Output The type of the final response data
 *
 * @param serverAction The server action function to execute
 * @param options Configuration options for the hook
 *
 * @returns An object containing the current state of the operation and a mutate function to trigger it
 *
 * @example
 * ```tsx
 * // Non-streaming usage
 * const {
 *   data,           // The final result (Output | null)
 *   isLoading,      // Whether the request is in progress
 *   isSuccess,      // Whether the request completed successfully
 *   error,          // Any error that occurred
 *   mutate         // Function to trigger the request
 * } = useLLM(extractResume, {
 *   onFinal: (response) => console.log('Final:', response.final),
 * });
 *
 * // Streaming usage
 * const {
 *   data,           // The final result (Output | null)
 *   partialData,    // The latest partial result (Partial<Output> | null)
 *   isLoading,      // Whether the request is in progress
 *   isSuccess,      // Whether the request completed successfully
 *   error,          // Any error that occurred
 *   mutate         // Function to trigger the request
 * } = useLLM(extractResume, {
 *   stream: true,
 *   onPartial: (response) => console.log('Partial:', response.partial),
 *   onFinal: (response) => console.log('Final:', response.final),
 * });
 *
 * // Trigger the request
 * await mutate({ text: "Some text to process" });
 * ```
 */
export function useLLM<Output, Input extends unknown[]>(
  action: StreamableServerActionType<Output, Input>,
  options: StreamingInputProps<Output>
): UseLLMReturnType<Output, Input, StreamingInputProps<Output>>;

export function useLLM<Output, Input extends unknown[]>(
  action: NonStreamableServerActionType<Output, Input>,
  options: NonStreamingInputProps<Output>
): UseLLMReturnType<Output, Input, NonStreamingInputProps<Output>>;

export function useLLM<Output, Input extends unknown[]>(
  serverAction: ServerActionType<Output, Input>,
  options: UseLLMOptions<Output> = {},
): UseLLMReturnType<Output, Input, typeof options> {
  const { onFinal, onError, onPartial } = options;
  const isStreaming = isStreamingOptions(options);

  const [state, dispatch] = useReducer(llmReducer<RecursivePartialNull<Output>, Output>, {
    isLoading: false,
    isSuccess: false,
    error: null,
    data: null,
    partialData: null,
  });

  const mutate = useCallback(
    async (...params: Input) => {
      dispatch({ type: 'START_REQUEST' });

      try {
        const response = await serverAction(...params, { stream: true});

        if (isStreaming && response instanceof ReadableStream) {
          const reader = response.getReader();
          const decoder = new TextDecoder();

          try {
            while (true) {
              const { value, done } = await reader.read();

              if (done) break;

              if (value) {
                const chunk = decoder.decode(value, { stream: true }).trim();
                try {
                  const parsed = JSON.parse(chunk);
                  if (isPartialResponse<Output>(parsed) && parsed.partial !== null) {
                    const partialValue = parsed.partial;
                    dispatch({ type: 'SET_PARTIAL', payload: partialValue });
                    onPartial?.(partialValue);
                  } else if (isFinalResponse<Output>(parsed)) {
                    const finalValue = parsed.final;
                    dispatch({ type: 'SET_FINAL', payload: finalValue });
                    onFinal?.(finalValue);
                    return finalValue;
                  }
                } catch (err) {
                  // If JSON parsing fails, treat the chunk as a raw string partial update
                  dispatch({ type: 'SET_PARTIAL', payload: chunk});
                  onPartial?.(chunk);
                }
              }
            }
          } catch (err) {
            throw err instanceof Error ? err : new Error(String(err));
          } finally {
            reader.releaseLock();
          }
          return response;
        }

        // Non-streaming case
        dispatch({ type: 'SET_FINAL', payload: response });
        onFinal?.(response);
        return response;
      } catch (error_) {
        const error = error_ instanceof Error ? error_ : new Error(String(error_));
        dispatch({ type: 'SET_ERROR', payload: error });
        onError?.(error);
        return null;
      }
    },
    [serverAction, isStreaming, onPartial, onFinal, onError],
  );

  const status = useMemo<"idle" | "loading" | "success" | "error">(() => {
    if (state.isLoading) return "loading";
    if (state.error) return "error";
    if (state.isSuccess) return "success";
    return "idle";
  }, [state.isLoading, state.error, state.isSuccess]);

  const result = {
    data: state.data,
    error: state.error,
    isError: state.error !== null,
    isLoading: state.isLoading,
    isSuccess: state.isSuccess,
    mutate,
    status,
  };

  return {
    ...result,
    partialData: isStreaming ? state.partialData : undefined,
  }
}
/**
 * A specialized hook for the AaaSamOutputFormat BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - recipe: string
 *
 *
 * Return Type:
 * - Non-streaming: Recipe
 * - Streaming Partial: RecursivePartialNull<Recipe>
 * - Streaming Final: Recipe
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useAaaSamOutputFormat();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Recipe
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Recipe | null
 *   partialData, // Type: RecursivePartialNull<Recipe> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useAaaSamOutputFormat({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Recipe>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Recipe>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       recipe: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       recipe: firstValue as string,
 *     }),
 *     mutate({
 *       recipe: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useAaaSamOutputFormat(
    options?: StreamingInputProps<Recipe>
): UseLLMReturnType<
    Recipe,
    [
        recipe: string
    ],
    StreamingInputProps<Recipe>
>;

export function useAaaSamOutputFormat(
    options?: NonStreamingInputProps<Recipe>
): UseLLMReturnType<
    Recipe,
    [
        recipe: string
    ],
    NonStreamingInputProps<Recipe>
>;

export function useAaaSamOutputFormat(
    options: UseLLMOptions<Recipe> = {}
): UseLLMReturnType<
    Recipe,
    [
        recipe: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Recipe, [
        recipe: string
      ]>(ServerActions.AaaSamOutputFormatAction, options);
    }

    return useLLM<Recipe, [
        recipe: string
    ]>(ServerActions.AaaSamOutputFormatAction, options);
}

/**
 * A specialized hook for the AliasThatPointsToRecursiveType BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - list: LinkedListAliasNode
 *
 *
 * Return Type:
 * - Non-streaming: LinkedListAliasNode
 * - Streaming Partial: RecursivePartialNull<LinkedListAliasNode>
 * - Streaming Final: LinkedListAliasNode
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useAliasThatPointsToRecursiveType();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to LinkedListAliasNode
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: LinkedListAliasNode | null
 *   partialData, // Type: RecursivePartialNull<LinkedListAliasNode> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useAliasThatPointsToRecursiveType({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<LinkedListAliasNode>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<LinkedListAliasNode>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       list: someValue as LinkedListAliasNode,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       list: firstValue as LinkedListAliasNode,
 *     }),
 *     mutate({
 *       list: secondValue as LinkedListAliasNode,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useAliasThatPointsToRecursiveType(
    options?: StreamingInputProps<LinkedListAliasNode>
): UseLLMReturnType<
    LinkedListAliasNode,
    [
        list: LinkedListAliasNode
    ],
    StreamingInputProps<LinkedListAliasNode>
>;

export function useAliasThatPointsToRecursiveType(
    options?: NonStreamingInputProps<LinkedListAliasNode>
): UseLLMReturnType<
    LinkedListAliasNode,
    [
        list: LinkedListAliasNode
    ],
    NonStreamingInputProps<LinkedListAliasNode>
>;

export function useAliasThatPointsToRecursiveType(
    options: UseLLMOptions<LinkedListAliasNode> = {}
): UseLLMReturnType<
    LinkedListAliasNode,
    [
        list: LinkedListAliasNode
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<LinkedListAliasNode, [
        list: LinkedListAliasNode
      ]>(ServerActions.AliasThatPointsToRecursiveTypeAction, options);
    }

    return useLLM<LinkedListAliasNode, [
        list: LinkedListAliasNode
    ]>(ServerActions.AliasThatPointsToRecursiveTypeAction, options);
}

/**
 * A specialized hook for the AliasWithMultipleAttrs BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - money: Checked<number,"gt_ten">
 *
 *
 * Return Type:
 * - Non-streaming: Checked<number,"gt_ten">
 * - Streaming Partial: RecursivePartialNull<Checked<number,"gt_ten">>
 * - Streaming Final: Checked<number,"gt_ten">
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useAliasWithMultipleAttrs();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Checked<number,"gt_ten">
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Checked<number,"gt_ten"> | null
 *   partialData, // Type: RecursivePartialNull<Checked<number,"gt_ten">> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useAliasWithMultipleAttrs({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Checked<number,"gt_ten">>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Checked<number,"gt_ten">>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       money: someValue as Checked<number,"gt_ten">,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       money: firstValue as Checked<number,"gt_ten">,
 *     }),
 *     mutate({
 *       money: secondValue as Checked<number,"gt_ten">,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useAliasWithMultipleAttrs(
    options?: StreamingInputProps<Checked<number,"gt_ten">>
): UseLLMReturnType<
    Checked<number,"gt_ten">,
    [
        money: Checked<number,"gt_ten">
    ],
    StreamingInputProps<Checked<number,"gt_ten">>
>;

export function useAliasWithMultipleAttrs(
    options?: NonStreamingInputProps<Checked<number,"gt_ten">>
): UseLLMReturnType<
    Checked<number,"gt_ten">,
    [
        money: Checked<number,"gt_ten">
    ],
    NonStreamingInputProps<Checked<number,"gt_ten">>
>;

export function useAliasWithMultipleAttrs(
    options: UseLLMOptions<Checked<number,"gt_ten">> = {}
): UseLLMReturnType<
    Checked<number,"gt_ten">,
    [
        money: Checked<number,"gt_ten">
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Checked<number,"gt_ten">, [
        money: Checked<number,"gt_ten">
      ]>(ServerActions.AliasWithMultipleAttrsAction, options);
    }

    return useLLM<Checked<number,"gt_ten">, [
        money: Checked<number,"gt_ten">
    ]>(ServerActions.AliasWithMultipleAttrsAction, options);
}

/**
 * A specialized hook for the AliasedInputClass BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: InputClass
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useAliasedInputClass();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useAliasedInputClass({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as InputClass,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as InputClass,
 *     }),
 *     mutate({
 *       input: secondValue as InputClass,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useAliasedInputClass(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: InputClass
    ],
    StreamingInputProps<string>
>;

export function useAliasedInputClass(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: InputClass
    ],
    NonStreamingInputProps<string>
>;

export function useAliasedInputClass(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: InputClass
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: InputClass
      ]>(ServerActions.AliasedInputClassAction, options);
    }

    return useLLM<string, [
        input: InputClass
    ]>(ServerActions.AliasedInputClassAction, options);
}

/**
 * A specialized hook for the AliasedInputClass2 BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: InputClass
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useAliasedInputClass2();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useAliasedInputClass2({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as InputClass,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as InputClass,
 *     }),
 *     mutate({
 *       input: secondValue as InputClass,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useAliasedInputClass2(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: InputClass
    ],
    StreamingInputProps<string>
>;

export function useAliasedInputClass2(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: InputClass
    ],
    NonStreamingInputProps<string>
>;

export function useAliasedInputClass2(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: InputClass
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: InputClass
      ]>(ServerActions.AliasedInputClass2Action, options);
    }

    return useLLM<string, [
        input: InputClass
    ]>(ServerActions.AliasedInputClass2Action, options);
}

/**
 * A specialized hook for the AliasedInputClassNested BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: InputClassNested
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useAliasedInputClassNested();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useAliasedInputClassNested({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as InputClassNested,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as InputClassNested,
 *     }),
 *     mutate({
 *       input: secondValue as InputClassNested,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useAliasedInputClassNested(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: InputClassNested
    ],
    StreamingInputProps<string>
>;

export function useAliasedInputClassNested(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: InputClassNested
    ],
    NonStreamingInputProps<string>
>;

export function useAliasedInputClassNested(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: InputClassNested
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: InputClassNested
      ]>(ServerActions.AliasedInputClassNestedAction, options);
    }

    return useLLM<string, [
        input: InputClassNested
    ]>(ServerActions.AliasedInputClassNestedAction, options);
}

/**
 * A specialized hook for the AliasedInputEnum BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: AliasedEnum
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useAliasedInputEnum();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useAliasedInputEnum({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as AliasedEnum,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as AliasedEnum,
 *     }),
 *     mutate({
 *       input: secondValue as AliasedEnum,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useAliasedInputEnum(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: AliasedEnum
    ],
    StreamingInputProps<string>
>;

export function useAliasedInputEnum(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: AliasedEnum
    ],
    NonStreamingInputProps<string>
>;

export function useAliasedInputEnum(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: AliasedEnum
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: AliasedEnum
      ]>(ServerActions.AliasedInputEnumAction, options);
    }

    return useLLM<string, [
        input: AliasedEnum
    ]>(ServerActions.AliasedInputEnumAction, options);
}

/**
 * A specialized hook for the AliasedInputList BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: AliasedEnum[]
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useAliasedInputList();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useAliasedInputList({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as AliasedEnum[],  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as AliasedEnum[],
 *     }),
 *     mutate({
 *       input: secondValue as AliasedEnum[],
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useAliasedInputList(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: AliasedEnum[]
    ],
    StreamingInputProps<string>
>;

export function useAliasedInputList(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: AliasedEnum[]
    ],
    NonStreamingInputProps<string>
>;

export function useAliasedInputList(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: AliasedEnum[]
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: AliasedEnum[]
      ]>(ServerActions.AliasedInputListAction, options);
    }

    return useLLM<string, [
        input: AliasedEnum[]
    ]>(ServerActions.AliasedInputListAction, options);
}

/**
 * A specialized hook for the AllowedOptionals BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - optionals: OptionalListAndMap
 *
 *
 * Return Type:
 * - Non-streaming: OptionalListAndMap
 * - Streaming Partial: RecursivePartialNull<OptionalListAndMap>
 * - Streaming Final: OptionalListAndMap
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useAllowedOptionals();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to OptionalListAndMap
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: OptionalListAndMap | null
 *   partialData, // Type: RecursivePartialNull<OptionalListAndMap> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useAllowedOptionals({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<OptionalListAndMap>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<OptionalListAndMap>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       optionals: someValue as OptionalListAndMap,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       optionals: firstValue as OptionalListAndMap,
 *     }),
 *     mutate({
 *       optionals: secondValue as OptionalListAndMap,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useAllowedOptionals(
    options?: StreamingInputProps<OptionalListAndMap>
): UseLLMReturnType<
    OptionalListAndMap,
    [
        optionals: OptionalListAndMap
    ],
    StreamingInputProps<OptionalListAndMap>
>;

export function useAllowedOptionals(
    options?: NonStreamingInputProps<OptionalListAndMap>
): UseLLMReturnType<
    OptionalListAndMap,
    [
        optionals: OptionalListAndMap
    ],
    NonStreamingInputProps<OptionalListAndMap>
>;

export function useAllowedOptionals(
    options: UseLLMOptions<OptionalListAndMap> = {}
): UseLLMReturnType<
    OptionalListAndMap,
    [
        optionals: OptionalListAndMap
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<OptionalListAndMap, [
        optionals: OptionalListAndMap
      ]>(ServerActions.AllowedOptionalsAction, options);
    }

    return useLLM<OptionalListAndMap, [
        optionals: OptionalListAndMap
    ]>(ServerActions.AllowedOptionalsAction, options);
}

/**
 * A specialized hook for the AudioInput BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - aud: Audio
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useAudioInput();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useAudioInput({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       aud: someValue as Audio,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       aud: firstValue as Audio,
 *     }),
 *     mutate({
 *       aud: secondValue as Audio,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useAudioInput(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        aud: Audio
    ],
    StreamingInputProps<string>
>;

export function useAudioInput(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        aud: Audio
    ],
    NonStreamingInputProps<string>
>;

export function useAudioInput(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        aud: Audio
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        aud: Audio
      ]>(ServerActions.AudioInputAction, options);
    }

    return useLLM<string, [
        aud: Audio
    ]>(ServerActions.AudioInputAction, options);
}

/**
 * A specialized hook for the BuildLinkedList BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: number[]
 *
 *
 * Return Type:
 * - Non-streaming: LinkedList
 * - Streaming Partial: RecursivePartialNull<LinkedList>
 * - Streaming Final: LinkedList
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useBuildLinkedList();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to LinkedList
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: LinkedList | null
 *   partialData, // Type: RecursivePartialNull<LinkedList> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useBuildLinkedList({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<LinkedList>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<LinkedList>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as number[],  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as number[],
 *     }),
 *     mutate({
 *       input: secondValue as number[],
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useBuildLinkedList(
    options?: StreamingInputProps<LinkedList>
): UseLLMReturnType<
    LinkedList,
    [
        input: number[]
    ],
    StreamingInputProps<LinkedList>
>;

export function useBuildLinkedList(
    options?: NonStreamingInputProps<LinkedList>
): UseLLMReturnType<
    LinkedList,
    [
        input: number[]
    ],
    NonStreamingInputProps<LinkedList>
>;

export function useBuildLinkedList(
    options: UseLLMOptions<LinkedList> = {}
): UseLLMReturnType<
    LinkedList,
    [
        input: number[]
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<LinkedList, [
        input: number[]
      ]>(ServerActions.BuildLinkedListAction, options);
    }

    return useLLM<LinkedList, [
        input: number[]
    ]>(ServerActions.BuildLinkedListAction, options);
}

/**
 * A specialized hook for the BuildTree BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: BinaryNode
 *
 *
 * Return Type:
 * - Non-streaming: Tree
 * - Streaming Partial: RecursivePartialNull<Tree>
 * - Streaming Final: Tree
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useBuildTree();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Tree
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Tree | null
 *   partialData, // Type: RecursivePartialNull<Tree> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useBuildTree({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Tree>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Tree>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as BinaryNode,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as BinaryNode,
 *     }),
 *     mutate({
 *       input: secondValue as BinaryNode,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useBuildTree(
    options?: StreamingInputProps<Tree>
): UseLLMReturnType<
    Tree,
    [
        input: BinaryNode
    ],
    StreamingInputProps<Tree>
>;

export function useBuildTree(
    options?: NonStreamingInputProps<Tree>
): UseLLMReturnType<
    Tree,
    [
        input: BinaryNode
    ],
    NonStreamingInputProps<Tree>
>;

export function useBuildTree(
    options: UseLLMOptions<Tree> = {}
): UseLLMReturnType<
    Tree,
    [
        input: BinaryNode
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Tree, [
        input: BinaryNode
      ]>(ServerActions.BuildTreeAction, options);
    }

    return useLLM<Tree, [
        input: BinaryNode
    ]>(ServerActions.BuildTreeAction, options);
}

/**
 * A specialized hook for the ClassThatPointsToRecursiveClassThroughAlias BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - cls: ClassToRecAlias
 *
 *
 * Return Type:
 * - Non-streaming: ClassToRecAlias
 * - Streaming Partial: RecursivePartialNull<ClassToRecAlias>
 * - Streaming Final: ClassToRecAlias
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useClassThatPointsToRecursiveClassThroughAlias();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to ClassToRecAlias
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: ClassToRecAlias | null
 *   partialData, // Type: RecursivePartialNull<ClassToRecAlias> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useClassThatPointsToRecursiveClassThroughAlias({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<ClassToRecAlias>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<ClassToRecAlias>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       cls: someValue as ClassToRecAlias,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       cls: firstValue as ClassToRecAlias,
 *     }),
 *     mutate({
 *       cls: secondValue as ClassToRecAlias,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useClassThatPointsToRecursiveClassThroughAlias(
    options?: StreamingInputProps<ClassToRecAlias>
): UseLLMReturnType<
    ClassToRecAlias,
    [
        cls: ClassToRecAlias
    ],
    StreamingInputProps<ClassToRecAlias>
>;

export function useClassThatPointsToRecursiveClassThroughAlias(
    options?: NonStreamingInputProps<ClassToRecAlias>
): UseLLMReturnType<
    ClassToRecAlias,
    [
        cls: ClassToRecAlias
    ],
    NonStreamingInputProps<ClassToRecAlias>
>;

export function useClassThatPointsToRecursiveClassThroughAlias(
    options: UseLLMOptions<ClassToRecAlias> = {}
): UseLLMReturnType<
    ClassToRecAlias,
    [
        cls: ClassToRecAlias
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<ClassToRecAlias, [
        cls: ClassToRecAlias
      ]>(ServerActions.ClassThatPointsToRecursiveClassThroughAliasAction, options);
    }

    return useLLM<ClassToRecAlias, [
        cls: ClassToRecAlias
    ]>(ServerActions.ClassThatPointsToRecursiveClassThroughAliasAction, options);
}

/**
 * A specialized hook for the ClassifyDynEnumTwo BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: (string | DynEnumTwo)
 * - Streaming Partial: RecursivePartialNull<(string | DynEnumTwo)>
 * - Streaming Final: (string | DynEnumTwo)
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useClassifyDynEnumTwo();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to (string | DynEnumTwo)
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: (string | DynEnumTwo) | null
 *   partialData, // Type: RecursivePartialNull<(string | DynEnumTwo)> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useClassifyDynEnumTwo({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<(string | DynEnumTwo)>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<(string | DynEnumTwo)>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useClassifyDynEnumTwo(
    options?: StreamingInputProps<(string | DynEnumTwo)>
): UseLLMReturnType<
    (string | DynEnumTwo),
    [
        input: string
    ],
    StreamingInputProps<(string | DynEnumTwo)>
>;

export function useClassifyDynEnumTwo(
    options?: NonStreamingInputProps<(string | DynEnumTwo)>
): UseLLMReturnType<
    (string | DynEnumTwo),
    [
        input: string
    ],
    NonStreamingInputProps<(string | DynEnumTwo)>
>;

export function useClassifyDynEnumTwo(
    options: UseLLMOptions<(string | DynEnumTwo)> = {}
): UseLLMReturnType<
    (string | DynEnumTwo),
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<(string | DynEnumTwo), [
        input: string
      ]>(ServerActions.ClassifyDynEnumTwoAction, options);
    }

    return useLLM<(string | DynEnumTwo), [
        input: string
    ]>(ServerActions.ClassifyDynEnumTwoAction, options);
}

/**
 * A specialized hook for the ClassifyMessage BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: Category
 * - Streaming Partial: RecursivePartialNull<Category>
 * - Streaming Final: Category
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useClassifyMessage();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Category
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Category | null
 *   partialData, // Type: RecursivePartialNull<Category> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useClassifyMessage({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Category>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Category>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useClassifyMessage(
    options?: StreamingInputProps<Category>
): UseLLMReturnType<
    Category,
    [
        input: string
    ],
    StreamingInputProps<Category>
>;

export function useClassifyMessage(
    options?: NonStreamingInputProps<Category>
): UseLLMReturnType<
    Category,
    [
        input: string
    ],
    NonStreamingInputProps<Category>
>;

export function useClassifyMessage(
    options: UseLLMOptions<Category> = {}
): UseLLMReturnType<
    Category,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Category, [
        input: string
      ]>(ServerActions.ClassifyMessageAction, options);
    }

    return useLLM<Category, [
        input: string
    ]>(ServerActions.ClassifyMessageAction, options);
}

/**
 * A specialized hook for the ClassifyMessage2 BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: Category
 * - Streaming Partial: RecursivePartialNull<Category>
 * - Streaming Final: Category
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useClassifyMessage2();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Category
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Category | null
 *   partialData, // Type: RecursivePartialNull<Category> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useClassifyMessage2({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Category>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Category>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useClassifyMessage2(
    options?: StreamingInputProps<Category>
): UseLLMReturnType<
    Category,
    [
        input: string
    ],
    StreamingInputProps<Category>
>;

export function useClassifyMessage2(
    options?: NonStreamingInputProps<Category>
): UseLLMReturnType<
    Category,
    [
        input: string
    ],
    NonStreamingInputProps<Category>
>;

export function useClassifyMessage2(
    options: UseLLMOptions<Category> = {}
): UseLLMReturnType<
    Category,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Category, [
        input: string
      ]>(ServerActions.ClassifyMessage2Action, options);
    }

    return useLLM<Category, [
        input: string
    ]>(ServerActions.ClassifyMessage2Action, options);
}

/**
 * A specialized hook for the ClassifyMessage3 BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: Category
 * - Streaming Partial: RecursivePartialNull<Category>
 * - Streaming Final: Category
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useClassifyMessage3();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Category
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Category | null
 *   partialData, // Type: RecursivePartialNull<Category> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useClassifyMessage3({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Category>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Category>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useClassifyMessage3(
    options?: StreamingInputProps<Category>
): UseLLMReturnType<
    Category,
    [
        input: string
    ],
    StreamingInputProps<Category>
>;

export function useClassifyMessage3(
    options?: NonStreamingInputProps<Category>
): UseLLMReturnType<
    Category,
    [
        input: string
    ],
    NonStreamingInputProps<Category>
>;

export function useClassifyMessage3(
    options: UseLLMOptions<Category> = {}
): UseLLMReturnType<
    Category,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Category, [
        input: string
      ]>(ServerActions.ClassifyMessage3Action, options);
    }

    return useLLM<Category, [
        input: string
    ]>(ServerActions.ClassifyMessage3Action, options);
}

/**
 * A specialized hook for the Completion BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - prefix: string
 *
 * - suffix: string
 *
 * - language: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useCompletion();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useCompletion({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       prefix: someValue as string,  // Replace someValue with your data
 *       suffix: someValue as string,  // Replace someValue with your data
 *       language: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       prefix: firstValue as string,
 *       suffix: firstValue as string,
 *       language: firstValue as string,
 *     }),
 *     mutate({
 *       prefix: secondValue as string,
 *       suffix: secondValue as string,
 *       language: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useCompletion(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        prefix: string,
        suffix: string,
        language: string
    ],
    StreamingInputProps<string>
>;

export function useCompletion(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        prefix: string,
        suffix: string,
        language: string
    ],
    NonStreamingInputProps<string>
>;

export function useCompletion(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        prefix: string,
        suffix: string,
        language: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        prefix: string,
        suffix: string,
        language: string
      ]>(ServerActions.CompletionAction, options);
    }

    return useLLM<string, [
        prefix: string,
        suffix: string,
        language: string
    ]>(ServerActions.CompletionAction, options);
}

/**
 * A specialized hook for the CustomTask BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: BookOrder | FlightConfirmation | GroceryReceipt
 * - Streaming Partial: RecursivePartialNull<BookOrder | FlightConfirmation | GroceryReceipt>
 * - Streaming Final: BookOrder | FlightConfirmation | GroceryReceipt
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useCustomTask();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to BookOrder | FlightConfirmation | GroceryReceipt
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: BookOrder | FlightConfirmation | GroceryReceipt | null
 *   partialData, // Type: RecursivePartialNull<BookOrder | FlightConfirmation | GroceryReceipt> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useCustomTask({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<BookOrder | FlightConfirmation | GroceryReceipt>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<BookOrder | FlightConfirmation | GroceryReceipt>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useCustomTask(
    options?: StreamingInputProps<BookOrder | FlightConfirmation | GroceryReceipt>
): UseLLMReturnType<
    BookOrder | FlightConfirmation | GroceryReceipt,
    [
        input: string
    ],
    StreamingInputProps<BookOrder | FlightConfirmation | GroceryReceipt>
>;

export function useCustomTask(
    options?: NonStreamingInputProps<BookOrder | FlightConfirmation | GroceryReceipt>
): UseLLMReturnType<
    BookOrder | FlightConfirmation | GroceryReceipt,
    [
        input: string
    ],
    NonStreamingInputProps<BookOrder | FlightConfirmation | GroceryReceipt>
>;

export function useCustomTask(
    options: UseLLMOptions<BookOrder | FlightConfirmation | GroceryReceipt> = {}
): UseLLMReturnType<
    BookOrder | FlightConfirmation | GroceryReceipt,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<BookOrder | FlightConfirmation | GroceryReceipt, [
        input: string
      ]>(ServerActions.CustomTaskAction, options);
    }

    return useLLM<BookOrder | FlightConfirmation | GroceryReceipt, [
        input: string
    ]>(ServerActions.CustomTaskAction, options);
}

/**
 * A specialized hook for the DescribeImage BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - img: Image
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useDescribeImage();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useDescribeImage({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       img: someValue as Image,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       img: firstValue as Image,
 *     }),
 *     mutate({
 *       img: secondValue as Image,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useDescribeImage(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        img: Image
    ],
    StreamingInputProps<string>
>;

export function useDescribeImage(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        img: Image
    ],
    NonStreamingInputProps<string>
>;

export function useDescribeImage(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        img: Image
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        img: Image
      ]>(ServerActions.DescribeImageAction, options);
    }

    return useLLM<string, [
        img: Image
    ]>(ServerActions.DescribeImageAction, options);
}

/**
 * A specialized hook for the DescribeImage2 BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - classWithImage: ClassWithImage
 *
 * - img2: Image
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useDescribeImage2();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useDescribeImage2({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       classWithImage: someValue as ClassWithImage,  // Replace someValue with your data
 *       img2: someValue as Image,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       classWithImage: firstValue as ClassWithImage,
 *       img2: firstValue as Image,
 *     }),
 *     mutate({
 *       classWithImage: secondValue as ClassWithImage,
 *       img2: secondValue as Image,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useDescribeImage2(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        classWithImage: ClassWithImage,
        img2: Image
    ],
    StreamingInputProps<string>
>;

export function useDescribeImage2(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        classWithImage: ClassWithImage,
        img2: Image
    ],
    NonStreamingInputProps<string>
>;

export function useDescribeImage2(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        classWithImage: ClassWithImage,
        img2: Image
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        classWithImage: ClassWithImage,
        img2: Image
      ]>(ServerActions.DescribeImage2Action, options);
    }

    return useLLM<string, [
        classWithImage: ClassWithImage,
        img2: Image
    ]>(ServerActions.DescribeImage2Action, options);
}

/**
 * A specialized hook for the DescribeImage3 BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - classWithImage: ClassWithImage
 *
 * - img2: Image
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useDescribeImage3();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useDescribeImage3({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       classWithImage: someValue as ClassWithImage,  // Replace someValue with your data
 *       img2: someValue as Image,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       classWithImage: firstValue as ClassWithImage,
 *       img2: firstValue as Image,
 *     }),
 *     mutate({
 *       classWithImage: secondValue as ClassWithImage,
 *       img2: secondValue as Image,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useDescribeImage3(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        classWithImage: ClassWithImage,
        img2: Image
    ],
    StreamingInputProps<string>
>;

export function useDescribeImage3(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        classWithImage: ClassWithImage,
        img2: Image
    ],
    NonStreamingInputProps<string>
>;

export function useDescribeImage3(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        classWithImage: ClassWithImage,
        img2: Image
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        classWithImage: ClassWithImage,
        img2: Image
      ]>(ServerActions.DescribeImage3Action, options);
    }

    return useLLM<string, [
        classWithImage: ClassWithImage,
        img2: Image
    ]>(ServerActions.DescribeImage3Action, options);
}

/**
 * A specialized hook for the DescribeImage4 BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - classWithImage: ClassWithImage
 *
 * - img2: Image
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useDescribeImage4();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useDescribeImage4({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       classWithImage: someValue as ClassWithImage,  // Replace someValue with your data
 *       img2: someValue as Image,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       classWithImage: firstValue as ClassWithImage,
 *       img2: firstValue as Image,
 *     }),
 *     mutate({
 *       classWithImage: secondValue as ClassWithImage,
 *       img2: secondValue as Image,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useDescribeImage4(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        classWithImage: ClassWithImage,
        img2: Image
    ],
    StreamingInputProps<string>
>;

export function useDescribeImage4(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        classWithImage: ClassWithImage,
        img2: Image
    ],
    NonStreamingInputProps<string>
>;

export function useDescribeImage4(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        classWithImage: ClassWithImage,
        img2: Image
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        classWithImage: ClassWithImage,
        img2: Image
      ]>(ServerActions.DescribeImage4Action, options);
    }

    return useLLM<string, [
        classWithImage: ClassWithImage,
        img2: Image
    ]>(ServerActions.DescribeImage4Action, options);
}

/**
 * A specialized hook for the DifferentiateUnions BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 *
 * Return Type:
 * - Non-streaming: OriginalA | OriginalB
 * - Streaming Partial: RecursivePartialNull<OriginalA | OriginalB>
 * - Streaming Final: OriginalA | OriginalB
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useDifferentiateUnions();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to OriginalA | OriginalB
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: OriginalA | OriginalB | null
 *   partialData, // Type: RecursivePartialNull<OriginalA | OriginalB> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useDifferentiateUnions({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<OriginalA | OriginalB>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<OriginalA | OriginalB>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *     }),
 *     mutate({
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useDifferentiateUnions(
    options?: StreamingInputProps<OriginalA | OriginalB>
): UseLLMReturnType<
    OriginalA | OriginalB,
    [
    ],
    StreamingInputProps<OriginalA | OriginalB>
>;

export function useDifferentiateUnions(
    options?: NonStreamingInputProps<OriginalA | OriginalB>
): UseLLMReturnType<
    OriginalA | OriginalB,
    [
    ],
    NonStreamingInputProps<OriginalA | OriginalB>
>;

export function useDifferentiateUnions(
    options: UseLLMOptions<OriginalA | OriginalB> = {}
): UseLLMReturnType<
    OriginalA | OriginalB,
    [
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<OriginalA | OriginalB, [
      ]>(ServerActions.DifferentiateUnionsAction, options);
    }

    return useLLM<OriginalA | OriginalB, [
    ]>(ServerActions.DifferentiateUnionsAction, options);
}

/**
 * A specialized hook for the DummyOutputFunction BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: DummyOutput
 * - Streaming Partial: RecursivePartialNull<DummyOutput>
 * - Streaming Final: DummyOutput
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useDummyOutputFunction();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to DummyOutput
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: DummyOutput | null
 *   partialData, // Type: RecursivePartialNull<DummyOutput> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useDummyOutputFunction({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<DummyOutput>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<DummyOutput>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useDummyOutputFunction(
    options?: StreamingInputProps<DummyOutput>
): UseLLMReturnType<
    DummyOutput,
    [
        input: string
    ],
    StreamingInputProps<DummyOutput>
>;

export function useDummyOutputFunction(
    options?: NonStreamingInputProps<DummyOutput>
): UseLLMReturnType<
    DummyOutput,
    [
        input: string
    ],
    NonStreamingInputProps<DummyOutput>
>;

export function useDummyOutputFunction(
    options: UseLLMOptions<DummyOutput> = {}
): UseLLMReturnType<
    DummyOutput,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<DummyOutput, [
        input: string
      ]>(ServerActions.DummyOutputFunctionAction, options);
    }

    return useLLM<DummyOutput, [
        input: string
    ]>(ServerActions.DummyOutputFunctionAction, options);
}

/**
 * A specialized hook for the DynamicFunc BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: DynamicClassOne
 *
 *
 * Return Type:
 * - Non-streaming: DynamicClassTwo
 * - Streaming Partial: RecursivePartialNull<DynamicClassTwo>
 * - Streaming Final: DynamicClassTwo
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useDynamicFunc();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to DynamicClassTwo
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: DynamicClassTwo | null
 *   partialData, // Type: RecursivePartialNull<DynamicClassTwo> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useDynamicFunc({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<DynamicClassTwo>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<DynamicClassTwo>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as DynamicClassOne,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as DynamicClassOne,
 *     }),
 *     mutate({
 *       input: secondValue as DynamicClassOne,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useDynamicFunc(
    options?: StreamingInputProps<DynamicClassTwo>
): UseLLMReturnType<
    DynamicClassTwo,
    [
        input: DynamicClassOne
    ],
    StreamingInputProps<DynamicClassTwo>
>;

export function useDynamicFunc(
    options?: NonStreamingInputProps<DynamicClassTwo>
): UseLLMReturnType<
    DynamicClassTwo,
    [
        input: DynamicClassOne
    ],
    NonStreamingInputProps<DynamicClassTwo>
>;

export function useDynamicFunc(
    options: UseLLMOptions<DynamicClassTwo> = {}
): UseLLMReturnType<
    DynamicClassTwo,
    [
        input: DynamicClassOne
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<DynamicClassTwo, [
        input: DynamicClassOne
      ]>(ServerActions.DynamicFuncAction, options);
    }

    return useLLM<DynamicClassTwo, [
        input: DynamicClassOne
    ]>(ServerActions.DynamicFuncAction, options);
}

/**
 * A specialized hook for the DynamicInputOutput BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: DynInputOutput
 *
 *
 * Return Type:
 * - Non-streaming: DynInputOutput
 * - Streaming Partial: RecursivePartialNull<DynInputOutput>
 * - Streaming Final: DynInputOutput
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useDynamicInputOutput();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to DynInputOutput
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: DynInputOutput | null
 *   partialData, // Type: RecursivePartialNull<DynInputOutput> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useDynamicInputOutput({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<DynInputOutput>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<DynInputOutput>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as DynInputOutput,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as DynInputOutput,
 *     }),
 *     mutate({
 *       input: secondValue as DynInputOutput,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useDynamicInputOutput(
    options?: StreamingInputProps<DynInputOutput>
): UseLLMReturnType<
    DynInputOutput,
    [
        input: DynInputOutput
    ],
    StreamingInputProps<DynInputOutput>
>;

export function useDynamicInputOutput(
    options?: NonStreamingInputProps<DynInputOutput>
): UseLLMReturnType<
    DynInputOutput,
    [
        input: DynInputOutput
    ],
    NonStreamingInputProps<DynInputOutput>
>;

export function useDynamicInputOutput(
    options: UseLLMOptions<DynInputOutput> = {}
): UseLLMReturnType<
    DynInputOutput,
    [
        input: DynInputOutput
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<DynInputOutput, [
        input: DynInputOutput
      ]>(ServerActions.DynamicInputOutputAction, options);
    }

    return useLLM<DynInputOutput, [
        input: DynInputOutput
    ]>(ServerActions.DynamicInputOutputAction, options);
}

/**
 * A specialized hook for the DynamicListInputOutput BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: DynInputOutput[]
 *
 *
 * Return Type:
 * - Non-streaming: DynInputOutput[]
 * - Streaming Partial: RecursivePartialNull<DynInputOutput[]>
 * - Streaming Final: DynInputOutput[]
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useDynamicListInputOutput();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to DynInputOutput[]
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: DynInputOutput[] | null
 *   partialData, // Type: RecursivePartialNull<DynInputOutput[]> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useDynamicListInputOutput({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<DynInputOutput[]>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<DynInputOutput[]>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as DynInputOutput[],  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as DynInputOutput[],
 *     }),
 *     mutate({
 *       input: secondValue as DynInputOutput[],
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useDynamicListInputOutput(
    options?: StreamingInputProps<DynInputOutput[]>
): UseLLMReturnType<
    DynInputOutput[],
    [
        input: DynInputOutput[]
    ],
    StreamingInputProps<DynInputOutput[]>
>;

export function useDynamicListInputOutput(
    options?: NonStreamingInputProps<DynInputOutput[]>
): UseLLMReturnType<
    DynInputOutput[],
    [
        input: DynInputOutput[]
    ],
    NonStreamingInputProps<DynInputOutput[]>
>;

export function useDynamicListInputOutput(
    options: UseLLMOptions<DynInputOutput[]> = {}
): UseLLMReturnType<
    DynInputOutput[],
    [
        input: DynInputOutput[]
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<DynInputOutput[], [
        input: DynInputOutput[]
      ]>(ServerActions.DynamicListInputOutputAction, options);
    }

    return useLLM<DynInputOutput[], [
        input: DynInputOutput[]
    ]>(ServerActions.DynamicListInputOutputAction, options);
}

/**
 * A specialized hook for the ExpectFailure BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useExpectFailure();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useExpectFailure({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *     }),
 *     mutate({
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useExpectFailure(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
    ],
    StreamingInputProps<string>
>;

export function useExpectFailure(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
    ],
    NonStreamingInputProps<string>
>;

export function useExpectFailure(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
      ]>(ServerActions.ExpectFailureAction, options);
    }

    return useLLM<string, [
    ]>(ServerActions.ExpectFailureAction, options);
}

/**
 * A specialized hook for the ExtractContactInfo BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - document: string
 *
 *
 * Return Type:
 * - Non-streaming: ContactInfo
 * - Streaming Partial: RecursivePartialNull<ContactInfo>
 * - Streaming Final: ContactInfo
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useExtractContactInfo();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to ContactInfo
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: ContactInfo | null
 *   partialData, // Type: RecursivePartialNull<ContactInfo> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useExtractContactInfo({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<ContactInfo>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<ContactInfo>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       document: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       document: firstValue as string,
 *     }),
 *     mutate({
 *       document: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useExtractContactInfo(
    options?: StreamingInputProps<ContactInfo>
): UseLLMReturnType<
    ContactInfo,
    [
        document: string
    ],
    StreamingInputProps<ContactInfo>
>;

export function useExtractContactInfo(
    options?: NonStreamingInputProps<ContactInfo>
): UseLLMReturnType<
    ContactInfo,
    [
        document: string
    ],
    NonStreamingInputProps<ContactInfo>
>;

export function useExtractContactInfo(
    options: UseLLMOptions<ContactInfo> = {}
): UseLLMReturnType<
    ContactInfo,
    [
        document: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<ContactInfo, [
        document: string
      ]>(ServerActions.ExtractContactInfoAction, options);
    }

    return useLLM<ContactInfo, [
        document: string
    ]>(ServerActions.ExtractContactInfoAction, options);
}

/**
 * A specialized hook for the ExtractHobby BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - text: string
 *
 *
 * Return Type:
 * - Non-streaming: (string | Hobby)[]
 * - Streaming Partial: RecursivePartialNull<(string | Hobby)[]>
 * - Streaming Final: (string | Hobby)[]
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useExtractHobby();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to (string | Hobby)[]
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: (string | Hobby)[] | null
 *   partialData, // Type: RecursivePartialNull<(string | Hobby)[]> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useExtractHobby({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<(string | Hobby)[]>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<(string | Hobby)[]>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       text: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       text: firstValue as string,
 *     }),
 *     mutate({
 *       text: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useExtractHobby(
    options?: StreamingInputProps<(string | Hobby)[]>
): UseLLMReturnType<
    (string | Hobby)[],
    [
        text: string
    ],
    StreamingInputProps<(string | Hobby)[]>
>;

export function useExtractHobby(
    options?: NonStreamingInputProps<(string | Hobby)[]>
): UseLLMReturnType<
    (string | Hobby)[],
    [
        text: string
    ],
    NonStreamingInputProps<(string | Hobby)[]>
>;

export function useExtractHobby(
    options: UseLLMOptions<(string | Hobby)[]> = {}
): UseLLMReturnType<
    (string | Hobby)[],
    [
        text: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<(string | Hobby)[], [
        text: string
      ]>(ServerActions.ExtractHobbyAction, options);
    }

    return useLLM<(string | Hobby)[], [
        text: string
    ]>(ServerActions.ExtractHobbyAction, options);
}

/**
 * A specialized hook for the ExtractNames BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string[]
 * - Streaming Partial: RecursivePartialNull<string[]>
 * - Streaming Final: string[]
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useExtractNames();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string[]
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string[] | null
 *   partialData, // Type: RecursivePartialNull<string[]> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useExtractNames({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string[]>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string[]>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useExtractNames(
    options?: StreamingInputProps<string[]>
): UseLLMReturnType<
    string[],
    [
        input: string
    ],
    StreamingInputProps<string[]>
>;

export function useExtractNames(
    options?: NonStreamingInputProps<string[]>
): UseLLMReturnType<
    string[],
    [
        input: string
    ],
    NonStreamingInputProps<string[]>
>;

export function useExtractNames(
    options: UseLLMOptions<string[]> = {}
): UseLLMReturnType<
    string[],
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string[], [
        input: string
      ]>(ServerActions.ExtractNamesAction, options);
    }

    return useLLM<string[], [
        input: string
    ]>(ServerActions.ExtractNamesAction, options);
}

/**
 * A specialized hook for the ExtractPeople BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - text: string
 *
 *
 * Return Type:
 * - Non-streaming: Person[]
 * - Streaming Partial: RecursivePartialNull<Person[]>
 * - Streaming Final: Person[]
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useExtractPeople();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Person[]
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Person[] | null
 *   partialData, // Type: RecursivePartialNull<Person[]> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useExtractPeople({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Person[]>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Person[]>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       text: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       text: firstValue as string,
 *     }),
 *     mutate({
 *       text: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useExtractPeople(
    options?: StreamingInputProps<Person[]>
): UseLLMReturnType<
    Person[],
    [
        text: string
    ],
    StreamingInputProps<Person[]>
>;

export function useExtractPeople(
    options?: NonStreamingInputProps<Person[]>
): UseLLMReturnType<
    Person[],
    [
        text: string
    ],
    NonStreamingInputProps<Person[]>
>;

export function useExtractPeople(
    options: UseLLMOptions<Person[]> = {}
): UseLLMReturnType<
    Person[],
    [
        text: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Person[], [
        text: string
      ]>(ServerActions.ExtractPeopleAction, options);
    }

    return useLLM<Person[], [
        text: string
    ]>(ServerActions.ExtractPeopleAction, options);
}

/**
 * A specialized hook for the ExtractReceiptInfo BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - email: string
 *
 * - reason: "curiosity" | "personal_finance"
 *
 *
 * Return Type:
 * - Non-streaming: ReceiptInfo
 * - Streaming Partial: RecursivePartialNull<ReceiptInfo>
 * - Streaming Final: ReceiptInfo
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useExtractReceiptInfo();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to ReceiptInfo
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: ReceiptInfo | null
 *   partialData, // Type: RecursivePartialNull<ReceiptInfo> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useExtractReceiptInfo({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<ReceiptInfo>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<ReceiptInfo>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       email: someValue as string,  // Replace someValue with your data
 *       reason: someValue as "curiosity" | "personal_finance",  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       email: firstValue as string,
 *       reason: firstValue as "curiosity" | "personal_finance",
 *     }),
 *     mutate({
 *       email: secondValue as string,
 *       reason: secondValue as "curiosity" | "personal_finance",
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useExtractReceiptInfo(
    options?: StreamingInputProps<ReceiptInfo>
): UseLLMReturnType<
    ReceiptInfo,
    [
        email: string,
        reason: "curiosity" | "personal_finance"
    ],
    StreamingInputProps<ReceiptInfo>
>;

export function useExtractReceiptInfo(
    options?: NonStreamingInputProps<ReceiptInfo>
): UseLLMReturnType<
    ReceiptInfo,
    [
        email: string,
        reason: "curiosity" | "personal_finance"
    ],
    NonStreamingInputProps<ReceiptInfo>
>;

export function useExtractReceiptInfo(
    options: UseLLMOptions<ReceiptInfo> = {}
): UseLLMReturnType<
    ReceiptInfo,
    [
        email: string,
        reason: "curiosity" | "personal_finance"
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<ReceiptInfo, [
        email: string,
        reason: "curiosity" | "personal_finance"
      ]>(ServerActions.ExtractReceiptInfoAction, options);
    }

    return useLLM<ReceiptInfo, [
        email: string,
        reason: "curiosity" | "personal_finance"
    ]>(ServerActions.ExtractReceiptInfoAction, options);
}

/**
 * A specialized hook for the ExtractResume BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - resume: string
 *
 * - img (optional): Image | null
 *
 *
 * Return Type:
 * - Non-streaming: Resume
 * - Streaming Partial: RecursivePartialNull<Resume>
 * - Streaming Final: Resume
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useExtractResume();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Resume
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Resume | null
 *   partialData, // Type: RecursivePartialNull<Resume> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useExtractResume({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Resume>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Resume>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       resume: someValue as string,  // Replace someValue with your data
 *       img: someValue as Image | null,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       resume: firstValue as string,
 *       img: firstValue as Image | null,
 *     }),
 *     mutate({
 *       resume: secondValue as string,
 *       img: secondValue as Image | null,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useExtractResume(
    options?: StreamingInputProps<Resume>
): UseLLMReturnType<
    Resume,
    [
        resume: string,
        img: Image | null
    ],
    StreamingInputProps<Resume>
>;

export function useExtractResume(
    options?: NonStreamingInputProps<Resume>
): UseLLMReturnType<
    Resume,
    [
        resume: string,
        img: Image | null
    ],
    NonStreamingInputProps<Resume>
>;

export function useExtractResume(
    options: UseLLMOptions<Resume> = {}
): UseLLMReturnType<
    Resume,
    [
        resume: string,
        img: Image | null
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Resume, [
        resume: string,
        img: Image | null
      ]>(ServerActions.ExtractResumeAction, options);
    }

    return useLLM<Resume, [
        resume: string,
        img: Image | null
    ]>(ServerActions.ExtractResumeAction, options);
}

/**
 * A specialized hook for the ExtractResume2 BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - resume: string
 *
 *
 * Return Type:
 * - Non-streaming: Resume
 * - Streaming Partial: RecursivePartialNull<Resume>
 * - Streaming Final: Resume
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useExtractResume2();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Resume
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Resume | null
 *   partialData, // Type: RecursivePartialNull<Resume> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useExtractResume2({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Resume>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Resume>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       resume: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       resume: firstValue as string,
 *     }),
 *     mutate({
 *       resume: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useExtractResume2(
    options?: StreamingInputProps<Resume>
): UseLLMReturnType<
    Resume,
    [
        resume: string
    ],
    StreamingInputProps<Resume>
>;

export function useExtractResume2(
    options?: NonStreamingInputProps<Resume>
): UseLLMReturnType<
    Resume,
    [
        resume: string
    ],
    NonStreamingInputProps<Resume>
>;

export function useExtractResume2(
    options: UseLLMOptions<Resume> = {}
): UseLLMReturnType<
    Resume,
    [
        resume: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Resume, [
        resume: string
      ]>(ServerActions.ExtractResume2Action, options);
    }

    return useLLM<Resume, [
        resume: string
    ]>(ServerActions.ExtractResume2Action, options);
}

/**
 * A specialized hook for the FnClassOptionalOutput BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: ClassOptionalOutput | null
 * - Streaming Partial: RecursivePartialNull<ClassOptionalOutput | null>
 * - Streaming Final: ClassOptionalOutput | null
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnClassOptionalOutput();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to ClassOptionalOutput | null
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: ClassOptionalOutput | null | null
 *   partialData, // Type: RecursivePartialNull<ClassOptionalOutput | null> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnClassOptionalOutput({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<ClassOptionalOutput | null>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<ClassOptionalOutput | null>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnClassOptionalOutput(
    options?: StreamingInputProps<ClassOptionalOutput | null>
): UseLLMReturnType<
    ClassOptionalOutput | null,
    [
        input: string
    ],
    StreamingInputProps<ClassOptionalOutput | null>
>;

export function useFnClassOptionalOutput(
    options?: NonStreamingInputProps<ClassOptionalOutput | null>
): UseLLMReturnType<
    ClassOptionalOutput | null,
    [
        input: string
    ],
    NonStreamingInputProps<ClassOptionalOutput | null>
>;

export function useFnClassOptionalOutput(
    options: UseLLMOptions<ClassOptionalOutput | null> = {}
): UseLLMReturnType<
    ClassOptionalOutput | null,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<ClassOptionalOutput | null, [
        input: string
      ]>(ServerActions.FnClassOptionalOutputAction, options);
    }

    return useLLM<ClassOptionalOutput | null, [
        input: string
    ]>(ServerActions.FnClassOptionalOutputAction, options);
}

/**
 * A specialized hook for the FnClassOptionalOutput2 BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: ClassOptionalOutput2 | null
 * - Streaming Partial: RecursivePartialNull<ClassOptionalOutput2 | null>
 * - Streaming Final: ClassOptionalOutput2 | null
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnClassOptionalOutput2();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to ClassOptionalOutput2 | null
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: ClassOptionalOutput2 | null | null
 *   partialData, // Type: RecursivePartialNull<ClassOptionalOutput2 | null> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnClassOptionalOutput2({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<ClassOptionalOutput2 | null>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<ClassOptionalOutput2 | null>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnClassOptionalOutput2(
    options?: StreamingInputProps<ClassOptionalOutput2 | null>
): UseLLMReturnType<
    ClassOptionalOutput2 | null,
    [
        input: string
    ],
    StreamingInputProps<ClassOptionalOutput2 | null>
>;

export function useFnClassOptionalOutput2(
    options?: NonStreamingInputProps<ClassOptionalOutput2 | null>
): UseLLMReturnType<
    ClassOptionalOutput2 | null,
    [
        input: string
    ],
    NonStreamingInputProps<ClassOptionalOutput2 | null>
>;

export function useFnClassOptionalOutput2(
    options: UseLLMOptions<ClassOptionalOutput2 | null> = {}
): UseLLMReturnType<
    ClassOptionalOutput2 | null,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<ClassOptionalOutput2 | null, [
        input: string
      ]>(ServerActions.FnClassOptionalOutput2Action, options);
    }

    return useLLM<ClassOptionalOutput2 | null, [
        input: string
    ]>(ServerActions.FnClassOptionalOutput2Action, options);
}

/**
 * A specialized hook for the FnEnumListOutput BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: EnumOutput[]
 * - Streaming Partial: RecursivePartialNull<EnumOutput[]>
 * - Streaming Final: EnumOutput[]
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnEnumListOutput();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to EnumOutput[]
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: EnumOutput[] | null
 *   partialData, // Type: RecursivePartialNull<EnumOutput[]> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnEnumListOutput({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<EnumOutput[]>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<EnumOutput[]>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnEnumListOutput(
    options?: StreamingInputProps<EnumOutput[]>
): UseLLMReturnType<
    EnumOutput[],
    [
        input: string
    ],
    StreamingInputProps<EnumOutput[]>
>;

export function useFnEnumListOutput(
    options?: NonStreamingInputProps<EnumOutput[]>
): UseLLMReturnType<
    EnumOutput[],
    [
        input: string
    ],
    NonStreamingInputProps<EnumOutput[]>
>;

export function useFnEnumListOutput(
    options: UseLLMOptions<EnumOutput[]> = {}
): UseLLMReturnType<
    EnumOutput[],
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<EnumOutput[], [
        input: string
      ]>(ServerActions.FnEnumListOutputAction, options);
    }

    return useLLM<EnumOutput[], [
        input: string
    ]>(ServerActions.FnEnumListOutputAction, options);
}

/**
 * A specialized hook for the FnEnumOutput BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: EnumOutput
 * - Streaming Partial: RecursivePartialNull<EnumOutput>
 * - Streaming Final: EnumOutput
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnEnumOutput();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to EnumOutput
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: EnumOutput | null
 *   partialData, // Type: RecursivePartialNull<EnumOutput> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnEnumOutput({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<EnumOutput>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<EnumOutput>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnEnumOutput(
    options?: StreamingInputProps<EnumOutput>
): UseLLMReturnType<
    EnumOutput,
    [
        input: string
    ],
    StreamingInputProps<EnumOutput>
>;

export function useFnEnumOutput(
    options?: NonStreamingInputProps<EnumOutput>
): UseLLMReturnType<
    EnumOutput,
    [
        input: string
    ],
    NonStreamingInputProps<EnumOutput>
>;

export function useFnEnumOutput(
    options: UseLLMOptions<EnumOutput> = {}
): UseLLMReturnType<
    EnumOutput,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<EnumOutput, [
        input: string
      ]>(ServerActions.FnEnumOutputAction, options);
    }

    return useLLM<EnumOutput, [
        input: string
    ]>(ServerActions.FnEnumOutputAction, options);
}

/**
 * A specialized hook for the FnLiteralClassInputOutput BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: LiteralClassHello
 *
 *
 * Return Type:
 * - Non-streaming: LiteralClassHello
 * - Streaming Partial: RecursivePartialNull<LiteralClassHello>
 * - Streaming Final: LiteralClassHello
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnLiteralClassInputOutput();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to LiteralClassHello
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: LiteralClassHello | null
 *   partialData, // Type: RecursivePartialNull<LiteralClassHello> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnLiteralClassInputOutput({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<LiteralClassHello>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<LiteralClassHello>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as LiteralClassHello,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as LiteralClassHello,
 *     }),
 *     mutate({
 *       input: secondValue as LiteralClassHello,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnLiteralClassInputOutput(
    options?: StreamingInputProps<LiteralClassHello>
): UseLLMReturnType<
    LiteralClassHello,
    [
        input: LiteralClassHello
    ],
    StreamingInputProps<LiteralClassHello>
>;

export function useFnLiteralClassInputOutput(
    options?: NonStreamingInputProps<LiteralClassHello>
): UseLLMReturnType<
    LiteralClassHello,
    [
        input: LiteralClassHello
    ],
    NonStreamingInputProps<LiteralClassHello>
>;

export function useFnLiteralClassInputOutput(
    options: UseLLMOptions<LiteralClassHello> = {}
): UseLLMReturnType<
    LiteralClassHello,
    [
        input: LiteralClassHello
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<LiteralClassHello, [
        input: LiteralClassHello
      ]>(ServerActions.FnLiteralClassInputOutputAction, options);
    }

    return useLLM<LiteralClassHello, [
        input: LiteralClassHello
    ]>(ServerActions.FnLiteralClassInputOutputAction, options);
}

/**
 * A specialized hook for the FnLiteralUnionClassInputOutput BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: LiteralClassOne | LiteralClassTwo
 *
 *
 * Return Type:
 * - Non-streaming: LiteralClassOne | LiteralClassTwo
 * - Streaming Partial: RecursivePartialNull<LiteralClassOne | LiteralClassTwo>
 * - Streaming Final: LiteralClassOne | LiteralClassTwo
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnLiteralUnionClassInputOutput();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to LiteralClassOne | LiteralClassTwo
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: LiteralClassOne | LiteralClassTwo | null
 *   partialData, // Type: RecursivePartialNull<LiteralClassOne | LiteralClassTwo> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnLiteralUnionClassInputOutput({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<LiteralClassOne | LiteralClassTwo>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<LiteralClassOne | LiteralClassTwo>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as LiteralClassOne | LiteralClassTwo,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as LiteralClassOne | LiteralClassTwo,
 *     }),
 *     mutate({
 *       input: secondValue as LiteralClassOne | LiteralClassTwo,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnLiteralUnionClassInputOutput(
    options?: StreamingInputProps<LiteralClassOne | LiteralClassTwo>
): UseLLMReturnType<
    LiteralClassOne | LiteralClassTwo,
    [
        input: LiteralClassOne | LiteralClassTwo
    ],
    StreamingInputProps<LiteralClassOne | LiteralClassTwo>
>;

export function useFnLiteralUnionClassInputOutput(
    options?: NonStreamingInputProps<LiteralClassOne | LiteralClassTwo>
): UseLLMReturnType<
    LiteralClassOne | LiteralClassTwo,
    [
        input: LiteralClassOne | LiteralClassTwo
    ],
    NonStreamingInputProps<LiteralClassOne | LiteralClassTwo>
>;

export function useFnLiteralUnionClassInputOutput(
    options: UseLLMOptions<LiteralClassOne | LiteralClassTwo> = {}
): UseLLMReturnType<
    LiteralClassOne | LiteralClassTwo,
    [
        input: LiteralClassOne | LiteralClassTwo
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<LiteralClassOne | LiteralClassTwo, [
        input: LiteralClassOne | LiteralClassTwo
      ]>(ServerActions.FnLiteralUnionClassInputOutputAction, options);
    }

    return useLLM<LiteralClassOne | LiteralClassTwo, [
        input: LiteralClassOne | LiteralClassTwo
    ]>(ServerActions.FnLiteralUnionClassInputOutputAction, options);
}

/**
 * A specialized hook for the FnNamedArgsSingleStringOptional BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - myString (optional): string | null
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnNamedArgsSingleStringOptional();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnNamedArgsSingleStringOptional({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       myString: someValue as string | null,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       myString: firstValue as string | null,
 *     }),
 *     mutate({
 *       myString: secondValue as string | null,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnNamedArgsSingleStringOptional(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myString: string | null
    ],
    StreamingInputProps<string>
>;

export function useFnNamedArgsSingleStringOptional(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myString: string | null
    ],
    NonStreamingInputProps<string>
>;

export function useFnNamedArgsSingleStringOptional(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        myString: string | null
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        myString: string | null
      ]>(ServerActions.FnNamedArgsSingleStringOptionalAction, options);
    }

    return useLLM<string, [
        myString: string | null
    ]>(ServerActions.FnNamedArgsSingleStringOptionalAction, options);
}

/**
 * A specialized hook for the FnOutputBool BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: boolean
 * - Streaming Partial: RecursivePartialNull<boolean>
 * - Streaming Final: boolean
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnOutputBool();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to boolean
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: boolean | null
 *   partialData, // Type: RecursivePartialNull<boolean> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnOutputBool({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<boolean>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<boolean>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnOutputBool(
    options?: StreamingInputProps<boolean>
): UseLLMReturnType<
    boolean,
    [
        input: string
    ],
    StreamingInputProps<boolean>
>;

export function useFnOutputBool(
    options?: NonStreamingInputProps<boolean>
): UseLLMReturnType<
    boolean,
    [
        input: string
    ],
    NonStreamingInputProps<boolean>
>;

export function useFnOutputBool(
    options: UseLLMOptions<boolean> = {}
): UseLLMReturnType<
    boolean,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<boolean, [
        input: string
      ]>(ServerActions.FnOutputBoolAction, options);
    }

    return useLLM<boolean, [
        input: string
    ]>(ServerActions.FnOutputBoolAction, options);
}

/**
 * A specialized hook for the FnOutputClass BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: TestOutputClass
 * - Streaming Partial: RecursivePartialNull<TestOutputClass>
 * - Streaming Final: TestOutputClass
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnOutputClass();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to TestOutputClass
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: TestOutputClass | null
 *   partialData, // Type: RecursivePartialNull<TestOutputClass> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnOutputClass({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<TestOutputClass>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<TestOutputClass>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnOutputClass(
    options?: StreamingInputProps<TestOutputClass>
): UseLLMReturnType<
    TestOutputClass,
    [
        input: string
    ],
    StreamingInputProps<TestOutputClass>
>;

export function useFnOutputClass(
    options?: NonStreamingInputProps<TestOutputClass>
): UseLLMReturnType<
    TestOutputClass,
    [
        input: string
    ],
    NonStreamingInputProps<TestOutputClass>
>;

export function useFnOutputClass(
    options: UseLLMOptions<TestOutputClass> = {}
): UseLLMReturnType<
    TestOutputClass,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<TestOutputClass, [
        input: string
      ]>(ServerActions.FnOutputClassAction, options);
    }

    return useLLM<TestOutputClass, [
        input: string
    ]>(ServerActions.FnOutputClassAction, options);
}

/**
 * A specialized hook for the FnOutputClassList BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: TestOutputClass[]
 * - Streaming Partial: RecursivePartialNull<TestOutputClass[]>
 * - Streaming Final: TestOutputClass[]
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnOutputClassList();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to TestOutputClass[]
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: TestOutputClass[] | null
 *   partialData, // Type: RecursivePartialNull<TestOutputClass[]> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnOutputClassList({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<TestOutputClass[]>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<TestOutputClass[]>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnOutputClassList(
    options?: StreamingInputProps<TestOutputClass[]>
): UseLLMReturnType<
    TestOutputClass[],
    [
        input: string
    ],
    StreamingInputProps<TestOutputClass[]>
>;

export function useFnOutputClassList(
    options?: NonStreamingInputProps<TestOutputClass[]>
): UseLLMReturnType<
    TestOutputClass[],
    [
        input: string
    ],
    NonStreamingInputProps<TestOutputClass[]>
>;

export function useFnOutputClassList(
    options: UseLLMOptions<TestOutputClass[]> = {}
): UseLLMReturnType<
    TestOutputClass[],
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<TestOutputClass[], [
        input: string
      ]>(ServerActions.FnOutputClassListAction, options);
    }

    return useLLM<TestOutputClass[], [
        input: string
    ]>(ServerActions.FnOutputClassListAction, options);
}

/**
 * A specialized hook for the FnOutputClassNested BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: TestClassNested
 * - Streaming Partial: RecursivePartialNull<TestClassNested>
 * - Streaming Final: TestClassNested
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnOutputClassNested();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to TestClassNested
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: TestClassNested | null
 *   partialData, // Type: RecursivePartialNull<TestClassNested> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnOutputClassNested({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<TestClassNested>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<TestClassNested>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnOutputClassNested(
    options?: StreamingInputProps<TestClassNested>
): UseLLMReturnType<
    TestClassNested,
    [
        input: string
    ],
    StreamingInputProps<TestClassNested>
>;

export function useFnOutputClassNested(
    options?: NonStreamingInputProps<TestClassNested>
): UseLLMReturnType<
    TestClassNested,
    [
        input: string
    ],
    NonStreamingInputProps<TestClassNested>
>;

export function useFnOutputClassNested(
    options: UseLLMOptions<TestClassNested> = {}
): UseLLMReturnType<
    TestClassNested,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<TestClassNested, [
        input: string
      ]>(ServerActions.FnOutputClassNestedAction, options);
    }

    return useLLM<TestClassNested, [
        input: string
    ]>(ServerActions.FnOutputClassNestedAction, options);
}

/**
 * A specialized hook for the FnOutputClassWithEnum BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: TestClassWithEnum
 * - Streaming Partial: RecursivePartialNull<TestClassWithEnum>
 * - Streaming Final: TestClassWithEnum
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnOutputClassWithEnum();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to TestClassWithEnum
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: TestClassWithEnum | null
 *   partialData, // Type: RecursivePartialNull<TestClassWithEnum> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnOutputClassWithEnum({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<TestClassWithEnum>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<TestClassWithEnum>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnOutputClassWithEnum(
    options?: StreamingInputProps<TestClassWithEnum>
): UseLLMReturnType<
    TestClassWithEnum,
    [
        input: string
    ],
    StreamingInputProps<TestClassWithEnum>
>;

export function useFnOutputClassWithEnum(
    options?: NonStreamingInputProps<TestClassWithEnum>
): UseLLMReturnType<
    TestClassWithEnum,
    [
        input: string
    ],
    NonStreamingInputProps<TestClassWithEnum>
>;

export function useFnOutputClassWithEnum(
    options: UseLLMOptions<TestClassWithEnum> = {}
): UseLLMReturnType<
    TestClassWithEnum,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<TestClassWithEnum, [
        input: string
      ]>(ServerActions.FnOutputClassWithEnumAction, options);
    }

    return useLLM<TestClassWithEnum, [
        input: string
    ]>(ServerActions.FnOutputClassWithEnumAction, options);
}

/**
 * A specialized hook for the FnOutputInt BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: number
 * - Streaming Partial: RecursivePartialNull<number>
 * - Streaming Final: number
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnOutputInt();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to number
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: number | null
 *   partialData, // Type: RecursivePartialNull<number> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnOutputInt({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<number>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<number>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnOutputInt(
    options?: StreamingInputProps<number>
): UseLLMReturnType<
    number,
    [
        input: string
    ],
    StreamingInputProps<number>
>;

export function useFnOutputInt(
    options?: NonStreamingInputProps<number>
): UseLLMReturnType<
    number,
    [
        input: string
    ],
    NonStreamingInputProps<number>
>;

export function useFnOutputInt(
    options: UseLLMOptions<number> = {}
): UseLLMReturnType<
    number,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<number, [
        input: string
      ]>(ServerActions.FnOutputIntAction, options);
    }

    return useLLM<number, [
        input: string
    ]>(ServerActions.FnOutputIntAction, options);
}

/**
 * A specialized hook for the FnOutputLiteralBool BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: false
 * - Streaming Partial: RecursivePartialNull<false>
 * - Streaming Final: false
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnOutputLiteralBool();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to false
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: false | null
 *   partialData, // Type: RecursivePartialNull<false> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnOutputLiteralBool({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<false>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<false>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnOutputLiteralBool(
    options?: StreamingInputProps<false>
): UseLLMReturnType<
    false,
    [
        input: string
    ],
    StreamingInputProps<false>
>;

export function useFnOutputLiteralBool(
    options?: NonStreamingInputProps<false>
): UseLLMReturnType<
    false,
    [
        input: string
    ],
    NonStreamingInputProps<false>
>;

export function useFnOutputLiteralBool(
    options: UseLLMOptions<false> = {}
): UseLLMReturnType<
    false,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<false, [
        input: string
      ]>(ServerActions.FnOutputLiteralBoolAction, options);
    }

    return useLLM<false, [
        input: string
    ]>(ServerActions.FnOutputLiteralBoolAction, options);
}

/**
 * A specialized hook for the FnOutputLiteralInt BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: 5
 * - Streaming Partial: RecursivePartialNull<5>
 * - Streaming Final: 5
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnOutputLiteralInt();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to 5
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: 5 | null
 *   partialData, // Type: RecursivePartialNull<5> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnOutputLiteralInt({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<5>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<5>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnOutputLiteralInt(
    options?: StreamingInputProps<5>
): UseLLMReturnType<
    5,
    [
        input: string
    ],
    StreamingInputProps<5>
>;

export function useFnOutputLiteralInt(
    options?: NonStreamingInputProps<5>
): UseLLMReturnType<
    5,
    [
        input: string
    ],
    NonStreamingInputProps<5>
>;

export function useFnOutputLiteralInt(
    options: UseLLMOptions<5> = {}
): UseLLMReturnType<
    5,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<5, [
        input: string
      ]>(ServerActions.FnOutputLiteralIntAction, options);
    }

    return useLLM<5, [
        input: string
    ]>(ServerActions.FnOutputLiteralIntAction, options);
}

/**
 * A specialized hook for the FnOutputLiteralString BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: "example output"
 * - Streaming Partial: RecursivePartialNull<"example output">
 * - Streaming Final: "example output"
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnOutputLiteralString();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to "example output"
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: "example output" | null
 *   partialData, // Type: RecursivePartialNull<"example output"> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnOutputLiteralString({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<"example output">
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<"example output">
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnOutputLiteralString(
    options?: StreamingInputProps<"example output">
): UseLLMReturnType<
    "example output",
    [
        input: string
    ],
    StreamingInputProps<"example output">
>;

export function useFnOutputLiteralString(
    options?: NonStreamingInputProps<"example output">
): UseLLMReturnType<
    "example output",
    [
        input: string
    ],
    NonStreamingInputProps<"example output">
>;

export function useFnOutputLiteralString(
    options: UseLLMOptions<"example output"> = {}
): UseLLMReturnType<
    "example output",
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<"example output", [
        input: string
      ]>(ServerActions.FnOutputLiteralStringAction, options);
    }

    return useLLM<"example output", [
        input: string
    ]>(ServerActions.FnOutputLiteralStringAction, options);
}

/**
 * A specialized hook for the FnOutputStringList BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string[]
 * - Streaming Partial: RecursivePartialNull<string[]>
 * - Streaming Final: string[]
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnOutputStringList();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string[]
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string[] | null
 *   partialData, // Type: RecursivePartialNull<string[]> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnOutputStringList({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string[]>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string[]>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnOutputStringList(
    options?: StreamingInputProps<string[]>
): UseLLMReturnType<
    string[],
    [
        input: string
    ],
    StreamingInputProps<string[]>
>;

export function useFnOutputStringList(
    options?: NonStreamingInputProps<string[]>
): UseLLMReturnType<
    string[],
    [
        input: string
    ],
    NonStreamingInputProps<string[]>
>;

export function useFnOutputStringList(
    options: UseLLMOptions<string[]> = {}
): UseLLMReturnType<
    string[],
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string[], [
        input: string
      ]>(ServerActions.FnOutputStringListAction, options);
    }

    return useLLM<string[], [
        input: string
    ]>(ServerActions.FnOutputStringListAction, options);
}

/**
 * A specialized hook for the FnTestAliasedEnumOutput BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: TestEnum
 * - Streaming Partial: RecursivePartialNull<TestEnum>
 * - Streaming Final: TestEnum
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnTestAliasedEnumOutput();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to TestEnum
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: TestEnum | null
 *   partialData, // Type: RecursivePartialNull<TestEnum> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnTestAliasedEnumOutput({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<TestEnum>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<TestEnum>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnTestAliasedEnumOutput(
    options?: StreamingInputProps<TestEnum>
): UseLLMReturnType<
    TestEnum,
    [
        input: string
    ],
    StreamingInputProps<TestEnum>
>;

export function useFnTestAliasedEnumOutput(
    options?: NonStreamingInputProps<TestEnum>
): UseLLMReturnType<
    TestEnum,
    [
        input: string
    ],
    NonStreamingInputProps<TestEnum>
>;

export function useFnTestAliasedEnumOutput(
    options: UseLLMOptions<TestEnum> = {}
): UseLLMReturnType<
    TestEnum,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<TestEnum, [
        input: string
      ]>(ServerActions.FnTestAliasedEnumOutputAction, options);
    }

    return useLLM<TestEnum, [
        input: string
    ]>(ServerActions.FnTestAliasedEnumOutputAction, options);
}

/**
 * A specialized hook for the FnTestClassAlias BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: TestClassAlias
 * - Streaming Partial: RecursivePartialNull<TestClassAlias>
 * - Streaming Final: TestClassAlias
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnTestClassAlias();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to TestClassAlias
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: TestClassAlias | null
 *   partialData, // Type: RecursivePartialNull<TestClassAlias> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnTestClassAlias({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<TestClassAlias>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<TestClassAlias>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnTestClassAlias(
    options?: StreamingInputProps<TestClassAlias>
): UseLLMReturnType<
    TestClassAlias,
    [
        input: string
    ],
    StreamingInputProps<TestClassAlias>
>;

export function useFnTestClassAlias(
    options?: NonStreamingInputProps<TestClassAlias>
): UseLLMReturnType<
    TestClassAlias,
    [
        input: string
    ],
    NonStreamingInputProps<TestClassAlias>
>;

export function useFnTestClassAlias(
    options: UseLLMOptions<TestClassAlias> = {}
): UseLLMReturnType<
    TestClassAlias,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<TestClassAlias, [
        input: string
      ]>(ServerActions.FnTestClassAliasAction, options);
    }

    return useLLM<TestClassAlias, [
        input: string
    ]>(ServerActions.FnTestClassAliasAction, options);
}

/**
 * A specialized hook for the FnTestNamedArgsSingleEnum BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - myArg: NamedArgsSingleEnum
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useFnTestNamedArgsSingleEnum();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useFnTestNamedArgsSingleEnum({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       myArg: someValue as NamedArgsSingleEnum,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       myArg: firstValue as NamedArgsSingleEnum,
 *     }),
 *     mutate({
 *       myArg: secondValue as NamedArgsSingleEnum,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useFnTestNamedArgsSingleEnum(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myArg: NamedArgsSingleEnum
    ],
    StreamingInputProps<string>
>;

export function useFnTestNamedArgsSingleEnum(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myArg: NamedArgsSingleEnum
    ],
    NonStreamingInputProps<string>
>;

export function useFnTestNamedArgsSingleEnum(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        myArg: NamedArgsSingleEnum
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        myArg: NamedArgsSingleEnum
      ]>(ServerActions.FnTestNamedArgsSingleEnumAction, options);
    }

    return useLLM<string, [
        myArg: NamedArgsSingleEnum
    ]>(ServerActions.FnTestNamedArgsSingleEnumAction, options);
}

/**
 * A specialized hook for the GetDataType BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - text: string
 *
 *
 * Return Type:
 * - Non-streaming: RaysData
 * - Streaming Partial: RecursivePartialNull<RaysData>
 * - Streaming Final: RaysData
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useGetDataType();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to RaysData
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: RaysData | null
 *   partialData, // Type: RecursivePartialNull<RaysData> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useGetDataType({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<RaysData>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<RaysData>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       text: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       text: firstValue as string,
 *     }),
 *     mutate({
 *       text: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useGetDataType(
    options?: StreamingInputProps<RaysData>
): UseLLMReturnType<
    RaysData,
    [
        text: string
    ],
    StreamingInputProps<RaysData>
>;

export function useGetDataType(
    options?: NonStreamingInputProps<RaysData>
): UseLLMReturnType<
    RaysData,
    [
        text: string
    ],
    NonStreamingInputProps<RaysData>
>;

export function useGetDataType(
    options: UseLLMOptions<RaysData> = {}
): UseLLMReturnType<
    RaysData,
    [
        text: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<RaysData, [
        text: string
      ]>(ServerActions.GetDataTypeAction, options);
    }

    return useLLM<RaysData, [
        text: string
    ]>(ServerActions.GetDataTypeAction, options);
}

/**
 * A specialized hook for the GetOrderInfo BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - email: Email
 *
 *
 * Return Type:
 * - Non-streaming: OrderInfo
 * - Streaming Partial: RecursivePartialNull<OrderInfo>
 * - Streaming Final: OrderInfo
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useGetOrderInfo();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to OrderInfo
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: OrderInfo | null
 *   partialData, // Type: RecursivePartialNull<OrderInfo> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useGetOrderInfo({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<OrderInfo>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<OrderInfo>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       email: someValue as Email,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       email: firstValue as Email,
 *     }),
 *     mutate({
 *       email: secondValue as Email,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useGetOrderInfo(
    options?: StreamingInputProps<OrderInfo>
): UseLLMReturnType<
    OrderInfo,
    [
        email: Email
    ],
    StreamingInputProps<OrderInfo>
>;

export function useGetOrderInfo(
    options?: NonStreamingInputProps<OrderInfo>
): UseLLMReturnType<
    OrderInfo,
    [
        email: Email
    ],
    NonStreamingInputProps<OrderInfo>
>;

export function useGetOrderInfo(
    options: UseLLMOptions<OrderInfo> = {}
): UseLLMReturnType<
    OrderInfo,
    [
        email: Email
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<OrderInfo, [
        email: Email
      ]>(ServerActions.GetOrderInfoAction, options);
    }

    return useLLM<OrderInfo, [
        email: Email
    ]>(ServerActions.GetOrderInfoAction, options);
}

/**
 * A specialized hook for the GetQuery BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - query: string
 *
 *
 * Return Type:
 * - Non-streaming: SearchParams
 * - Streaming Partial: RecursivePartialNull<SearchParams>
 * - Streaming Final: SearchParams
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useGetQuery();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to SearchParams
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: SearchParams | null
 *   partialData, // Type: RecursivePartialNull<SearchParams> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useGetQuery({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<SearchParams>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<SearchParams>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       query: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       query: firstValue as string,
 *     }),
 *     mutate({
 *       query: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useGetQuery(
    options?: StreamingInputProps<SearchParams>
): UseLLMReturnType<
    SearchParams,
    [
        query: string
    ],
    StreamingInputProps<SearchParams>
>;

export function useGetQuery(
    options?: NonStreamingInputProps<SearchParams>
): UseLLMReturnType<
    SearchParams,
    [
        query: string
    ],
    NonStreamingInputProps<SearchParams>
>;

export function useGetQuery(
    options: UseLLMOptions<SearchParams> = {}
): UseLLMReturnType<
    SearchParams,
    [
        query: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<SearchParams, [
        query: string
      ]>(ServerActions.GetQueryAction, options);
    }

    return useLLM<SearchParams, [
        query: string
    ]>(ServerActions.GetQueryAction, options);
}

/**
 * A specialized hook for the InOutEnumMapKey BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - i1: Partial<Record<MapKey, string>>
 *
 * - i2: Partial<Record<MapKey, string>>
 *
 *
 * Return Type:
 * - Non-streaming: Partial<Record<MapKey, string>>
 * - Streaming Partial: RecursivePartialNull<Partial<Record<MapKey, string>>>
 * - Streaming Final: Partial<Record<MapKey, string>>
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useInOutEnumMapKey();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Partial<Record<MapKey, string>>
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Partial<Record<MapKey, string>> | null
 *   partialData, // Type: RecursivePartialNull<Partial<Record<MapKey, string>>> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useInOutEnumMapKey({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Partial<Record<MapKey, string>>>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Partial<Record<MapKey, string>>>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       i1: someValue as Partial<Record<MapKey, string>>,  // Replace someValue with your data
 *       i2: someValue as Partial<Record<MapKey, string>>,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       i1: firstValue as Partial<Record<MapKey, string>>,
 *       i2: firstValue as Partial<Record<MapKey, string>>,
 *     }),
 *     mutate({
 *       i1: secondValue as Partial<Record<MapKey, string>>,
 *       i2: secondValue as Partial<Record<MapKey, string>>,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useInOutEnumMapKey(
    options?: StreamingInputProps<Partial<Record<MapKey, string>>>
): UseLLMReturnType<
    Partial<Record<MapKey, string>>,
    [
        i1: Partial<Record<MapKey, string>>,
        i2: Partial<Record<MapKey, string>>
    ],
    StreamingInputProps<Partial<Record<MapKey, string>>>
>;

export function useInOutEnumMapKey(
    options?: NonStreamingInputProps<Partial<Record<MapKey, string>>>
): UseLLMReturnType<
    Partial<Record<MapKey, string>>,
    [
        i1: Partial<Record<MapKey, string>>,
        i2: Partial<Record<MapKey, string>>
    ],
    NonStreamingInputProps<Partial<Record<MapKey, string>>>
>;

export function useInOutEnumMapKey(
    options: UseLLMOptions<Partial<Record<MapKey, string>>> = {}
): UseLLMReturnType<
    Partial<Record<MapKey, string>>,
    [
        i1: Partial<Record<MapKey, string>>,
        i2: Partial<Record<MapKey, string>>
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Partial<Record<MapKey, string>>, [
        i1: Partial<Record<MapKey, string>>,
        i2: Partial<Record<MapKey, string>>
      ]>(ServerActions.InOutEnumMapKeyAction, options);
    }

    return useLLM<Partial<Record<MapKey, string>>, [
        i1: Partial<Record<MapKey, string>>,
        i2: Partial<Record<MapKey, string>>
    ]>(ServerActions.InOutEnumMapKeyAction, options);
}

/**
 * A specialized hook for the InOutLiteralStringUnionMapKey BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - i1: Partial<Record<"one" | "two" | "three" | "four", string>>
 *
 * - i2: Partial<Record<"one" | "two" | "three" | "four", string>>
 *
 *
 * Return Type:
 * - Non-streaming: Partial<Record<"one" | "two" | "three" | "four", string>>
 * - Streaming Partial: RecursivePartialNull<Partial<Record<"one" | "two" | "three" | "four", string>>>
 * - Streaming Final: Partial<Record<"one" | "two" | "three" | "four", string>>
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useInOutLiteralStringUnionMapKey();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Partial<Record<"one" | "two" | "three" | "four", string>>
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Partial<Record<"one" | "two" | "three" | "four", string>> | null
 *   partialData, // Type: RecursivePartialNull<Partial<Record<"one" | "two" | "three" | "four", string>>> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useInOutLiteralStringUnionMapKey({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Partial<Record<"one" | "two" | "three" | "four", string>>>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Partial<Record<"one" | "two" | "three" | "four", string>>>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       i1: someValue as Partial<Record<"one" | "two" | "three" | "four", string>>,  // Replace someValue with your data
 *       i2: someValue as Partial<Record<"one" | "two" | "three" | "four", string>>,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       i1: firstValue as Partial<Record<"one" | "two" | "three" | "four", string>>,
 *       i2: firstValue as Partial<Record<"one" | "two" | "three" | "four", string>>,
 *     }),
 *     mutate({
 *       i1: secondValue as Partial<Record<"one" | "two" | "three" | "four", string>>,
 *       i2: secondValue as Partial<Record<"one" | "two" | "three" | "four", string>>,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useInOutLiteralStringUnionMapKey(
    options?: StreamingInputProps<Partial<Record<"one" | "two" | "three" | "four", string>>>
): UseLLMReturnType<
    Partial<Record<"one" | "two" | "three" | "four", string>>,
    [
        i1: Partial<Record<"one" | "two" | "three" | "four", string>>,
        i2: Partial<Record<"one" | "two" | "three" | "four", string>>
    ],
    StreamingInputProps<Partial<Record<"one" | "two" | "three" | "four", string>>>
>;

export function useInOutLiteralStringUnionMapKey(
    options?: NonStreamingInputProps<Partial<Record<"one" | "two" | "three" | "four", string>>>
): UseLLMReturnType<
    Partial<Record<"one" | "two" | "three" | "four", string>>,
    [
        i1: Partial<Record<"one" | "two" | "three" | "four", string>>,
        i2: Partial<Record<"one" | "two" | "three" | "four", string>>
    ],
    NonStreamingInputProps<Partial<Record<"one" | "two" | "three" | "four", string>>>
>;

export function useInOutLiteralStringUnionMapKey(
    options: UseLLMOptions<Partial<Record<"one" | "two" | "three" | "four", string>>> = {}
): UseLLMReturnType<
    Partial<Record<"one" | "two" | "three" | "four", string>>,
    [
        i1: Partial<Record<"one" | "two" | "three" | "four", string>>,
        i2: Partial<Record<"one" | "two" | "three" | "four", string>>
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Partial<Record<"one" | "two" | "three" | "four", string>>, [
        i1: Partial<Record<"one" | "two" | "three" | "four", string>>,
        i2: Partial<Record<"one" | "two" | "three" | "four", string>>
      ]>(ServerActions.InOutLiteralStringUnionMapKeyAction, options);
    }

    return useLLM<Partial<Record<"one" | "two" | "three" | "four", string>>, [
        i1: Partial<Record<"one" | "two" | "three" | "four", string>>,
        i2: Partial<Record<"one" | "two" | "three" | "four", string>>
    ]>(ServerActions.InOutLiteralStringUnionMapKeyAction, options);
}

/**
 * A specialized hook for the InOutSingleLiteralStringMapKey BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - m: Partial<Record<"key", string>>
 *
 *
 * Return Type:
 * - Non-streaming: Partial<Record<"key", string>>
 * - Streaming Partial: RecursivePartialNull<Partial<Record<"key", string>>>
 * - Streaming Final: Partial<Record<"key", string>>
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useInOutSingleLiteralStringMapKey();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Partial<Record<"key", string>>
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Partial<Record<"key", string>> | null
 *   partialData, // Type: RecursivePartialNull<Partial<Record<"key", string>>> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useInOutSingleLiteralStringMapKey({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Partial<Record<"key", string>>>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Partial<Record<"key", string>>>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       m: someValue as Partial<Record<"key", string>>,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       m: firstValue as Partial<Record<"key", string>>,
 *     }),
 *     mutate({
 *       m: secondValue as Partial<Record<"key", string>>,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useInOutSingleLiteralStringMapKey(
    options?: StreamingInputProps<Partial<Record<"key", string>>>
): UseLLMReturnType<
    Partial<Record<"key", string>>,
    [
        m: Partial<Record<"key", string>>
    ],
    StreamingInputProps<Partial<Record<"key", string>>>
>;

export function useInOutSingleLiteralStringMapKey(
    options?: NonStreamingInputProps<Partial<Record<"key", string>>>
): UseLLMReturnType<
    Partial<Record<"key", string>>,
    [
        m: Partial<Record<"key", string>>
    ],
    NonStreamingInputProps<Partial<Record<"key", string>>>
>;

export function useInOutSingleLiteralStringMapKey(
    options: UseLLMOptions<Partial<Record<"key", string>>> = {}
): UseLLMReturnType<
    Partial<Record<"key", string>>,
    [
        m: Partial<Record<"key", string>>
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Partial<Record<"key", string>>, [
        m: Partial<Record<"key", string>>
      ]>(ServerActions.InOutSingleLiteralStringMapKeyAction, options);
    }

    return useLLM<Partial<Record<"key", string>>, [
        m: Partial<Record<"key", string>>
    ]>(ServerActions.InOutSingleLiteralStringMapKeyAction, options);
}

/**
 * A specialized hook for the JsonTypeAliasCycle BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: JsonValue
 *
 *
 * Return Type:
 * - Non-streaming: JsonValue
 * - Streaming Partial: RecursivePartialNull<JsonValue>
 * - Streaming Final: JsonValue
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useJsonTypeAliasCycle();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to JsonValue
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: JsonValue | null
 *   partialData, // Type: RecursivePartialNull<JsonValue> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useJsonTypeAliasCycle({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<JsonValue>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<JsonValue>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as JsonValue,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as JsonValue,
 *     }),
 *     mutate({
 *       input: secondValue as JsonValue,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useJsonTypeAliasCycle(
    options?: StreamingInputProps<JsonValue>
): UseLLMReturnType<
    JsonValue,
    [
        input: JsonValue
    ],
    StreamingInputProps<JsonValue>
>;

export function useJsonTypeAliasCycle(
    options?: NonStreamingInputProps<JsonValue>
): UseLLMReturnType<
    JsonValue,
    [
        input: JsonValue
    ],
    NonStreamingInputProps<JsonValue>
>;

export function useJsonTypeAliasCycle(
    options: UseLLMOptions<JsonValue> = {}
): UseLLMReturnType<
    JsonValue,
    [
        input: JsonValue
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<JsonValue, [
        input: JsonValue
      ]>(ServerActions.JsonTypeAliasCycleAction, options);
    }

    return useLLM<JsonValue, [
        input: JsonValue
    ]>(ServerActions.JsonTypeAliasCycleAction, options);
}

/**
 * A specialized hook for the LiteralUnionsTest BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: 1 | true | "string output"
 * - Streaming Partial: RecursivePartialNull<1 | true | "string output">
 * - Streaming Final: 1 | true | "string output"
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useLiteralUnionsTest();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to 1 | true | "string output"
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: 1 | true | "string output" | null
 *   partialData, // Type: RecursivePartialNull<1 | true | "string output"> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useLiteralUnionsTest({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<1 | true | "string output">
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<1 | true | "string output">
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useLiteralUnionsTest(
    options?: StreamingInputProps<1 | true | "string output">
): UseLLMReturnType<
    1 | true | "string output",
    [
        input: string
    ],
    StreamingInputProps<1 | true | "string output">
>;

export function useLiteralUnionsTest(
    options?: NonStreamingInputProps<1 | true | "string output">
): UseLLMReturnType<
    1 | true | "string output",
    [
        input: string
    ],
    NonStreamingInputProps<1 | true | "string output">
>;

export function useLiteralUnionsTest(
    options: UseLLMOptions<1 | true | "string output"> = {}
): UseLLMReturnType<
    1 | true | "string output",
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<1 | true | "string output", [
        input: string
      ]>(ServerActions.LiteralUnionsTestAction, options);
    }

    return useLLM<1 | true | "string output", [
        input: string
    ]>(ServerActions.LiteralUnionsTestAction, options);
}

/**
 * A specialized hook for the MakeBlockConstraint BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 *
 * Return Type:
 * - Non-streaming: Checked<BlockConstraint,"cross_field">
 * - Streaming Partial: RecursivePartialNull<Checked<BlockConstraint,"cross_field">>
 * - Streaming Final: Checked<BlockConstraint,"cross_field">
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useMakeBlockConstraint();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Checked<BlockConstraint,"cross_field">
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Checked<BlockConstraint,"cross_field"> | null
 *   partialData, // Type: RecursivePartialNull<Checked<BlockConstraint,"cross_field">> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useMakeBlockConstraint({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Checked<BlockConstraint,"cross_field">>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Checked<BlockConstraint,"cross_field">>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *     }),
 *     mutate({
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useMakeBlockConstraint(
    options?: StreamingInputProps<Checked<BlockConstraint,"cross_field">>
): UseLLMReturnType<
    Checked<BlockConstraint,"cross_field">,
    [
    ],
    StreamingInputProps<Checked<BlockConstraint,"cross_field">>
>;

export function useMakeBlockConstraint(
    options?: NonStreamingInputProps<Checked<BlockConstraint,"cross_field">>
): UseLLMReturnType<
    Checked<BlockConstraint,"cross_field">,
    [
    ],
    NonStreamingInputProps<Checked<BlockConstraint,"cross_field">>
>;

export function useMakeBlockConstraint(
    options: UseLLMOptions<Checked<BlockConstraint,"cross_field">> = {}
): UseLLMReturnType<
    Checked<BlockConstraint,"cross_field">,
    [
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Checked<BlockConstraint,"cross_field">, [
      ]>(ServerActions.MakeBlockConstraintAction, options);
    }

    return useLLM<Checked<BlockConstraint,"cross_field">, [
    ]>(ServerActions.MakeBlockConstraintAction, options);
}

/**
 * A specialized hook for the MakeNestedBlockConstraint BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 *
 * Return Type:
 * - Non-streaming: NestedBlockConstraint
 * - Streaming Partial: RecursivePartialNull<NestedBlockConstraint>
 * - Streaming Final: NestedBlockConstraint
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useMakeNestedBlockConstraint();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to NestedBlockConstraint
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: NestedBlockConstraint | null
 *   partialData, // Type: RecursivePartialNull<NestedBlockConstraint> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useMakeNestedBlockConstraint({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<NestedBlockConstraint>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<NestedBlockConstraint>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *     }),
 *     mutate({
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useMakeNestedBlockConstraint(
    options?: StreamingInputProps<NestedBlockConstraint>
): UseLLMReturnType<
    NestedBlockConstraint,
    [
    ],
    StreamingInputProps<NestedBlockConstraint>
>;

export function useMakeNestedBlockConstraint(
    options?: NonStreamingInputProps<NestedBlockConstraint>
): UseLLMReturnType<
    NestedBlockConstraint,
    [
    ],
    NonStreamingInputProps<NestedBlockConstraint>
>;

export function useMakeNestedBlockConstraint(
    options: UseLLMOptions<NestedBlockConstraint> = {}
): UseLLMReturnType<
    NestedBlockConstraint,
    [
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<NestedBlockConstraint, [
      ]>(ServerActions.MakeNestedBlockConstraintAction, options);
    }

    return useLLM<NestedBlockConstraint, [
    ]>(ServerActions.MakeNestedBlockConstraintAction, options);
}

/**
 * A specialized hook for the MapAlias BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - m: Record<string, string[]>
 *
 *
 * Return Type:
 * - Non-streaming: Record<string, string[]>
 * - Streaming Partial: RecursivePartialNull<Record<string, string[]>>
 * - Streaming Final: Record<string, string[]>
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useMapAlias();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Record<string, string[]>
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Record<string, string[]> | null
 *   partialData, // Type: RecursivePartialNull<Record<string, string[]>> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useMapAlias({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Record<string, string[]>>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Record<string, string[]>>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       m: someValue as Record<string, string[]>,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       m: firstValue as Record<string, string[]>,
 *     }),
 *     mutate({
 *       m: secondValue as Record<string, string[]>,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useMapAlias(
    options?: StreamingInputProps<Record<string, string[]>>
): UseLLMReturnType<
    Record<string, string[]>,
    [
        m: Record<string, string[]>
    ],
    StreamingInputProps<Record<string, string[]>>
>;

export function useMapAlias(
    options?: NonStreamingInputProps<Record<string, string[]>>
): UseLLMReturnType<
    Record<string, string[]>,
    [
        m: Record<string, string[]>
    ],
    NonStreamingInputProps<Record<string, string[]>>
>;

export function useMapAlias(
    options: UseLLMOptions<Record<string, string[]>> = {}
): UseLLMReturnType<
    Record<string, string[]>,
    [
        m: Record<string, string[]>
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Record<string, string[]>, [
        m: Record<string, string[]>
      ]>(ServerActions.MapAliasAction, options);
    }

    return useLLM<Record<string, string[]>, [
        m: Record<string, string[]>
    ]>(ServerActions.MapAliasAction, options);
}

/**
 * A specialized hook for the MergeAliasAttributes BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - money: number
 *
 *
 * Return Type:
 * - Non-streaming: MergeAttrs
 * - Streaming Partial: RecursivePartialNull<MergeAttrs>
 * - Streaming Final: MergeAttrs
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useMergeAliasAttributes();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to MergeAttrs
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: MergeAttrs | null
 *   partialData, // Type: RecursivePartialNull<MergeAttrs> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useMergeAliasAttributes({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<MergeAttrs>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<MergeAttrs>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       money: someValue as number,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       money: firstValue as number,
 *     }),
 *     mutate({
 *       money: secondValue as number,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useMergeAliasAttributes(
    options?: StreamingInputProps<MergeAttrs>
): UseLLMReturnType<
    MergeAttrs,
    [
        money: number
    ],
    StreamingInputProps<MergeAttrs>
>;

export function useMergeAliasAttributes(
    options?: NonStreamingInputProps<MergeAttrs>
): UseLLMReturnType<
    MergeAttrs,
    [
        money: number
    ],
    NonStreamingInputProps<MergeAttrs>
>;

export function useMergeAliasAttributes(
    options: UseLLMOptions<MergeAttrs> = {}
): UseLLMReturnType<
    MergeAttrs,
    [
        money: number
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<MergeAttrs, [
        money: number
      ]>(ServerActions.MergeAliasAttributesAction, options);
    }

    return useLLM<MergeAttrs, [
        money: number
    ]>(ServerActions.MergeAliasAttributesAction, options);
}

/**
 * A specialized hook for the MyFunc BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: DynamicOutput
 * - Streaming Partial: RecursivePartialNull<DynamicOutput>
 * - Streaming Final: DynamicOutput
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useMyFunc();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to DynamicOutput
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: DynamicOutput | null
 *   partialData, // Type: RecursivePartialNull<DynamicOutput> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useMyFunc({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<DynamicOutput>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<DynamicOutput>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useMyFunc(
    options?: StreamingInputProps<DynamicOutput>
): UseLLMReturnType<
    DynamicOutput,
    [
        input: string
    ],
    StreamingInputProps<DynamicOutput>
>;

export function useMyFunc(
    options?: NonStreamingInputProps<DynamicOutput>
): UseLLMReturnType<
    DynamicOutput,
    [
        input: string
    ],
    NonStreamingInputProps<DynamicOutput>
>;

export function useMyFunc(
    options: UseLLMOptions<DynamicOutput> = {}
): UseLLMReturnType<
    DynamicOutput,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<DynamicOutput, [
        input: string
      ]>(ServerActions.MyFuncAction, options);
    }

    return useLLM<DynamicOutput, [
        input: string
    ]>(ServerActions.MyFuncAction, options);
}

/**
 * A specialized hook for the NestedAlias BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - c: number | string | boolean | number | string[] | Record<string, string[]>
 *
 *
 * Return Type:
 * - Non-streaming: number | string | boolean | number | string[] | Record<string, string[]>
 * - Streaming Partial: RecursivePartialNull<number | string | boolean | number | string[] | Record<string, string[]>>
 * - Streaming Final: number | string | boolean | number | string[] | Record<string, string[]>
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useNestedAlias();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to number | string | boolean | number | string[] | Record<string, string[]>
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: number | string | boolean | number | string[] | Record<string, string[]> | null
 *   partialData, // Type: RecursivePartialNull<number | string | boolean | number | string[] | Record<string, string[]>> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useNestedAlias({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<number | string | boolean | number | string[] | Record<string, string[]>>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<number | string | boolean | number | string[] | Record<string, string[]>>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       c: someValue as number | string | boolean | number | string[] | Record<string, string[]>,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       c: firstValue as number | string | boolean | number | string[] | Record<string, string[]>,
 *     }),
 *     mutate({
 *       c: secondValue as number | string | boolean | number | string[] | Record<string, string[]>,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useNestedAlias(
    options?: StreamingInputProps<number | string | boolean | number | string[] | Record<string, string[]>>
): UseLLMReturnType<
    number | string | boolean | number | string[] | Record<string, string[]>,
    [
        c: number | string | boolean | number | string[] | Record<string, string[]>
    ],
    StreamingInputProps<number | string | boolean | number | string[] | Record<string, string[]>>
>;

export function useNestedAlias(
    options?: NonStreamingInputProps<number | string | boolean | number | string[] | Record<string, string[]>>
): UseLLMReturnType<
    number | string | boolean | number | string[] | Record<string, string[]>,
    [
        c: number | string | boolean | number | string[] | Record<string, string[]>
    ],
    NonStreamingInputProps<number | string | boolean | number | string[] | Record<string, string[]>>
>;

export function useNestedAlias(
    options: UseLLMOptions<number | string | boolean | number | string[] | Record<string, string[]>> = {}
): UseLLMReturnType<
    number | string | boolean | number | string[] | Record<string, string[]>,
    [
        c: number | string | boolean | number | string[] | Record<string, string[]>
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<number | string | boolean | number | string[] | Record<string, string[]>, [
        c: number | string | boolean | number | string[] | Record<string, string[]>
      ]>(ServerActions.NestedAliasAction, options);
    }

    return useLLM<number | string | boolean | number | string[] | Record<string, string[]>, [
        c: number | string | boolean | number | string[] | Record<string, string[]>
    ]>(ServerActions.NestedAliasAction, options);
}

/**
 * A specialized hook for the OptionalTest_Function BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: (OptionalTest_ReturnType | null)[]
 * - Streaming Partial: RecursivePartialNull<(OptionalTest_ReturnType | null)[]>
 * - Streaming Final: (OptionalTest_ReturnType | null)[]
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useOptionalTest_Function();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to (OptionalTest_ReturnType | null)[]
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: (OptionalTest_ReturnType | null)[] | null
 *   partialData, // Type: RecursivePartialNull<(OptionalTest_ReturnType | null)[]> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useOptionalTest_Function({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<(OptionalTest_ReturnType | null)[]>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<(OptionalTest_ReturnType | null)[]>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useOptionalTest_Function(
    options?: StreamingInputProps<(OptionalTest_ReturnType | null)[]>
): UseLLMReturnType<
    (OptionalTest_ReturnType | null)[],
    [
        input: string
    ],
    StreamingInputProps<(OptionalTest_ReturnType | null)[]>
>;

export function useOptionalTest_Function(
    options?: NonStreamingInputProps<(OptionalTest_ReturnType | null)[]>
): UseLLMReturnType<
    (OptionalTest_ReturnType | null)[],
    [
        input: string
    ],
    NonStreamingInputProps<(OptionalTest_ReturnType | null)[]>
>;

export function useOptionalTest_Function(
    options: UseLLMOptions<(OptionalTest_ReturnType | null)[]> = {}
): UseLLMReturnType<
    (OptionalTest_ReturnType | null)[],
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<(OptionalTest_ReturnType | null)[], [
        input: string
      ]>(ServerActions.OptionalTest_FunctionAction, options);
    }

    return useLLM<(OptionalTest_ReturnType | null)[], [
        input: string
    ]>(ServerActions.OptionalTest_FunctionAction, options);
}

/**
 * A specialized hook for the PredictAge BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - name: string
 *
 *
 * Return Type:
 * - Non-streaming: FooAny
 * - Streaming Partial: RecursivePartialNull<FooAny>
 * - Streaming Final: FooAny
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = usePredictAge();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to FooAny
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: FooAny | null
 *   partialData, // Type: RecursivePartialNull<FooAny> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = usePredictAge({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<FooAny>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<FooAny>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       name: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       name: firstValue as string,
 *     }),
 *     mutate({
 *       name: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function usePredictAge(
    options?: StreamingInputProps<FooAny>
): UseLLMReturnType<
    FooAny,
    [
        name: string
    ],
    StreamingInputProps<FooAny>
>;

export function usePredictAge(
    options?: NonStreamingInputProps<FooAny>
): UseLLMReturnType<
    FooAny,
    [
        name: string
    ],
    NonStreamingInputProps<FooAny>
>;

export function usePredictAge(
    options: UseLLMOptions<FooAny> = {}
): UseLLMReturnType<
    FooAny,
    [
        name: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<FooAny, [
        name: string
      ]>(ServerActions.PredictAgeAction, options);
    }

    return useLLM<FooAny, [
        name: string
    ]>(ServerActions.PredictAgeAction, options);
}

/**
 * A specialized hook for the PredictAgeBare BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - inp: string
 *
 *
 * Return Type:
 * - Non-streaming: Checked<number,"too_big">
 * - Streaming Partial: RecursivePartialNull<Checked<number,"too_big">>
 * - Streaming Final: Checked<number,"too_big">
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = usePredictAgeBare();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Checked<number,"too_big">
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Checked<number,"too_big"> | null
 *   partialData, // Type: RecursivePartialNull<Checked<number,"too_big">> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = usePredictAgeBare({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Checked<number,"too_big">>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Checked<number,"too_big">>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       inp: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       inp: firstValue as string,
 *     }),
 *     mutate({
 *       inp: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function usePredictAgeBare(
    options?: StreamingInputProps<Checked<number,"too_big">>
): UseLLMReturnType<
    Checked<number,"too_big">,
    [
        inp: string
    ],
    StreamingInputProps<Checked<number,"too_big">>
>;

export function usePredictAgeBare(
    options?: NonStreamingInputProps<Checked<number,"too_big">>
): UseLLMReturnType<
    Checked<number,"too_big">,
    [
        inp: string
    ],
    NonStreamingInputProps<Checked<number,"too_big">>
>;

export function usePredictAgeBare(
    options: UseLLMOptions<Checked<number,"too_big">> = {}
): UseLLMReturnType<
    Checked<number,"too_big">,
    [
        inp: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Checked<number,"too_big">, [
        inp: string
      ]>(ServerActions.PredictAgeBareAction, options);
    }

    return useLLM<Checked<number,"too_big">, [
        inp: string
    ]>(ServerActions.PredictAgeBareAction, options);
}

/**
 * A specialized hook for the PrimitiveAlias BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - p: number | string | boolean | number
 *
 *
 * Return Type:
 * - Non-streaming: number | string | boolean | number
 * - Streaming Partial: RecursivePartialNull<number | string | boolean | number>
 * - Streaming Final: number | string | boolean | number
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = usePrimitiveAlias();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to number | string | boolean | number
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: number | string | boolean | number | null
 *   partialData, // Type: RecursivePartialNull<number | string | boolean | number> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = usePrimitiveAlias({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<number | string | boolean | number>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<number | string | boolean | number>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       p: someValue as number | string | boolean | number,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       p: firstValue as number | string | boolean | number,
 *     }),
 *     mutate({
 *       p: secondValue as number | string | boolean | number,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function usePrimitiveAlias(
    options?: StreamingInputProps<number | string | boolean | number>
): UseLLMReturnType<
    number | string | boolean | number,
    [
        p: number | string | boolean | number
    ],
    StreamingInputProps<number | string | boolean | number>
>;

export function usePrimitiveAlias(
    options?: NonStreamingInputProps<number | string | boolean | number>
): UseLLMReturnType<
    number | string | boolean | number,
    [
        p: number | string | boolean | number
    ],
    NonStreamingInputProps<number | string | boolean | number>
>;

export function usePrimitiveAlias(
    options: UseLLMOptions<number | string | boolean | number> = {}
): UseLLMReturnType<
    number | string | boolean | number,
    [
        p: number | string | boolean | number
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<number | string | boolean | number, [
        p: number | string | boolean | number
      ]>(ServerActions.PrimitiveAliasAction, options);
    }

    return useLLM<number | string | boolean | number, [
        p: number | string | boolean | number
    ]>(ServerActions.PrimitiveAliasAction, options);
}

/**
 * A specialized hook for the PromptTestClaude BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = usePromptTestClaude();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = usePromptTestClaude({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function usePromptTestClaude(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function usePromptTestClaude(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function usePromptTestClaude(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.PromptTestClaudeAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.PromptTestClaudeAction, options);
}

/**
 * A specialized hook for the PromptTestClaudeChat BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = usePromptTestClaudeChat();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = usePromptTestClaudeChat({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function usePromptTestClaudeChat(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function usePromptTestClaudeChat(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function usePromptTestClaudeChat(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.PromptTestClaudeChatAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.PromptTestClaudeChatAction, options);
}

/**
 * A specialized hook for the PromptTestClaudeChatNoSystem BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = usePromptTestClaudeChatNoSystem();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = usePromptTestClaudeChatNoSystem({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function usePromptTestClaudeChatNoSystem(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function usePromptTestClaudeChatNoSystem(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function usePromptTestClaudeChatNoSystem(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.PromptTestClaudeChatNoSystemAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.PromptTestClaudeChatNoSystemAction, options);
}

/**
 * A specialized hook for the PromptTestOpenAI BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = usePromptTestOpenAI();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = usePromptTestOpenAI({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function usePromptTestOpenAI(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function usePromptTestOpenAI(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function usePromptTestOpenAI(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.PromptTestOpenAIAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.PromptTestOpenAIAction, options);
}

/**
 * A specialized hook for the PromptTestOpenAIChat BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = usePromptTestOpenAIChat();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = usePromptTestOpenAIChat({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function usePromptTestOpenAIChat(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function usePromptTestOpenAIChat(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function usePromptTestOpenAIChat(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.PromptTestOpenAIChatAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.PromptTestOpenAIChatAction, options);
}

/**
 * A specialized hook for the PromptTestOpenAIChatNoSystem BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = usePromptTestOpenAIChatNoSystem();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = usePromptTestOpenAIChatNoSystem({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function usePromptTestOpenAIChatNoSystem(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function usePromptTestOpenAIChatNoSystem(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function usePromptTestOpenAIChatNoSystem(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.PromptTestOpenAIChatNoSystemAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.PromptTestOpenAIChatNoSystemAction, options);
}

/**
 * A specialized hook for the PromptTestStreaming BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = usePromptTestStreaming();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = usePromptTestStreaming({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function usePromptTestStreaming(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function usePromptTestStreaming(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function usePromptTestStreaming(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.PromptTestStreamingAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.PromptTestStreamingAction, options);
}

/**
 * A specialized hook for the RecursiveAliasCycle BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: RecAliasOne
 *
 *
 * Return Type:
 * - Non-streaming: RecAliasOne
 * - Streaming Partial: RecursivePartialNull<RecAliasOne>
 * - Streaming Final: RecAliasOne
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useRecursiveAliasCycle();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to RecAliasOne
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: RecAliasOne | null
 *   partialData, // Type: RecursivePartialNull<RecAliasOne> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useRecursiveAliasCycle({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<RecAliasOne>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<RecAliasOne>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as RecAliasOne,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as RecAliasOne,
 *     }),
 *     mutate({
 *       input: secondValue as RecAliasOne,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useRecursiveAliasCycle(
    options?: StreamingInputProps<RecAliasOne>
): UseLLMReturnType<
    RecAliasOne,
    [
        input: RecAliasOne
    ],
    StreamingInputProps<RecAliasOne>
>;

export function useRecursiveAliasCycle(
    options?: NonStreamingInputProps<RecAliasOne>
): UseLLMReturnType<
    RecAliasOne,
    [
        input: RecAliasOne
    ],
    NonStreamingInputProps<RecAliasOne>
>;

export function useRecursiveAliasCycle(
    options: UseLLMOptions<RecAliasOne> = {}
): UseLLMReturnType<
    RecAliasOne,
    [
        input: RecAliasOne
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<RecAliasOne, [
        input: RecAliasOne
      ]>(ServerActions.RecursiveAliasCycleAction, options);
    }

    return useLLM<RecAliasOne, [
        input: RecAliasOne
    ]>(ServerActions.RecursiveAliasCycleAction, options);
}

/**
 * A specialized hook for the RecursiveClassWithAliasIndirection BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - cls: NodeWithAliasIndirection
 *
 *
 * Return Type:
 * - Non-streaming: NodeWithAliasIndirection
 * - Streaming Partial: RecursivePartialNull<NodeWithAliasIndirection>
 * - Streaming Final: NodeWithAliasIndirection
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useRecursiveClassWithAliasIndirection();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to NodeWithAliasIndirection
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: NodeWithAliasIndirection | null
 *   partialData, // Type: RecursivePartialNull<NodeWithAliasIndirection> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useRecursiveClassWithAliasIndirection({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<NodeWithAliasIndirection>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<NodeWithAliasIndirection>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       cls: someValue as NodeWithAliasIndirection,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       cls: firstValue as NodeWithAliasIndirection,
 *     }),
 *     mutate({
 *       cls: secondValue as NodeWithAliasIndirection,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useRecursiveClassWithAliasIndirection(
    options?: StreamingInputProps<NodeWithAliasIndirection>
): UseLLMReturnType<
    NodeWithAliasIndirection,
    [
        cls: NodeWithAliasIndirection
    ],
    StreamingInputProps<NodeWithAliasIndirection>
>;

export function useRecursiveClassWithAliasIndirection(
    options?: NonStreamingInputProps<NodeWithAliasIndirection>
): UseLLMReturnType<
    NodeWithAliasIndirection,
    [
        cls: NodeWithAliasIndirection
    ],
    NonStreamingInputProps<NodeWithAliasIndirection>
>;

export function useRecursiveClassWithAliasIndirection(
    options: UseLLMOptions<NodeWithAliasIndirection> = {}
): UseLLMReturnType<
    NodeWithAliasIndirection,
    [
        cls: NodeWithAliasIndirection
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<NodeWithAliasIndirection, [
        cls: NodeWithAliasIndirection
      ]>(ServerActions.RecursiveClassWithAliasIndirectionAction, options);
    }

    return useLLM<NodeWithAliasIndirection, [
        cls: NodeWithAliasIndirection
    ]>(ServerActions.RecursiveClassWithAliasIndirectionAction, options);
}

/**
 * A specialized hook for the ReturnAliasWithMergedAttributes BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - money: Checked<number,"gt_ten">
 *
 *
 * Return Type:
 * - Non-streaming: Checked<number,"gt_ten">
 * - Streaming Partial: RecursivePartialNull<Checked<number,"gt_ten">>
 * - Streaming Final: Checked<number,"gt_ten">
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useReturnAliasWithMergedAttributes();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Checked<number,"gt_ten">
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Checked<number,"gt_ten"> | null
 *   partialData, // Type: RecursivePartialNull<Checked<number,"gt_ten">> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useReturnAliasWithMergedAttributes({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Checked<number,"gt_ten">>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Checked<number,"gt_ten">>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       money: someValue as Checked<number,"gt_ten">,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       money: firstValue as Checked<number,"gt_ten">,
 *     }),
 *     mutate({
 *       money: secondValue as Checked<number,"gt_ten">,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useReturnAliasWithMergedAttributes(
    options?: StreamingInputProps<Checked<number,"gt_ten">>
): UseLLMReturnType<
    Checked<number,"gt_ten">,
    [
        money: Checked<number,"gt_ten">
    ],
    StreamingInputProps<Checked<number,"gt_ten">>
>;

export function useReturnAliasWithMergedAttributes(
    options?: NonStreamingInputProps<Checked<number,"gt_ten">>
): UseLLMReturnType<
    Checked<number,"gt_ten">,
    [
        money: Checked<number,"gt_ten">
    ],
    NonStreamingInputProps<Checked<number,"gt_ten">>
>;

export function useReturnAliasWithMergedAttributes(
    options: UseLLMOptions<Checked<number,"gt_ten">> = {}
): UseLLMReturnType<
    Checked<number,"gt_ten">,
    [
        money: Checked<number,"gt_ten">
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Checked<number,"gt_ten">, [
        money: Checked<number,"gt_ten">
      ]>(ServerActions.ReturnAliasWithMergedAttributesAction, options);
    }

    return useLLM<Checked<number,"gt_ten">, [
        money: Checked<number,"gt_ten">
    ]>(ServerActions.ReturnAliasWithMergedAttributesAction, options);
}

/**
 * A specialized hook for the ReturnFailingAssert BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - inp: number
 *
 *
 * Return Type:
 * - Non-streaming: number
 * - Streaming Partial: RecursivePartialNull<number>
 * - Streaming Final: number
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useReturnFailingAssert();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to number
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: number | null
 *   partialData, // Type: RecursivePartialNull<number> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useReturnFailingAssert({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<number>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<number>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       inp: someValue as number,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       inp: firstValue as number,
 *     }),
 *     mutate({
 *       inp: secondValue as number,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useReturnFailingAssert(
    options?: StreamingInputProps<number>
): UseLLMReturnType<
    number,
    [
        inp: number
    ],
    StreamingInputProps<number>
>;

export function useReturnFailingAssert(
    options?: NonStreamingInputProps<number>
): UseLLMReturnType<
    number,
    [
        inp: number
    ],
    NonStreamingInputProps<number>
>;

export function useReturnFailingAssert(
    options: UseLLMOptions<number> = {}
): UseLLMReturnType<
    number,
    [
        inp: number
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<number, [
        inp: number
      ]>(ServerActions.ReturnFailingAssertAction, options);
    }

    return useLLM<number, [
        inp: number
    ]>(ServerActions.ReturnFailingAssertAction, options);
}

/**
 * A specialized hook for the ReturnMalformedConstraints BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - a: number
 *
 *
 * Return Type:
 * - Non-streaming: MalformedConstraints
 * - Streaming Partial: RecursivePartialNull<MalformedConstraints>
 * - Streaming Final: MalformedConstraints
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useReturnMalformedConstraints();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to MalformedConstraints
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: MalformedConstraints | null
 *   partialData, // Type: RecursivePartialNull<MalformedConstraints> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useReturnMalformedConstraints({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<MalformedConstraints>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<MalformedConstraints>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       a: someValue as number,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       a: firstValue as number,
 *     }),
 *     mutate({
 *       a: secondValue as number,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useReturnMalformedConstraints(
    options?: StreamingInputProps<MalformedConstraints>
): UseLLMReturnType<
    MalformedConstraints,
    [
        a: number
    ],
    StreamingInputProps<MalformedConstraints>
>;

export function useReturnMalformedConstraints(
    options?: NonStreamingInputProps<MalformedConstraints>
): UseLLMReturnType<
    MalformedConstraints,
    [
        a: number
    ],
    NonStreamingInputProps<MalformedConstraints>
>;

export function useReturnMalformedConstraints(
    options: UseLLMOptions<MalformedConstraints> = {}
): UseLLMReturnType<
    MalformedConstraints,
    [
        a: number
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<MalformedConstraints, [
        a: number
      ]>(ServerActions.ReturnMalformedConstraintsAction, options);
    }

    return useLLM<MalformedConstraints, [
        a: number
    ]>(ServerActions.ReturnMalformedConstraintsAction, options);
}

/**
 * A specialized hook for the SchemaDescriptions BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: Schema
 * - Streaming Partial: RecursivePartialNull<Schema>
 * - Streaming Final: Schema
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useSchemaDescriptions();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Schema
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Schema | null
 *   partialData, // Type: RecursivePartialNull<Schema> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useSchemaDescriptions({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Schema>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Schema>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useSchemaDescriptions(
    options?: StreamingInputProps<Schema>
): UseLLMReturnType<
    Schema,
    [
        input: string
    ],
    StreamingInputProps<Schema>
>;

export function useSchemaDescriptions(
    options?: NonStreamingInputProps<Schema>
): UseLLMReturnType<
    Schema,
    [
        input: string
    ],
    NonStreamingInputProps<Schema>
>;

export function useSchemaDescriptions(
    options: UseLLMOptions<Schema> = {}
): UseLLMReturnType<
    Schema,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Schema, [
        input: string
      ]>(ServerActions.SchemaDescriptionsAction, options);
    }

    return useLLM<Schema, [
        input: string
    ]>(ServerActions.SchemaDescriptionsAction, options);
}

/**
 * A specialized hook for the SimpleRecursiveListAlias BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: RecursiveListAlias
 *
 *
 * Return Type:
 * - Non-streaming: RecursiveListAlias
 * - Streaming Partial: RecursivePartialNull<RecursiveListAlias>
 * - Streaming Final: RecursiveListAlias
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useSimpleRecursiveListAlias();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to RecursiveListAlias
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: RecursiveListAlias | null
 *   partialData, // Type: RecursivePartialNull<RecursiveListAlias> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useSimpleRecursiveListAlias({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<RecursiveListAlias>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<RecursiveListAlias>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as RecursiveListAlias,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as RecursiveListAlias,
 *     }),
 *     mutate({
 *       input: secondValue as RecursiveListAlias,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useSimpleRecursiveListAlias(
    options?: StreamingInputProps<RecursiveListAlias>
): UseLLMReturnType<
    RecursiveListAlias,
    [
        input: RecursiveListAlias
    ],
    StreamingInputProps<RecursiveListAlias>
>;

export function useSimpleRecursiveListAlias(
    options?: NonStreamingInputProps<RecursiveListAlias>
): UseLLMReturnType<
    RecursiveListAlias,
    [
        input: RecursiveListAlias
    ],
    NonStreamingInputProps<RecursiveListAlias>
>;

export function useSimpleRecursiveListAlias(
    options: UseLLMOptions<RecursiveListAlias> = {}
): UseLLMReturnType<
    RecursiveListAlias,
    [
        input: RecursiveListAlias
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<RecursiveListAlias, [
        input: RecursiveListAlias
      ]>(ServerActions.SimpleRecursiveListAliasAction, options);
    }

    return useLLM<RecursiveListAlias, [
        input: RecursiveListAlias
    ]>(ServerActions.SimpleRecursiveListAliasAction, options);
}

/**
 * A specialized hook for the SimpleRecursiveMapAlias BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: RecursiveMapAlias
 *
 *
 * Return Type:
 * - Non-streaming: RecursiveMapAlias
 * - Streaming Partial: RecursivePartialNull<RecursiveMapAlias>
 * - Streaming Final: RecursiveMapAlias
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useSimpleRecursiveMapAlias();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to RecursiveMapAlias
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: RecursiveMapAlias | null
 *   partialData, // Type: RecursivePartialNull<RecursiveMapAlias> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useSimpleRecursiveMapAlias({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<RecursiveMapAlias>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<RecursiveMapAlias>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as RecursiveMapAlias,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as RecursiveMapAlias,
 *     }),
 *     mutate({
 *       input: secondValue as RecursiveMapAlias,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useSimpleRecursiveMapAlias(
    options?: StreamingInputProps<RecursiveMapAlias>
): UseLLMReturnType<
    RecursiveMapAlias,
    [
        input: RecursiveMapAlias
    ],
    StreamingInputProps<RecursiveMapAlias>
>;

export function useSimpleRecursiveMapAlias(
    options?: NonStreamingInputProps<RecursiveMapAlias>
): UseLLMReturnType<
    RecursiveMapAlias,
    [
        input: RecursiveMapAlias
    ],
    NonStreamingInputProps<RecursiveMapAlias>
>;

export function useSimpleRecursiveMapAlias(
    options: UseLLMOptions<RecursiveMapAlias> = {}
): UseLLMReturnType<
    RecursiveMapAlias,
    [
        input: RecursiveMapAlias
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<RecursiveMapAlias, [
        input: RecursiveMapAlias
      ]>(ServerActions.SimpleRecursiveMapAliasAction, options);
    }

    return useLLM<RecursiveMapAlias, [
        input: RecursiveMapAlias
    ]>(ServerActions.SimpleRecursiveMapAliasAction, options);
}

/**
 * A specialized hook for the StreamBigNumbers BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - digits: number
 *
 *
 * Return Type:
 * - Non-streaming: BigNumbers
 * - Streaming Partial: RecursivePartialNull<BigNumbers>
 * - Streaming Final: BigNumbers
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useStreamBigNumbers();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to BigNumbers
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: BigNumbers | null
 *   partialData, // Type: RecursivePartialNull<BigNumbers> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useStreamBigNumbers({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<BigNumbers>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<BigNumbers>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       digits: someValue as number,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       digits: firstValue as number,
 *     }),
 *     mutate({
 *       digits: secondValue as number,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useStreamBigNumbers(
    options?: StreamingInputProps<BigNumbers>
): UseLLMReturnType<
    BigNumbers,
    [
        digits: number
    ],
    StreamingInputProps<BigNumbers>
>;

export function useStreamBigNumbers(
    options?: NonStreamingInputProps<BigNumbers>
): UseLLMReturnType<
    BigNumbers,
    [
        digits: number
    ],
    NonStreamingInputProps<BigNumbers>
>;

export function useStreamBigNumbers(
    options: UseLLMOptions<BigNumbers> = {}
): UseLLMReturnType<
    BigNumbers,
    [
        digits: number
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<BigNumbers, [
        digits: number
      ]>(ServerActions.StreamBigNumbersAction, options);
    }

    return useLLM<BigNumbers, [
        digits: number
    ]>(ServerActions.StreamBigNumbersAction, options);
}

/**
 * A specialized hook for the StreamFailingAssertion BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - theme: string
 *
 * - length: number
 *
 *
 * Return Type:
 * - Non-streaming: TwoStoriesOneTitle
 * - Streaming Partial: RecursivePartialNull<TwoStoriesOneTitle>
 * - Streaming Final: TwoStoriesOneTitle
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useStreamFailingAssertion();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to TwoStoriesOneTitle
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: TwoStoriesOneTitle | null
 *   partialData, // Type: RecursivePartialNull<TwoStoriesOneTitle> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useStreamFailingAssertion({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<TwoStoriesOneTitle>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<TwoStoriesOneTitle>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       theme: someValue as string,  // Replace someValue with your data
 *       length: someValue as number,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       theme: firstValue as string,
 *       length: firstValue as number,
 *     }),
 *     mutate({
 *       theme: secondValue as string,
 *       length: secondValue as number,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useStreamFailingAssertion(
    options?: StreamingInputProps<TwoStoriesOneTitle>
): UseLLMReturnType<
    TwoStoriesOneTitle,
    [
        theme: string,
        length: number
    ],
    StreamingInputProps<TwoStoriesOneTitle>
>;

export function useStreamFailingAssertion(
    options?: NonStreamingInputProps<TwoStoriesOneTitle>
): UseLLMReturnType<
    TwoStoriesOneTitle,
    [
        theme: string,
        length: number
    ],
    NonStreamingInputProps<TwoStoriesOneTitle>
>;

export function useStreamFailingAssertion(
    options: UseLLMOptions<TwoStoriesOneTitle> = {}
): UseLLMReturnType<
    TwoStoriesOneTitle,
    [
        theme: string,
        length: number
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<TwoStoriesOneTitle, [
        theme: string,
        length: number
      ]>(ServerActions.StreamFailingAssertionAction, options);
    }

    return useLLM<TwoStoriesOneTitle, [
        theme: string,
        length: number
    ]>(ServerActions.StreamFailingAssertionAction, options);
}

/**
 * A specialized hook for the StreamOneBigNumber BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - digits: number
 *
 *
 * Return Type:
 * - Non-streaming: number
 * - Streaming Partial: RecursivePartialNull<number>
 * - Streaming Final: number
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useStreamOneBigNumber();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to number
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: number | null
 *   partialData, // Type: RecursivePartialNull<number> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useStreamOneBigNumber({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<number>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<number>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       digits: someValue as number,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       digits: firstValue as number,
 *     }),
 *     mutate({
 *       digits: secondValue as number,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useStreamOneBigNumber(
    options?: StreamingInputProps<number>
): UseLLMReturnType<
    number,
    [
        digits: number
    ],
    StreamingInputProps<number>
>;

export function useStreamOneBigNumber(
    options?: NonStreamingInputProps<number>
): UseLLMReturnType<
    number,
    [
        digits: number
    ],
    NonStreamingInputProps<number>
>;

export function useStreamOneBigNumber(
    options: UseLLMOptions<number> = {}
): UseLLMReturnType<
    number,
    [
        digits: number
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<number, [
        digits: number
      ]>(ServerActions.StreamOneBigNumberAction, options);
    }

    return useLLM<number, [
        digits: number
    ]>(ServerActions.StreamOneBigNumberAction, options);
}

/**
 * A specialized hook for the StreamUnionIntegers BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - digits: number
 *
 *
 * Return Type:
 * - Non-streaming: (number | string)[]
 * - Streaming Partial: RecursivePartialNull<(number | string)[]>
 * - Streaming Final: (number | string)[]
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useStreamUnionIntegers();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to (number | string)[]
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: (number | string)[] | null
 *   partialData, // Type: RecursivePartialNull<(number | string)[]> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useStreamUnionIntegers({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<(number | string)[]>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<(number | string)[]>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       digits: someValue as number,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       digits: firstValue as number,
 *     }),
 *     mutate({
 *       digits: secondValue as number,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useStreamUnionIntegers(
    options?: StreamingInputProps<(number | string)[]>
): UseLLMReturnType<
    (number | string)[],
    [
        digits: number
    ],
    StreamingInputProps<(number | string)[]>
>;

export function useStreamUnionIntegers(
    options?: NonStreamingInputProps<(number | string)[]>
): UseLLMReturnType<
    (number | string)[],
    [
        digits: number
    ],
    NonStreamingInputProps<(number | string)[]>
>;

export function useStreamUnionIntegers(
    options: UseLLMOptions<(number | string)[]> = {}
): UseLLMReturnType<
    (number | string)[],
    [
        digits: number
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<(number | string)[], [
        digits: number
      ]>(ServerActions.StreamUnionIntegersAction, options);
    }

    return useLLM<(number | string)[], [
        digits: number
    ]>(ServerActions.StreamUnionIntegersAction, options);
}

/**
 * A specialized hook for the StreamingCompoundNumbers BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - digits: number
 *
 * - yapping: boolean
 *
 *
 * Return Type:
 * - Non-streaming: CompoundBigNumbers
 * - Streaming Partial: RecursivePartialNull<CompoundBigNumbers>
 * - Streaming Final: CompoundBigNumbers
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useStreamingCompoundNumbers();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to CompoundBigNumbers
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: CompoundBigNumbers | null
 *   partialData, // Type: RecursivePartialNull<CompoundBigNumbers> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useStreamingCompoundNumbers({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<CompoundBigNumbers>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<CompoundBigNumbers>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       digits: someValue as number,  // Replace someValue with your data
 *       yapping: someValue as boolean,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       digits: firstValue as number,
 *       yapping: firstValue as boolean,
 *     }),
 *     mutate({
 *       digits: secondValue as number,
 *       yapping: secondValue as boolean,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useStreamingCompoundNumbers(
    options?: StreamingInputProps<CompoundBigNumbers>
): UseLLMReturnType<
    CompoundBigNumbers,
    [
        digits: number,
        yapping: boolean
    ],
    StreamingInputProps<CompoundBigNumbers>
>;

export function useStreamingCompoundNumbers(
    options?: NonStreamingInputProps<CompoundBigNumbers>
): UseLLMReturnType<
    CompoundBigNumbers,
    [
        digits: number,
        yapping: boolean
    ],
    NonStreamingInputProps<CompoundBigNumbers>
>;

export function useStreamingCompoundNumbers(
    options: UseLLMOptions<CompoundBigNumbers> = {}
): UseLLMReturnType<
    CompoundBigNumbers,
    [
        digits: number,
        yapping: boolean
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<CompoundBigNumbers, [
        digits: number,
        yapping: boolean
      ]>(ServerActions.StreamingCompoundNumbersAction, options);
    }

    return useLLM<CompoundBigNumbers, [
        digits: number,
        yapping: boolean
    ]>(ServerActions.StreamingCompoundNumbersAction, options);
}

/**
 * A specialized hook for the TestAnthropic BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestAnthropic();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestAnthropic({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestAnthropic(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function useTestAnthropic(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function useTestAnthropic(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.TestAnthropicAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.TestAnthropicAction, options);
}

/**
 * A specialized hook for the TestAnthropicShorthand BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestAnthropicShorthand();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestAnthropicShorthand({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestAnthropicShorthand(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function useTestAnthropicShorthand(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function useTestAnthropicShorthand(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.TestAnthropicShorthandAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.TestAnthropicShorthandAction, options);
}

/**
 * A specialized hook for the TestAws BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestAws();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestAws({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestAws(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function useTestAws(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function useTestAws(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.TestAwsAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.TestAwsAction, options);
}

/**
 * A specialized hook for the TestAwsInvalidAccessKey BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestAwsInvalidAccessKey();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestAwsInvalidAccessKey({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestAwsInvalidAccessKey(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function useTestAwsInvalidAccessKey(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function useTestAwsInvalidAccessKey(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.TestAwsInvalidAccessKeyAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.TestAwsInvalidAccessKeyAction, options);
}

/**
 * A specialized hook for the TestAwsInvalidProfile BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestAwsInvalidProfile();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestAwsInvalidProfile({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestAwsInvalidProfile(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function useTestAwsInvalidProfile(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function useTestAwsInvalidProfile(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.TestAwsInvalidProfileAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.TestAwsInvalidProfileAction, options);
}

/**
 * A specialized hook for the TestAwsInvalidRegion BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestAwsInvalidRegion();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestAwsInvalidRegion({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestAwsInvalidRegion(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function useTestAwsInvalidRegion(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function useTestAwsInvalidRegion(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.TestAwsInvalidRegionAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.TestAwsInvalidRegionAction, options);
}

/**
 * A specialized hook for the TestAwsInvalidSessionToken BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestAwsInvalidSessionToken();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestAwsInvalidSessionToken({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestAwsInvalidSessionToken(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function useTestAwsInvalidSessionToken(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function useTestAwsInvalidSessionToken(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.TestAwsInvalidSessionTokenAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.TestAwsInvalidSessionTokenAction, options);
}

/**
 * A specialized hook for the TestAzure BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestAzure();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestAzure({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestAzure(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function useTestAzure(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function useTestAzure(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.TestAzureAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.TestAzureAction, options);
}

/**
 * A specialized hook for the TestAzureFailure BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestAzureFailure();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestAzureFailure({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestAzureFailure(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function useTestAzureFailure(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function useTestAzureFailure(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.TestAzureFailureAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.TestAzureFailureAction, options);
}

/**
 * A specialized hook for the TestCaching BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 * - not_cached: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestCaching();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestCaching({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *       not_cached: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *       not_cached: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *       not_cached: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestCaching(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string,
        not_cached: string
    ],
    StreamingInputProps<string>
>;

export function useTestCaching(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string,
        not_cached: string
    ],
    NonStreamingInputProps<string>
>;

export function useTestCaching(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string,
        not_cached: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string,
        not_cached: string
      ]>(ServerActions.TestCachingAction, options);
    }

    return useLLM<string, [
        input: string,
        not_cached: string
    ]>(ServerActions.TestCachingAction, options);
}

/**
 * A specialized hook for the TestFallbackClient BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestFallbackClient();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestFallbackClient({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *     }),
 *     mutate({
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestFallbackClient(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
    ],
    StreamingInputProps<string>
>;

export function useTestFallbackClient(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
    ],
    NonStreamingInputProps<string>
>;

export function useTestFallbackClient(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
      ]>(ServerActions.TestFallbackClientAction, options);
    }

    return useLLM<string, [
    ]>(ServerActions.TestFallbackClientAction, options);
}

/**
 * A specialized hook for the TestFallbackToShorthand BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestFallbackToShorthand();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestFallbackToShorthand({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestFallbackToShorthand(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function useTestFallbackToShorthand(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function useTestFallbackToShorthand(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.TestFallbackToShorthandAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.TestFallbackToShorthandAction, options);
}

/**
 * A specialized hook for the TestFnNamedArgsSingleBool BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - myBool: boolean
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestFnNamedArgsSingleBool();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestFnNamedArgsSingleBool({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       myBool: someValue as boolean,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       myBool: firstValue as boolean,
 *     }),
 *     mutate({
 *       myBool: secondValue as boolean,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestFnNamedArgsSingleBool(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myBool: boolean
    ],
    StreamingInputProps<string>
>;

export function useTestFnNamedArgsSingleBool(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myBool: boolean
    ],
    NonStreamingInputProps<string>
>;

export function useTestFnNamedArgsSingleBool(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        myBool: boolean
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        myBool: boolean
      ]>(ServerActions.TestFnNamedArgsSingleBoolAction, options);
    }

    return useLLM<string, [
        myBool: boolean
    ]>(ServerActions.TestFnNamedArgsSingleBoolAction, options);
}

/**
 * A specialized hook for the TestFnNamedArgsSingleClass BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - myArg: NamedArgsSingleClass
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestFnNamedArgsSingleClass();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestFnNamedArgsSingleClass({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       myArg: someValue as NamedArgsSingleClass,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       myArg: firstValue as NamedArgsSingleClass,
 *     }),
 *     mutate({
 *       myArg: secondValue as NamedArgsSingleClass,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestFnNamedArgsSingleClass(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myArg: NamedArgsSingleClass
    ],
    StreamingInputProps<string>
>;

export function useTestFnNamedArgsSingleClass(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myArg: NamedArgsSingleClass
    ],
    NonStreamingInputProps<string>
>;

export function useTestFnNamedArgsSingleClass(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        myArg: NamedArgsSingleClass
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        myArg: NamedArgsSingleClass
      ]>(ServerActions.TestFnNamedArgsSingleClassAction, options);
    }

    return useLLM<string, [
        myArg: NamedArgsSingleClass
    ]>(ServerActions.TestFnNamedArgsSingleClassAction, options);
}

/**
 * A specialized hook for the TestFnNamedArgsSingleEnumList BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - myArg: NamedArgsSingleEnumList[]
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestFnNamedArgsSingleEnumList();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestFnNamedArgsSingleEnumList({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       myArg: someValue as NamedArgsSingleEnumList[],  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       myArg: firstValue as NamedArgsSingleEnumList[],
 *     }),
 *     mutate({
 *       myArg: secondValue as NamedArgsSingleEnumList[],
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestFnNamedArgsSingleEnumList(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myArg: NamedArgsSingleEnumList[]
    ],
    StreamingInputProps<string>
>;

export function useTestFnNamedArgsSingleEnumList(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myArg: NamedArgsSingleEnumList[]
    ],
    NonStreamingInputProps<string>
>;

export function useTestFnNamedArgsSingleEnumList(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        myArg: NamedArgsSingleEnumList[]
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        myArg: NamedArgsSingleEnumList[]
      ]>(ServerActions.TestFnNamedArgsSingleEnumListAction, options);
    }

    return useLLM<string, [
        myArg: NamedArgsSingleEnumList[]
    ]>(ServerActions.TestFnNamedArgsSingleEnumListAction, options);
}

/**
 * A specialized hook for the TestFnNamedArgsSingleFloat BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - myFloat: number
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestFnNamedArgsSingleFloat();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestFnNamedArgsSingleFloat({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       myFloat: someValue as number,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       myFloat: firstValue as number,
 *     }),
 *     mutate({
 *       myFloat: secondValue as number,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestFnNamedArgsSingleFloat(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myFloat: number
    ],
    StreamingInputProps<string>
>;

export function useTestFnNamedArgsSingleFloat(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myFloat: number
    ],
    NonStreamingInputProps<string>
>;

export function useTestFnNamedArgsSingleFloat(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        myFloat: number
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        myFloat: number
      ]>(ServerActions.TestFnNamedArgsSingleFloatAction, options);
    }

    return useLLM<string, [
        myFloat: number
    ]>(ServerActions.TestFnNamedArgsSingleFloatAction, options);
}

/**
 * A specialized hook for the TestFnNamedArgsSingleInt BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - myInt: number
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestFnNamedArgsSingleInt();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestFnNamedArgsSingleInt({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       myInt: someValue as number,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       myInt: firstValue as number,
 *     }),
 *     mutate({
 *       myInt: secondValue as number,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestFnNamedArgsSingleInt(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myInt: number
    ],
    StreamingInputProps<string>
>;

export function useTestFnNamedArgsSingleInt(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myInt: number
    ],
    NonStreamingInputProps<string>
>;

export function useTestFnNamedArgsSingleInt(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        myInt: number
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        myInt: number
      ]>(ServerActions.TestFnNamedArgsSingleIntAction, options);
    }

    return useLLM<string, [
        myInt: number
    ]>(ServerActions.TestFnNamedArgsSingleIntAction, options);
}

/**
 * A specialized hook for the TestFnNamedArgsSingleMapStringToClass BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - myMap: Record<string, StringToClassEntry>
 *
 *
 * Return Type:
 * - Non-streaming: Record<string, StringToClassEntry>
 * - Streaming Partial: RecursivePartialNull<Record<string, StringToClassEntry>>
 * - Streaming Final: Record<string, StringToClassEntry>
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestFnNamedArgsSingleMapStringToClass();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Record<string, StringToClassEntry>
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Record<string, StringToClassEntry> | null
 *   partialData, // Type: RecursivePartialNull<Record<string, StringToClassEntry>> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestFnNamedArgsSingleMapStringToClass({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Record<string, StringToClassEntry>>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Record<string, StringToClassEntry>>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       myMap: someValue as Record<string, StringToClassEntry>,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       myMap: firstValue as Record<string, StringToClassEntry>,
 *     }),
 *     mutate({
 *       myMap: secondValue as Record<string, StringToClassEntry>,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestFnNamedArgsSingleMapStringToClass(
    options?: StreamingInputProps<Record<string, StringToClassEntry>>
): UseLLMReturnType<
    Record<string, StringToClassEntry>,
    [
        myMap: Record<string, StringToClassEntry>
    ],
    StreamingInputProps<Record<string, StringToClassEntry>>
>;

export function useTestFnNamedArgsSingleMapStringToClass(
    options?: NonStreamingInputProps<Record<string, StringToClassEntry>>
): UseLLMReturnType<
    Record<string, StringToClassEntry>,
    [
        myMap: Record<string, StringToClassEntry>
    ],
    NonStreamingInputProps<Record<string, StringToClassEntry>>
>;

export function useTestFnNamedArgsSingleMapStringToClass(
    options: UseLLMOptions<Record<string, StringToClassEntry>> = {}
): UseLLMReturnType<
    Record<string, StringToClassEntry>,
    [
        myMap: Record<string, StringToClassEntry>
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Record<string, StringToClassEntry>, [
        myMap: Record<string, StringToClassEntry>
      ]>(ServerActions.TestFnNamedArgsSingleMapStringToClassAction, options);
    }

    return useLLM<Record<string, StringToClassEntry>, [
        myMap: Record<string, StringToClassEntry>
    ]>(ServerActions.TestFnNamedArgsSingleMapStringToClassAction, options);
}

/**
 * A specialized hook for the TestFnNamedArgsSingleMapStringToMap BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - myMap: Record<string, Record<string, string>>
 *
 *
 * Return Type:
 * - Non-streaming: Record<string, Record<string, string>>
 * - Streaming Partial: RecursivePartialNull<Record<string, Record<string, string>>>
 * - Streaming Final: Record<string, Record<string, string>>
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestFnNamedArgsSingleMapStringToMap();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Record<string, Record<string, string>>
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Record<string, Record<string, string>> | null
 *   partialData, // Type: RecursivePartialNull<Record<string, Record<string, string>>> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestFnNamedArgsSingleMapStringToMap({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Record<string, Record<string, string>>>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Record<string, Record<string, string>>>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       myMap: someValue as Record<string, Record<string, string>>,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       myMap: firstValue as Record<string, Record<string, string>>,
 *     }),
 *     mutate({
 *       myMap: secondValue as Record<string, Record<string, string>>,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestFnNamedArgsSingleMapStringToMap(
    options?: StreamingInputProps<Record<string, Record<string, string>>>
): UseLLMReturnType<
    Record<string, Record<string, string>>,
    [
        myMap: Record<string, Record<string, string>>
    ],
    StreamingInputProps<Record<string, Record<string, string>>>
>;

export function useTestFnNamedArgsSingleMapStringToMap(
    options?: NonStreamingInputProps<Record<string, Record<string, string>>>
): UseLLMReturnType<
    Record<string, Record<string, string>>,
    [
        myMap: Record<string, Record<string, string>>
    ],
    NonStreamingInputProps<Record<string, Record<string, string>>>
>;

export function useTestFnNamedArgsSingleMapStringToMap(
    options: UseLLMOptions<Record<string, Record<string, string>>> = {}
): UseLLMReturnType<
    Record<string, Record<string, string>>,
    [
        myMap: Record<string, Record<string, string>>
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Record<string, Record<string, string>>, [
        myMap: Record<string, Record<string, string>>
      ]>(ServerActions.TestFnNamedArgsSingleMapStringToMapAction, options);
    }

    return useLLM<Record<string, Record<string, string>>, [
        myMap: Record<string, Record<string, string>>
    ]>(ServerActions.TestFnNamedArgsSingleMapStringToMapAction, options);
}

/**
 * A specialized hook for the TestFnNamedArgsSingleMapStringToString BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - myMap: Record<string, string>
 *
 *
 * Return Type:
 * - Non-streaming: Record<string, string>
 * - Streaming Partial: RecursivePartialNull<Record<string, string>>
 * - Streaming Final: Record<string, string>
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestFnNamedArgsSingleMapStringToString();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to Record<string, string>
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: Record<string, string> | null
 *   partialData, // Type: RecursivePartialNull<Record<string, string>> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestFnNamedArgsSingleMapStringToString({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<Record<string, string>>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<Record<string, string>>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       myMap: someValue as Record<string, string>,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       myMap: firstValue as Record<string, string>,
 *     }),
 *     mutate({
 *       myMap: secondValue as Record<string, string>,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestFnNamedArgsSingleMapStringToString(
    options?: StreamingInputProps<Record<string, string>>
): UseLLMReturnType<
    Record<string, string>,
    [
        myMap: Record<string, string>
    ],
    StreamingInputProps<Record<string, string>>
>;

export function useTestFnNamedArgsSingleMapStringToString(
    options?: NonStreamingInputProps<Record<string, string>>
): UseLLMReturnType<
    Record<string, string>,
    [
        myMap: Record<string, string>
    ],
    NonStreamingInputProps<Record<string, string>>
>;

export function useTestFnNamedArgsSingleMapStringToString(
    options: UseLLMOptions<Record<string, string>> = {}
): UseLLMReturnType<
    Record<string, string>,
    [
        myMap: Record<string, string>
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<Record<string, string>, [
        myMap: Record<string, string>
      ]>(ServerActions.TestFnNamedArgsSingleMapStringToStringAction, options);
    }

    return useLLM<Record<string, string>, [
        myMap: Record<string, string>
    ]>(ServerActions.TestFnNamedArgsSingleMapStringToStringAction, options);
}

/**
 * A specialized hook for the TestFnNamedArgsSingleString BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - myString: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestFnNamedArgsSingleString();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestFnNamedArgsSingleString({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       myString: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       myString: firstValue as string,
 *     }),
 *     mutate({
 *       myString: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestFnNamedArgsSingleString(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myString: string
    ],
    StreamingInputProps<string>
>;

export function useTestFnNamedArgsSingleString(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myString: string
    ],
    NonStreamingInputProps<string>
>;

export function useTestFnNamedArgsSingleString(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        myString: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        myString: string
      ]>(ServerActions.TestFnNamedArgsSingleStringAction, options);
    }

    return useLLM<string, [
        myString: string
    ]>(ServerActions.TestFnNamedArgsSingleStringAction, options);
}

/**
 * A specialized hook for the TestFnNamedArgsSingleStringArray BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - myStringArray: string[]
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestFnNamedArgsSingleStringArray();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestFnNamedArgsSingleStringArray({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       myStringArray: someValue as string[],  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       myStringArray: firstValue as string[],
 *     }),
 *     mutate({
 *       myStringArray: secondValue as string[],
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestFnNamedArgsSingleStringArray(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myStringArray: string[]
    ],
    StreamingInputProps<string>
>;

export function useTestFnNamedArgsSingleStringArray(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myStringArray: string[]
    ],
    NonStreamingInputProps<string>
>;

export function useTestFnNamedArgsSingleStringArray(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        myStringArray: string[]
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        myStringArray: string[]
      ]>(ServerActions.TestFnNamedArgsSingleStringArrayAction, options);
    }

    return useLLM<string, [
        myStringArray: string[]
    ]>(ServerActions.TestFnNamedArgsSingleStringArrayAction, options);
}

/**
 * A specialized hook for the TestFnNamedArgsSingleStringList BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - myArg: string[]
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestFnNamedArgsSingleStringList();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestFnNamedArgsSingleStringList({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       myArg: someValue as string[],  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       myArg: firstValue as string[],
 *     }),
 *     mutate({
 *       myArg: secondValue as string[],
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestFnNamedArgsSingleStringList(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myArg: string[]
    ],
    StreamingInputProps<string>
>;

export function useTestFnNamedArgsSingleStringList(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myArg: string[]
    ],
    NonStreamingInputProps<string>
>;

export function useTestFnNamedArgsSingleStringList(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        myArg: string[]
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        myArg: string[]
      ]>(ServerActions.TestFnNamedArgsSingleStringListAction, options);
    }

    return useLLM<string, [
        myArg: string[]
    ]>(ServerActions.TestFnNamedArgsSingleStringListAction, options);
}

/**
 * A specialized hook for the TestGemini BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestGemini();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestGemini({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestGemini(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function useTestGemini(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function useTestGemini(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.TestGeminiAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.TestGeminiAction, options);
}

/**
 * A specialized hook for the TestImageInput BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - img: Image
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestImageInput();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestImageInput({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       img: someValue as Image,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       img: firstValue as Image,
 *     }),
 *     mutate({
 *       img: secondValue as Image,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestImageInput(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        img: Image
    ],
    StreamingInputProps<string>
>;

export function useTestImageInput(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        img: Image
    ],
    NonStreamingInputProps<string>
>;

export function useTestImageInput(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        img: Image
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        img: Image
      ]>(ServerActions.TestImageInputAction, options);
    }

    return useLLM<string, [
        img: Image
    ]>(ServerActions.TestImageInputAction, options);
}

/**
 * A specialized hook for the TestImageInputAnthropic BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - img: Image
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestImageInputAnthropic();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestImageInputAnthropic({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       img: someValue as Image,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       img: firstValue as Image,
 *     }),
 *     mutate({
 *       img: secondValue as Image,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestImageInputAnthropic(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        img: Image
    ],
    StreamingInputProps<string>
>;

export function useTestImageInputAnthropic(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        img: Image
    ],
    NonStreamingInputProps<string>
>;

export function useTestImageInputAnthropic(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        img: Image
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        img: Image
      ]>(ServerActions.TestImageInputAnthropicAction, options);
    }

    return useLLM<string, [
        img: Image
    ]>(ServerActions.TestImageInputAnthropicAction, options);
}

/**
 * A specialized hook for the TestImageListInput BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - imgs: Image[]
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestImageListInput();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestImageListInput({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       imgs: someValue as Image[],  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       imgs: firstValue as Image[],
 *     }),
 *     mutate({
 *       imgs: secondValue as Image[],
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestImageListInput(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        imgs: Image[]
    ],
    StreamingInputProps<string>
>;

export function useTestImageListInput(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        imgs: Image[]
    ],
    NonStreamingInputProps<string>
>;

export function useTestImageListInput(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        imgs: Image[]
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        imgs: Image[]
      ]>(ServerActions.TestImageListInputAction, options);
    }

    return useLLM<string, [
        imgs: Image[]
    ]>(ServerActions.TestImageListInputAction, options);
}

/**
 * A specialized hook for the TestMulticlassNamedArgs BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - myArg: NamedArgsSingleClass
 *
 * - myArg2: NamedArgsSingleClass
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestMulticlassNamedArgs();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestMulticlassNamedArgs({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       myArg: someValue as NamedArgsSingleClass,  // Replace someValue with your data
 *       myArg2: someValue as NamedArgsSingleClass,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       myArg: firstValue as NamedArgsSingleClass,
 *       myArg2: firstValue as NamedArgsSingleClass,
 *     }),
 *     mutate({
 *       myArg: secondValue as NamedArgsSingleClass,
 *       myArg2: secondValue as NamedArgsSingleClass,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestMulticlassNamedArgs(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myArg: NamedArgsSingleClass,
        myArg2: NamedArgsSingleClass
    ],
    StreamingInputProps<string>
>;

export function useTestMulticlassNamedArgs(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myArg: NamedArgsSingleClass,
        myArg2: NamedArgsSingleClass
    ],
    NonStreamingInputProps<string>
>;

export function useTestMulticlassNamedArgs(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        myArg: NamedArgsSingleClass,
        myArg2: NamedArgsSingleClass
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        myArg: NamedArgsSingleClass,
        myArg2: NamedArgsSingleClass
      ]>(ServerActions.TestMulticlassNamedArgsAction, options);
    }

    return useLLM<string, [
        myArg: NamedArgsSingleClass,
        myArg2: NamedArgsSingleClass
    ]>(ServerActions.TestMulticlassNamedArgsAction, options);
}

/**
 * A specialized hook for the TestNamedArgsLiteralBool BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - myBool: true
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestNamedArgsLiteralBool();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestNamedArgsLiteralBool({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       myBool: someValue as true,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       myBool: firstValue as true,
 *     }),
 *     mutate({
 *       myBool: secondValue as true,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestNamedArgsLiteralBool(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myBool: true
    ],
    StreamingInputProps<string>
>;

export function useTestNamedArgsLiteralBool(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myBool: true
    ],
    NonStreamingInputProps<string>
>;

export function useTestNamedArgsLiteralBool(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        myBool: true
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        myBool: true
      ]>(ServerActions.TestNamedArgsLiteralBoolAction, options);
    }

    return useLLM<string, [
        myBool: true
    ]>(ServerActions.TestNamedArgsLiteralBoolAction, options);
}

/**
 * A specialized hook for the TestNamedArgsLiteralInt BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - myInt: 1
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestNamedArgsLiteralInt();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestNamedArgsLiteralInt({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       myInt: someValue as 1,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       myInt: firstValue as 1,
 *     }),
 *     mutate({
 *       myInt: secondValue as 1,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestNamedArgsLiteralInt(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myInt: 1
    ],
    StreamingInputProps<string>
>;

export function useTestNamedArgsLiteralInt(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myInt: 1
    ],
    NonStreamingInputProps<string>
>;

export function useTestNamedArgsLiteralInt(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        myInt: 1
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        myInt: 1
      ]>(ServerActions.TestNamedArgsLiteralIntAction, options);
    }

    return useLLM<string, [
        myInt: 1
    ]>(ServerActions.TestNamedArgsLiteralIntAction, options);
}

/**
 * A specialized hook for the TestNamedArgsLiteralString BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - myString: "My String"
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestNamedArgsLiteralString();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestNamedArgsLiteralString({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       myString: someValue as "My String",  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       myString: firstValue as "My String",
 *     }),
 *     mutate({
 *       myString: secondValue as "My String",
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestNamedArgsLiteralString(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myString: "My String"
    ],
    StreamingInputProps<string>
>;

export function useTestNamedArgsLiteralString(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        myString: "My String"
    ],
    NonStreamingInputProps<string>
>;

export function useTestNamedArgsLiteralString(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        myString: "My String"
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        myString: "My String"
      ]>(ServerActions.TestNamedArgsLiteralStringAction, options);
    }

    return useLLM<string, [
        myString: "My String"
    ]>(ServerActions.TestNamedArgsLiteralStringAction, options);
}

/**
 * A specialized hook for the TestOllama BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestOllama();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestOllama({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestOllama(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function useTestOllama(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function useTestOllama(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.TestOllamaAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.TestOllamaAction, options);
}

/**
 * A specialized hook for the TestOpenAILegacyProvider BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestOpenAILegacyProvider();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestOpenAILegacyProvider({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestOpenAILegacyProvider(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function useTestOpenAILegacyProvider(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function useTestOpenAILegacyProvider(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.TestOpenAILegacyProviderAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.TestOpenAILegacyProviderAction, options);
}

/**
 * A specialized hook for the TestOpenAIShorthand BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestOpenAIShorthand();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestOpenAIShorthand({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestOpenAIShorthand(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function useTestOpenAIShorthand(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function useTestOpenAIShorthand(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.TestOpenAIShorthandAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.TestOpenAIShorthandAction, options);
}

/**
 * A specialized hook for the TestRetryConstant BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestRetryConstant();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestRetryConstant({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *     }),
 *     mutate({
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestRetryConstant(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
    ],
    StreamingInputProps<string>
>;

export function useTestRetryConstant(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
    ],
    NonStreamingInputProps<string>
>;

export function useTestRetryConstant(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
      ]>(ServerActions.TestRetryConstantAction, options);
    }

    return useLLM<string, [
    ]>(ServerActions.TestRetryConstantAction, options);
}

/**
 * A specialized hook for the TestRetryExponential BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestRetryExponential();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestRetryExponential({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *     }),
 *     mutate({
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestRetryExponential(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
    ],
    StreamingInputProps<string>
>;

export function useTestRetryExponential(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
    ],
    NonStreamingInputProps<string>
>;

export function useTestRetryExponential(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
      ]>(ServerActions.TestRetryExponentialAction, options);
    }

    return useLLM<string, [
    ]>(ServerActions.TestRetryExponentialAction, options);
}

/**
 * A specialized hook for the TestSingleFallbackClient BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestSingleFallbackClient();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestSingleFallbackClient({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *     }),
 *     mutate({
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestSingleFallbackClient(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
    ],
    StreamingInputProps<string>
>;

export function useTestSingleFallbackClient(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
    ],
    NonStreamingInputProps<string>
>;

export function useTestSingleFallbackClient(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
      ]>(ServerActions.TestSingleFallbackClientAction, options);
    }

    return useLLM<string, [
    ]>(ServerActions.TestSingleFallbackClientAction, options);
}

/**
 * A specialized hook for the TestUniverseQuestion BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - question: UniverseQuestionInput
 *
 *
 * Return Type:
 * - Non-streaming: UniverseQuestion
 * - Streaming Partial: RecursivePartialNull<UniverseQuestion>
 * - Streaming Final: UniverseQuestion
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestUniverseQuestion();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to UniverseQuestion
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: UniverseQuestion | null
 *   partialData, // Type: RecursivePartialNull<UniverseQuestion> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestUniverseQuestion({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<UniverseQuestion>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<UniverseQuestion>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       question: someValue as UniverseQuestionInput,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       question: firstValue as UniverseQuestionInput,
 *     }),
 *     mutate({
 *       question: secondValue as UniverseQuestionInput,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestUniverseQuestion(
    options?: StreamingInputProps<UniverseQuestion>
): UseLLMReturnType<
    UniverseQuestion,
    [
        question: UniverseQuestionInput
    ],
    StreamingInputProps<UniverseQuestion>
>;

export function useTestUniverseQuestion(
    options?: NonStreamingInputProps<UniverseQuestion>
): UseLLMReturnType<
    UniverseQuestion,
    [
        question: UniverseQuestionInput
    ],
    NonStreamingInputProps<UniverseQuestion>
>;

export function useTestUniverseQuestion(
    options: UseLLMOptions<UniverseQuestion> = {}
): UseLLMReturnType<
    UniverseQuestion,
    [
        question: UniverseQuestionInput
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<UniverseQuestion, [
        question: UniverseQuestionInput
      ]>(foo, options);
    }

    return useLLM<UniverseQuestion, [
        question: UniverseQuestionInput
    ]>(foo, options);
}

/**
 * A specialized hook for the TestVertex BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string
 *
 *
 * Return Type:
 * - Non-streaming: string
 * - Streaming Partial: RecursivePartialNull<string>
 * - Streaming Final: string
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useTestVertex();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to string
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: string | null
 *   partialData, // Type: RecursivePartialNull<string> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useTestVertex({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<string>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<string>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string,
 *     }),
 *     mutate({
 *       input: secondValue as string,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useTestVertex(
    options?: StreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    StreamingInputProps<string>
>;

export function useTestVertex(
    options?: NonStreamingInputProps<string>
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    NonStreamingInputProps<string>
>;

export function useTestVertex(
    options: UseLLMOptions<string> = {}
): UseLLMReturnType<
    string,
    [
        input: string
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<string, [
        input: string
      ]>(ServerActions.TestVertexAction, options);
    }

    return useLLM<string, [
        input: string
    ]>(ServerActions.TestVertexAction, options);
}

/**
 * A specialized hook for the UnionTest_Function BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - input: string | boolean
 *
 *
 * Return Type:
 * - Non-streaming: UnionTest_ReturnType
 * - Streaming Partial: RecursivePartialNull<UnionTest_ReturnType>
 * - Streaming Final: UnionTest_ReturnType
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useUnionTest_Function();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to UnionTest_ReturnType
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: UnionTest_ReturnType | null
 *   partialData, // Type: RecursivePartialNull<UnionTest_ReturnType> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useUnionTest_Function({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<UnionTest_ReturnType>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<UnionTest_ReturnType>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       input: someValue as string | boolean,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       input: firstValue as string | boolean,
 *     }),
 *     mutate({
 *       input: secondValue as string | boolean,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useUnionTest_Function(
    options?: StreamingInputProps<UnionTest_ReturnType>
): UseLLMReturnType<
    UnionTest_ReturnType,
    [
        input: string | boolean
    ],
    StreamingInputProps<UnionTest_ReturnType>
>;

export function useUnionTest_Function(
    options?: NonStreamingInputProps<UnionTest_ReturnType>
): UseLLMReturnType<
    UnionTest_ReturnType,
    [
        input: string | boolean
    ],
    NonStreamingInputProps<UnionTest_ReturnType>
>;

export function useUnionTest_Function(
    options: UseLLMOptions<UnionTest_ReturnType> = {}
): UseLLMReturnType<
    UnionTest_ReturnType,
    [
        input: string | boolean
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<UnionTest_ReturnType, [
        input: string | boolean
      ]>(ServerActions.UnionTest_FunctionAction, options);
    }

    return useLLM<UnionTest_ReturnType, [
        input: string | boolean
    ]>(ServerActions.UnionTest_FunctionAction, options);
}

/**
 * A specialized hook for the UseBlockConstraint BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - inp: BlockConstraintForParam
 *
 *
 * Return Type:
 * - Non-streaming: number
 * - Streaming Partial: RecursivePartialNull<number>
 * - Streaming Final: number
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useUseBlockConstraint();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to number
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: number | null
 *   partialData, // Type: RecursivePartialNull<number> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useUseBlockConstraint({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<number>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<number>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       inp: someValue as BlockConstraintForParam,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       inp: firstValue as BlockConstraintForParam,
 *     }),
 *     mutate({
 *       inp: secondValue as BlockConstraintForParam,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useUseBlockConstraint(
    options?: StreamingInputProps<number>
): UseLLMReturnType<
    number,
    [
        inp: BlockConstraintForParam
    ],
    StreamingInputProps<number>
>;

export function useUseBlockConstraint(
    options?: NonStreamingInputProps<number>
): UseLLMReturnType<
    number,
    [
        inp: BlockConstraintForParam
    ],
    NonStreamingInputProps<number>
>;

export function useUseBlockConstraint(
    options: UseLLMOptions<number> = {}
): UseLLMReturnType<
    number,
    [
        inp: BlockConstraintForParam
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<number, [
        inp: BlockConstraintForParam
      ]>(ServerActions.UseBlockConstraintAction, options);
    }

    return useLLM<number, [
        inp: BlockConstraintForParam
    ]>(ServerActions.UseBlockConstraintAction, options);
}

/**
 * A specialized hook for the UseMalformedConstraints BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - a: MalformedConstraints2
 *
 *
 * Return Type:
 * - Non-streaming: number
 * - Streaming Partial: RecursivePartialNull<number>
 * - Streaming Final: number
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useUseMalformedConstraints();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to number
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: number | null
 *   partialData, // Type: RecursivePartialNull<number> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useUseMalformedConstraints({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<number>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<number>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       a: someValue as MalformedConstraints2,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       a: firstValue as MalformedConstraints2,
 *     }),
 *     mutate({
 *       a: secondValue as MalformedConstraints2,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useUseMalformedConstraints(
    options?: StreamingInputProps<number>
): UseLLMReturnType<
    number,
    [
        a: MalformedConstraints2
    ],
    StreamingInputProps<number>
>;

export function useUseMalformedConstraints(
    options?: NonStreamingInputProps<number>
): UseLLMReturnType<
    number,
    [
        a: MalformedConstraints2
    ],
    NonStreamingInputProps<number>
>;

export function useUseMalformedConstraints(
    options: UseLLMOptions<number> = {}
): UseLLMReturnType<
    number,
    [
        a: MalformedConstraints2
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<number, [
        a: MalformedConstraints2
      ]>(ServerActions.UseMalformedConstraintsAction, options);
    }

    return useLLM<number, [
        a: MalformedConstraints2
    ]>(ServerActions.UseMalformedConstraintsAction, options);
}

/**
 * A specialized hook for the UseNestedBlockConstraint BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 *
 * - inp: NestedBlockConstraintForParam
 *
 *
 * Return Type:
 * - Non-streaming: number
 * - Streaming Partial: RecursivePartialNull<number>
 * - Streaming Final: number
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = useUseNestedBlockConstraint();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to number
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: number | null
 *   partialData, // Type: RecursivePartialNull<number> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = useUseNestedBlockConstraint({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (response) => {
 *     // Type: RecursivePartialNull<number>
 *     console.log('Partial:', response.partial);
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (response) => {
 *     // Type: FinalResponse<number>
 *     console.log('Final:', response.final);
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
 *       inp: someValue as NestedBlockConstraintForParam,  // Replace someValue with your data
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
 *       inp: firstValue as NestedBlockConstraintForParam,
 *     }),
 *     mutate({
 *       inp: secondValue as NestedBlockConstraintForParam,
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
 export function useUseNestedBlockConstraint(
    options?: StreamingInputProps<number>
): UseLLMReturnType<
    number,
    [
        inp: NestedBlockConstraintForParam
    ],
    StreamingInputProps<number>
>;

export function useUseNestedBlockConstraint(
    options?: NonStreamingInputProps<number>
): UseLLMReturnType<
    number,
    [
        inp: NestedBlockConstraintForParam
    ],
    NonStreamingInputProps<number>
>;

export function useUseNestedBlockConstraint(
    options: UseLLMOptions<number> = {}
): UseLLMReturnType<
    number,
    [
        inp: NestedBlockConstraintForParam
    ],
    typeof options
> {
   // NOTE: This is a hack to get the type inference to work.
    if (isStreamingOptions(options)) {
      return useLLM<number, [
        inp: NestedBlockConstraintForParam
      ]>(ServerActions.UseNestedBlockConstraintAction, options);
    }

    return useLLM<number, [
        inp: NestedBlockConstraintForParam
    ]>(ServerActions.UseNestedBlockConstraintAction, options);
}
