---
title: Tools / Function Calling
---


"Function calling" is a technique for getting an LLM to choose a function to call for you.

The way it works is:
1. You define a task with certain function(s)
2. Ask the LLM to **choose which function to call**
3. **Get the function parameters from the LLM** for the appropriate function it choose
4. **Call the functions** in your code with those parameters

It's common for people to think of "function calling" or "tool use" separately from "structured outputs" (even OpenAI has separate parameters for them), but at BAML, we think it's simpler and more impactful to think of them equivalently. This is because, at the end of the day, you are looking to get something processable back from your LLM. Whether it's extracting data from a document or calling the Weather API, you need a standard representation of that output, which is where BAML lives.

<control flow image>

In BAML, you can get represent a `tool` or a `function` you want to call as a BAML `class`, and make the function output be that class definition.

```baml BAML
class WeatherAPI {
  city string @description("the user's city")
  timeOfDay string @description("As an ISO8601 timestamp")
}

function UseTool(user_message: string) -> WeatherAPI {
  client GPT4Turbo
  prompt #"
    Extract the info from this message
    ---
    {{ user_message }}
    ---

    {# special macro to print the output schema. #}
    {{ ctx.output_format }}

    JSON:
  "#
}
```
Call the function like this:

<CodeGroup>
```python Python
import asyncio
import datetime
from baml_client import b
from baml_client.types import WeatherAPI

def get_weather(city: str, time_of_day: datetime.date):
    ...

def main():
    weather_info = b.UseTool("What's the weather like in San Francisco?")
    print(weather_info)
    assert isinstance(weather_info, WeatherAPI)
    print(f"City: {weather_info.city}")
    print(f"Time of Day: {weather_info.time_of_day}")
    weather = get_weather(city=weather_info.city, time_of_day=weather_info.timeOfDay)

if __name__ == '__main__':
    main()
```

```typescript TypeScript
import { b } from './baml_client'
import { WeatherAPI } from './baml_client/types'
import assert from 'assert'

const main = async () => {
  const weatherInfo = await b.UseTool("What's the weather like in San Francisco?")
  console.log(weatherInfo)
  assert(weatherInfo instanceof WeatherAPI)
  console.log(`City: ${weatherInfo.city}`)
  console.log(`Time of Day: ${weatherInfo.timeOfDay}`)
}
```

```ruby Ruby
require_relative "baml_client/client"

$b = Baml.Client

def main
  weather_info = $b.UseTool(user_message: "What's the weather like in San Francisco?")
  puts weather_info
  raise unless weather_info.is_a?(Baml::Types::WeatherAPI)
  puts "City: #{weather_info.city}"
  puts "Time of Day: #{weather_info.timeOfDay}"
end
```
</CodeGroup>

## Choosing multiple Tools

To choose ONE tool out of many, you can use a union:
```baml BAML
function UseTool(user_message: string) -> WeatherAPI | MyOtherAPI {
  .... // same thing
}
```

<Tip>If you use [VSCode Playground](/guides/installation-editors/vs-code-extension), you can see what we inject into the prompt, with full transparency.</Tip>

Call the function like this:

<CodeGroup>
```python Python
import asyncio
from baml_client import b
from baml_client.types import WeatherAPI, MyOtherAPI

async def main():
    tool = b.UseTool("What's the weather like in San Francisco?")
    print(tool)
    
    if isinstance(tool, WeatherAPI):
        print(f"Weather API called:")
        print(f"City: {tool.city}")
        print(f"Time of Day: {tool.timeOfDay}")
    elif isinstance(tool, MyOtherAPI):
        print(f"MyOtherAPI called:")
        # Handle MyOtherAPI specific attributes here

if __name__ == '__main__':
    main()
```

```typescript TypeScript
import { b } from './baml_client'
import { WeatherAPI, MyOtherAPI } from './baml_client/types'

const main = async () => {
  const tool = await b.UseTool("What's the weather like in San Francisco?")
  console.log(tool)
  
  if (tool instanceof WeatherAPI) {
    console.log("Weather API called:")
    console.log(`City: ${tool.city}`)
    console.log(`Time of Day: ${tool.timeOfDay}`)
  } else if (tool instanceof MyOtherAPI) {
    console.log("MyOtherAPI called:")
    // Handle MyOtherAPI specific attributes here
  }
}

main()
```

```ruby Ruby
require_relative "baml_client/client"

$b = Baml.Client

def main
  tool = $b.UseTool(user_message: "What's the weather like in San Francisco?")
  puts tool
  
  case tool
  when Baml::Types::WeatherAPI
    puts "Weather API called:"
    puts "City: #{tool.city}"
    puts "Time of Day: #{tool.timeOfDay}"
  when Baml::Types::MyOtherAPI
    puts "MyOtherAPI called:"
    # Handle MyOtherAPI specific attributes here
  end
end

main
```
</CodeGroup>

## Choosing N Tools
To choose many tools, you can use a union of a list:
```baml BAML
function UseTool(user_message: string) -> (WeatherAPI | MyOtherAPI)[] {
  .... // same thing
}
```

Call the function like this:

<CodeGroup>
```python Python
import asyncio
from baml_client import b
from baml_client.types import WeatherAPI, MyOtherAPI

async def main():
    tools = b.UseTool("What's the weather like in San Francisco and New York?")
    print(tools)  
    
    for tool in tools:
        if isinstance(tool, WeatherAPI):
            print(f"Weather API called:")
            print(f"City: {tool.city}")
            print(f"Time of Day: {tool.timeOfDay}")
        elif isinstance(tool, MyOtherAPI):
            print(f"MyOtherAPI called:")
            # Handle MyOtherAPI specific attributes here

if __name__ == '__main__':
    main()
```

```typescript TypeScript
import { b } from './baml_client'
import { WeatherAPI, MyOtherAPI } from './baml_client/types'

const main = async () => {
  const tools = await b.UseTool("What's the weather like in San Francisco and New York?")
  console.log(tools)
  
  tools.forEach(tool => {
    if (tool instanceof WeatherAPI) {
      console.log("Weather API called:")
      console.log(`City: ${tool.city}`)
      console.log(`Time of Day: ${tool.timeOfDay}`)
    } else if (tool instanceof MyOtherAPI) {
      console.log("MyOtherAPI called:")
      // Handle MyOtherAPI specific attributes here
    }
  })
}

main()
```

```ruby Ruby
require_relative "baml_client/client"

$b = Baml.Client

def main
  tools = $b.UseTool(user_message: "What's the weather like in San Francisco and New York?")
  puts tools
  
  tools.each do |tool|
    case tool
    when Baml::Types::WeatherAPI
      puts "Weather API called:"
      puts "City: #{tool.city}"
      puts "Time of Day: #{tool.timeOfDay}"
    when Baml::Types::MyOtherAPI
      puts "MyOtherAPI called:"
      # Handle MyOtherAPI specific attributes here
    end
  end
end

main
```
</CodeGroup>


## Dynamically Generate the tool signature
It might be cumbersome to define schemas in baml and code, so you can define them from code as well. Read more about dynamic types [here](https://docs.boundaryml.com/guide/baml-advanced/dynamic-runtime-types)
```baml BAML
class WeatherAPI {
  @@dynamic // params defined from code
}

function UseTool(user_message: string) -> WeatherAPI {
  .... // same thing
}
```

Call the function like this:

<CodeGroup>
```python Python
import asyncio
import inspect

from baml_client import b
from baml_client.type_builder import TypeBuilder
from baml_client.types import WeatherAPI

async def get_weather(city: str, time_of_day: str):
    print(f"Getting weather for {city} at {time_of_day}")
    return 42

async def main():
    tb = TypeBuilder()
    type_map = {int: tb.int(), float: tb.float(), str: tb.string()}
    signature = inspect.signature(get_weather)
    for param_name, param in signature.parameters.items():
        tb.WeatherAPI.add_property(param_name, type_map[param.annotation])
    tool = b.UseTool("What's the weather like in San Francisco this afternoon?", { "tb": tb })
    print(tool)
    weather = await get_weather(**tool.model_dump())
    print(weather)

if __name__ == '__main__':
    asyncio.run(main())
```

```typescript TypeScript
...
```

```ruby Ruby
...
```
</CodeGroup>

## Function-calling APIs vs Prompting
Injecting your function schemas into the prompt, as BAML does, outperforms function-calling across all benchmarks for major providers ([see our Berkeley FC Benchmark results with BAML](https://www.boundaryml.com/blog/sota-function-calling?q=0)).

Amongst other limitations, function-calling APIs will at times:
1. Return a schema when you don't want any (you want an error)
2. Not work for tools with more than 100 parameters.
3. Use [many more tokens than prompting](https://www.boundaryml.com/blog/type-definition-prompting-baml).

Keep in mind that "JSON mode" is nearly the same thing as "prompting", but it enforces the LLM response is ONLY a JSON blob.
BAML does not use JSON mode since it allows developers to use better prompting techniques like chain-of-thought, to allow the LLM to express its reasoning before printing out the actual schema. BAML's parser can find the json schema(s) out of free-form text for you. Read more about different approaches to structured generation [here](https://www.boundaryml.com/blog/schema-aligned-parsing)

BAML will still support native function-calling APIs in the future (please let us know more about your use-case so we can prioritize accordingly)
