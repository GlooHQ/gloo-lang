---
title: aws-bedrock
subtitle: AWS Bedrock provider for BAML
---


The `aws-bedrock` provider supports all text-output models available via the
[`Converse` API](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html).

Example:

```baml BAML
client<llm> MyClient {
  provider aws-bedrock
  options {
    inference_configuration {
      max_tokens 100
    }
    // model_id "mistral.mistral-7b-instruct-v0:2"
    // model "anthropic.claude-3-5-sonnet-20240620-v1:0"
    // model_id "anthropic.claude-3-haiku-20240307-v1:0"
    model "meta.llama3-8b-instruct-v1:0"
  }
}
```

## Authorization

We use the AWS SDK under the hood, which will respect [all authentication
mechanisms supported by the
SDK](https://docs.rs/aws-config/latest/aws_config/index.html), including but not
limited to:

  - loading the specified `AWS_PROFILE` from `~/.aws/config`
  - built-in authn for services running in EC2, ECS, Lambda, etc.
  - You can also specify the access key ID, secret access key, and region directly (see below)


## Playground setup
Add these three environment variables to your extension variables to use the AWS Bedrock provider in the playground.

- `AWS_ACCESS_KEY_ID`
- `AWS_SECRET_ACCESS_KEY`
- `AWS_REGION` - like `us-east-1`
<img src="/assets/vscode/bedrock-playground.png" width="400px" />

## Non-forwarded options

<ParamField
  path="default_role"
  type="string"
>
  The default role for any prompts that don't specify a role. **Default: `system`**

  We don't have any checks for this field, you can pass any string you wish.
</ParamField>

<Markdown src="/snippets/role-selection.mdx" />

<Markdown src="/snippets/allowed-role-metadata-basic.mdx" />
<Markdown src="/snippets/supports-streaming.mdx" />

<ParamField
  path="region"
  type="string"
>
  The AWS region to use. **Default: `AWS_REGION` environment variable**

  We don't have any checks for this field, you can pass any string you wish.
</ParamField>

<ParamField
  path="access_key_id"
  type="string"
>
  The AWS access key ID to use. **Default: `AWS_ACCESS_KEY_ID` environment variable**
</ParamField>

<ParamField
  path="secret_access_key"
  type="string"
>
  The AWS secret access key to use. **Default: `AWS_SECRET_ACCESS_KEY` environment variable**
</ParamField>


## Forwarded options

<ParamField
   path="messages"
   type="DO NOT USE"
>
  BAML will auto construct this field for you from the prompt
</ParamField>

<ParamField
  path="model (or model_id)"
  type="string"
>
  The model to use.

| Model           | Description                    |
| --------------- | ------------------------------ |
| `anthropic.claude-3-5-sonnet-20240620-v1:0` | Smartest              |
| `anthropic.claude-3-haiku-20240307-v1:0`  | Fastest + Cheapest    |
| `meta.llama3-8b-instruct-v1:0`            |                       |
| `meta.llama3-70b-instruct-v1:0`           |                       |
| `mistral.mistral-7b-instruct-v0:2`        |                       |
| `mistral.mixtral-8x7b-instruct-v0:1`      |                       |

Run `aws bedrock list-foundation-models | jq '.modelSummaries.[].modelId` to get
a list of available foundation models; you can also use any custom models you've
deployed.

Note that to use any of these models you'll need to [request model access].

[request model access]: https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html

</ParamField>

<ParamField path="inference_configuration" type="object">
Additional inference configuration to send with the request; see [AWS Bedrock
documentation](https://docs.rs/aws-sdk-bedrockruntime/latest/aws_sdk_bedrockruntime/types/struct.InferenceConfiguration.html).

Example:

```baml BAML
client<llm> MyClient {
  provider aws-bedrock
  options {
    inference_configuration {
      max_tokens 1000
      temperature 1.0
      top_p 0.8
    }
  }
}
```

</ParamField>
