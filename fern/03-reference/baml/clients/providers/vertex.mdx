---
title: vertex-ai
---

The `vertex-ai` provider is used to interact with the Google Vertex AI services.

<Warning>
  `vertex-ai` support for Anthropic models is coming soon.
</Warning>


Example: 
```baml BAML
client<llm> MyClient {
  provider vertex-ai
  options {
    model gemini-1.5-pro
    location us-central1
  }
}
```

## Authorization

The `vertex-ai` provider integrates with Google Cloud [application default
credentials](https://cloud.google.com/docs/authentication/application-default-credentials)
and by default will try to authenticate using the following:

- if `GOOGLE_APPLICATION_CREDENTIALS` is set, it will use the credentials in that file
- if you have run `gcloud auth application-default login`, it will use those credentials
- if running in GCP, it will query the metadata server to use the attached service account
- if `gcloud` is available on the `PATH`, it will use `gcloud auth print-access-token`

Setting [`options.credentials`](#credentials) will take precedence and force `vertex-ai` to load
service account credentials from that file path.

Setting [`options.credentials_content`](#credentials_content) will also take precedence and force
`vertex-ai` to load service account credentials from that string.

<Accordion title='Using a `vertex-ai` client in the playground'>
To use a `vertex-ai` client in the playground, you'll need to create
`GOOGLE_APPLICATION_CREDENTIALS` 
</Accordion>

Setting `options.credentials` or `options.credentials_content` will take
precedence over the `GOOGLE_APPLICATION_CREDENTIALS` environment variable.

### Implementation

The `vertex-ai` provider uses one of 3 strategies to authenticate with Google Cloud:

- `Credentials::JsonString` - parse the provided string as a JSON object, and use that to resolve a service account
- `Credentials::JsonFile` - parse the provided file as a JSON object, and use that to resolve a service account
- `Credentials::SystemDefault` - try 3 strategies in order:
    - resolve credentials from `.config/gcloud/application_default_credentials.json`; else
    - use the service account from the GCP compute environment by querying the metadata server; else
    - check if `gcloud` is available on the `PATH` and if so, use `gcloud auth print-access-token`

We choose one of the three strategies based on the following rules, in order:

- if `credentials` is provided, and it looks like a JSON object, we use `Credentials::JsonString` with `credentials`
  - we use `Credentials::JsonFile` with `credentials`
- if `credentials_content` is provided, we use `Credentials::JsonString` with `credentials_content`
- if neither is provided and `GOOGLE_APPLICATION_CREDENTIALS` is set and looks like a JSON object,
  we use `Credentials::JsonString` with `GOOGLE_APPLICATION_CREDENTIALS`
- if neither is provided and `GOOGLE_APPLICATION_CREDENTIALS` is set and does not look like a JSON object,
  we use `Credentials::JsonFile` with `GOOGLE_APPLICATION_CREDENTIALS`
- if neither is provided and `GOOGLE_APPLICATION_CREDENTIALS_CONTENT` is set,
  we use `Credentials::JsonString` with `GOOGLE_APPLICATION_CREDENTIALS_CONTENT`
- if neither is provided, and neither `GOOGLE_APPLICATION_CREDENTIALS_CONTENT` nor `GOOGLE_APPLICATION_CREDENTIALS` are set,
  we use `Credentials::SystemDefault`


```
https://${LOCATION}-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent
https://${LOCATION}-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:streamGenerateContent
```

## Authz (old)

The `vertex-ai` provider uses the Google Cloud SDK to authenticate with a temporary access token. We generate these Google Cloud Authentication Tokens using Google Cloud service account credentials. We do not store this token, and it is only used for the duration of the request.

### Instructions for downloading Google Cloud credentials
1. Go to the [Google Cloud Console](https://console.cloud.google.com/).
2. Click on the project you want to use.
3. Select the `IAM & Admin` section, and click on `Service Accounts`.
5. Select an existing service account or create a new one.
6. Click on the service account and select `Add Key`.
7. Choose the JSON key type and click `Create`.
9. Set the `GOOGLE_APPLICATION_CREDENTIALS` environment variable to the path of the file.


See the [Google Cloud Application Default Credentials Docs](https://cloud.google.com/docs/authentication/application-default-credentials) for more information.

## BAML-specific request `options`
These unique parameters (aka `options`) modify the API request sent to the provider.

You can use this to modify the `headers` and `base_url` for example.

<ParamField path="base_url" type="string">
  The base URL for the API.
  
  **Default: `https://{LOCATION}-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/{LOCATION}/publishers/google/models/
`**

  Can be used in lieu of the **`project_id`** and **`location`** fields, to manually set the request URL.
</ParamField>


<ParamField
  path="project_id"
  type="string"
  required
>
  Vertex requires a Google Cloud project ID for each request. See the [Google Cloud Project ID Docs](https://cloud.google.com/resource-manager/docs/creating-managing-projects#identifying_projects) for more information.

    

</ParamField>

{/*The anchor is placed above "location" and not "credentials" because this will ensure that "credentials" is
visible on-screen when the user navigates to #credentials, due to how Fern renders its HTML layout.*/}

<a name="credentials"></a>

<ParamField
  path="location"
  type="string"
  required
>
  Vertex requires a location for each request. Some locations may have different models avaiable.
  
  Common locations include:
  - `us-central1`
  - `us-west1`
  - `us-east1`
  - `us-south1`

  See the [Vertex Location Docs](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/locations#united-states) for all locations and supported models.

</ParamField>

{/*The anchor is placed above "credentials" and not "credentials_content" because this will ensure that "credentials_content" is
visible on-screen when the user navigates to #credentials_content, due to how Fern renders its HTML layout.*/}

<a name="credentials_content"></a>

<ParamField
  path="credentials"
  type="string | object"
>
  Path to a file containing service account credentials in JSON format.

  **Default: `env.GOOGLE_APPLICATION_CREDENTIALS`**

  <Accordion title='Example: file path'>
  In this case, the path is resolved relative to the CWD of your process.

  ```baml BAML
  client<llm> Vertex {
    provider vertex-ai
    options {
      model gemini-1.5-pro
      location us-central1
      credentials "path/to/credentials.json"
    }
  }
  ```
  </Accordion>
</ParamField>

<ParamField
  path="credentials_content"
  type="string"
>
  A string containing service account credentials in JSON format.

  **Default: `env.GOOGLE_APPLICATION_CREDENTIALS_CONTENT`**

  
  <Accordion title='Example'>
    ```baml BAML
    client<llm> Vertex {
      provider vertex-ai
      options {
        model gemini-1.5-pro
        location us-central1
        // credentials_content is a block string containing service account credentials in JSON format
        credentials_content #"
          {
            "type": "service_account",
            "project_id": "my-project-id",
            "private_key_id": "string",
            "private_key": "-----BEGIN PRIVATE KEY-----string\n-----END PRIVATE KEY-----\n",
            "client_email": "john_doe@gmail.com",
            "client_id": "123456",
            "auth_uri": "https://accounts.google.com/o/oauth2/auth",
            "token_uri": "https://oauth2.googleapis.com/token",
            "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
            "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/...",
            "universe_domain": "googleapis.com"
          }
        "#
      }
    }

    ```
  </Accordion>

  <Warning>
    We do not recommend using `credentials_content` in production; it is only
    intended for use in the BAML playground.
  </Warning>
</ParamField>


<ParamField
  path="model"
  type="string"
  required
>
  The Google model to use for the request.
  

| Model | Input(s) | Optimized for |
| --- | ---  | --- |
| `gemini-1.5-pro`  | Audio, images, videos, and text | Complex reasoning tasks such as code and text generation, text editing, problem solving, data extraction and generation |
| `gemini-1.5-flash`  | Audio, images, videos, and text | Fast and versatile performance across a diverse variety of tasks |
| `gemini-1.0-pro` | Text | Natural language tasks, multi-turn text and code chat, and code generation |

See the [Google Model Docs](https://ai.google.dev/gemini-api/docs/models/gemini) for the latest models.
</ParamField>

<ParamField path="headers" type="object">
  Additional headers to send with the request.

Example:
```baml BAML
client<llm> MyClient {
  provider vertex-ai
  options {
    model gemini-1.5-pro
    project_id my-project-id
    location us-central1
    // Additional headers
    headers {
      "X-My-Header" "my-value"
    }
  }
}
```
</ParamField>

<Markdown src="/snippets/role-selection.mdx" />

<Markdown src="/snippets/allowed-role-metadata-basic.mdx" />

<Markdown src="/snippets/supports-streaming.mdx" />

<Markdown src="/snippets/finish-reason.mdx" />

## Provider request parameters
These are other parameters that are passed through to the provider, without modification by BAML. For example if the request has a `temperature` field, you can define it in the client here so every call has that set.

Consult the specific provider's documentation for more information.
<ParamField
  path="safetySettings"
  type="object"
>
  Safety settings to apply to the request. You can stack different safety settings with a new `safetySettings` header for each one. See the [Google Vertex API Request Docs](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference) for more information on what safety settings can be set.

```baml BAML
client<llm> MyClient {
  provider vertex-ai
  options {
    model gemini-1.5-pro
    project_id my-project-id
    location us-central1

    safetySettings {
      category HARM_CATEGORY_HATE_SPEECH
      threshold BLOCK_LOW_AND_ABOVE
      method SEVERITY
    }
  }
}
```
</ParamField>

<ParamField
  path="generationConfig"
  type="object"
>
  Generation configurations to apply to the request. See the [Google Vertex API Request Docs](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference) for more information on what properties can be set.
```baml BAML
client<llm> MyClient {
  provider vertex-ai
  options {
    model gemini-1.5-pro
    project_id my-project-id
    location us-central1
    
    generationConfig {
      maxOutputTokens 100
      temperature 1
    }
  }
}
```
   
</ParamField>

For all other options, see the [official Vertex AI documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal).

## Publishers Other Than Google

If you are using models from publishers other than Google, such as Llama from
Meta, use your project endpoint as the `base_url` in BAML:

```baml
client<llm> VertexLlama {
  provider vertex-ai
  options {  
    base_url "https://${LOCATION}-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/${LOCATION}/endpoints/"
    location us-central1
  }
}
```

