'use client'

import { useCallback, useMemo, useReducer } from 'react';
import type { BamlStream } from '@boundaryml/baml';
import {
{%- for func in funcs %}
  {{ func.name }}Action,
{%- endfor %}
} from './server';

/**
 * A React hook for making BAML function calls with support for both streaming and non-streaming modes.
 * This hook handles all the complexity of managing state, streaming responses, and error handling.
 *
 * @template TPartial The type of incremental/streaming responses before completion
 * @template TFinal The type of the final, complete response
 * @template TParams The expected parameters for the BAML function
 *
 * @param serverAction The BAML server function to execute
 * @param options Configuration for streaming, callbacks, and error handling
 *
 * @returns A state object for managing the async operation lifecycle
 *
 * @example
 * ```tsx
 * // Non-streaming: Wait for complete response
 * const {
 *   data,           // The complete, final response when ready
 *   isLoading,      // True while waiting for the response
 *   isSuccess,      // True if the operation completed successfully
 *   error,          // Error object if something went wrong
 *   mutate         // Call this to start the operation
 * } = useLLM(extractResume, {
 *   onFinal: (data) => console.log('Processing complete:', data),
 * });
 *
 * // Streaming: Get incremental updates
 * const {
 *   data,           // The complete response once finished
 *   partialData,    // Incremental response chunks as they arrive
 *   isLoading,      // True while the stream is still open
 *   isSuccess,      // True after stream closes successfully
 *   error,          // Error if stream fails or operation errors
 *   mutate         // Call this to start streaming
 * } = useLLM(extractResume, {
 *   stream: true,
 *   onPartial: (chunk) => console.log('Got partial response:', chunk),
 *   onFinal: (data) => console.log('Stream complete:', data),
 * });
 *
 * // Start processing
 * await mutate({
 *   text: "Resume content to analyze",
 *   options: { ... }
 * });
 * ```
 */

/**
 * Base options for configuring the BAML function call.
 * @template TFinal The type of the complete, final response
 */
export interface useLLMBaseOptions<TFinal> {
  /**
   * Called when processing completes successfully.
   * Use this to handle the final result, e.g. updating UI or triggering next steps.
   */
  onFinal?: (data: TFinal) => void;
  /**
   * Called if the operation fails.
   * Use this to handle errors gracefully, e.g. showing error messages or retrying.
   */
  onError?: (error: Error) => void;
}

/**
 * Configuration for streaming mode, which provides incremental updates.
 * Use this when you want to show partial results as they become available.
 *
 * @template TPartial Type of the incremental response chunks
 * @template TFinal Type of the complete, final response
 */
export interface useLLMStreamingOptions<TPartial, TFinal>
  extends useLLMBaseOptions<TFinal> {
  /**
   * Called each time a new chunk of data arrives.
   * Use this to progressively update UI, e.g. showing typing animations
   * or incrementally displaying content.
   */
  onPartial?: (data: TPartial) => void;
  /**
   * Set to true to enable streaming mode.
   * This allows handling partial results before completion.
   */
  stream: true;
}

/**
 * Options interface for non-streaming mode of the useLLM hook.
 * @template TFinal The type of the final response data
 */
export interface useLLMNonStreamingOptions<TFinal>
  extends useLLMBaseOptions<TFinal> {
  /** Must be false or undefined for non-streaming mode */
  stream?: false;
}

/**
 * Union type of all possible options for the useLLM hook.
 * @template TPartial The type of partial/intermediate response data
 * @template TFinal The type of the final response data
 */
export type useLLMOptions<TPartial, TFinal> =
  | useLLMStreamingOptions<TPartial, TFinal>
  | useLLMNonStreamingOptions<TFinal>;

/**
 * Type definition for a streaming server action.
 * @template TPartial The type of partial/intermediate response data
 * @template TFinal The type of the final response data
 * @template TParams Tuple type of function parameters
 */
export type StreamingServerAction<
  TPartial,
  TFinal,
  TParams extends unknown[],
> = (...args: TParams) => Promise<{
  object: ReadableStream<{ partial: TPartial } | { final: TFinal }>;
}>;

/**
 * Type definition for a non-streaming server action.
 * @template TFinal The type of the final response data
 * @template TParams Tuple type of function parameters
 */
export type NonStreamingServerAction<TFinal, TParams extends unknown[]> = (
  ...args: TParams
) => Promise<TFinal>;

/**
 * The complete state and controls for a BAML operation.
 * Contains everything needed to track progress and handle results.
 */
interface BaseReturnType<TFinal, TParams extends unknown[]> {
  /**
   * The complete, final result of the operation.
   * Only available after successful completion (when isSuccess is true).
   * Null during loading or if an error occurred.
   */
  data: TFinal | null;
  /**
   * Error details if the operation failed.
   * Check this when isError is true to handle the failure.
   */
  error: Error | null;
  /**
   * True if the operation failed.
   * Use this to conditionally render error states or retry options.
   */
  isError: boolean;
  /**
   * True while the operation is in progress.
   * Use this to show loading states, spinners, or disable controls.
   */
  isLoading: boolean;
  /**
   * True if the operation completed successfully.
   * Check this before accessing the final data.
   */
  isSuccess: boolean;
  /**
   * The current phase of the operation:
   * - idle: Initial state, ready to start
   * - loading: Operation in progress
   * - success: Completed successfully
   * - error: Failed with an error
   */
  status: "idle" | "loading" | "success" | "error";
  /**
   * Call this function to start the operation.
   * Returns a promise that resolves with the final result or null if it failed.
   */
  mutate: (...args: TParams) => Promise<TFinal | null>;
}

/**
 * Additional state available in streaming mode.
 * Use this to handle incremental updates during processing.
 */
export type StreamingReturnType<
  TPartial,
  TFinal,
  TParams extends unknown[],
> = BaseReturnType<TFinal, TParams> & {
  /**
   * The most recent partial result from the stream.
   * Updates continuously while streaming, showing interim progress.
   * Use this to implement real-time UI updates, typing effects,
   * or progress indicators.
   */
  partialData: TPartial | null;
};

/**
 * Return type for non-streaming mode, extends base return type.
 * @template TFinal The type of the final response data
 * @template TParams Tuple type of function parameters
 */
export type NonStreamingReturnType<
  TFinal,
  TParams extends unknown[],
> = BaseReturnType<TFinal, TParams> & {
  /** Not available in non-streaming mode */
  partialData: never;
};

/**
 * Conditional return type based on the options provided.
 * Returns StreamingReturnType if streaming is enabled, otherwise NonStreamingReturnType.
 */
type useLLMReturn<TPartial, TFinal, TParams extends unknown[], TOptions> =
  TOptions extends useLLMStreamingOptions<TPartial, TFinal>
    ? StreamingReturnType<TPartial, TFinal, TParams>
    : NonStreamingReturnType<TFinal, TParams>;

/**
 * State interface for the LLM reducer.
 * @template TPartial The type of partial/intermediate response data
 * @template TFinal The type of the final response data
 */
interface LLMState<TPartial, TFinal> {
  /** Whether the request is currently loading */
  isLoading: boolean;
  /** Whether the request completed successfully */
  isSuccess: boolean;
  /** Any error that occurred during the operation */
  error: Error | null;
  /** The final result of the operation */
  data: TFinal | null;
  /** The latest partial/intermediate result (only in streaming mode) */
  partialData: TPartial | null;
}

/**
 * Action types for the LLM reducer.
 * @template TPartial The type of partial/intermediate response data
 * @template TFinal The type of the final response data
 */
type LLMAction<TPartial, TFinal> =
  | { type: 'START_REQUEST' }
  | { type: 'SET_ERROR'; payload: Error }
  | { type: 'SET_PARTIAL'; payload: TPartial }
  | { type: 'SET_FINAL'; payload: TFinal }
  | { type: 'RESET' };

/**
 * Reducer function to manage LLM request state.
 * Handles state transitions for loading, success, error, and data updates.
 */
function llmReducer<TPartial, TFinal>(
  state: LLMState<TPartial, TFinal>,
  action: LLMAction<TPartial, TFinal>
): LLMState<TPartial, TFinal> {
  switch (action.type) {
    case 'START_REQUEST':
      return {
        isLoading: true,
        isSuccess: false,
        error: null,
        data: null,
        partialData: null,
      };
    case 'SET_ERROR':
      return {
        ...state,
        isLoading: false,
        error: action.payload,
      };
    case 'SET_PARTIAL':
      return {
        ...state,
        partialData: action.payload,
      };
    case 'SET_FINAL':
      return {
        ...state,
        isLoading: false,
        isSuccess: true,
        data: action.payload,
      };
    case 'RESET':
      return {
        isLoading: false,
        isSuccess: false,
        error: null,
        data: null,
        partialData: null,
      };
    default:
      return state;
  }
}

/**
 * A React hook for making BAML function calls with support for both streaming and non-streaming modes.
 * Provides a unified interface for handling loading states, errors, and data updates.
 *
 * @template TPartial The type of partial/intermediate response data
 * @template TFinal The type of the final response data
 * @template TParams Tuple type of function parameters
 *
 * @param serverAction The server action function to execute
 * @param options Configuration options for the hook
 *
 * @returns An object containing the current state of the operation and a mutate function to trigger it
 *
 * @example
 * ```tsx
 * // Non-streaming usage
 * const {
 *   data,           // The final result (TFinal | null)
 *   isLoading,      // Whether the request is in progress
 *   isSuccess,      // Whether the request completed successfully
 *   error,          // Any error that occurred
 *   mutate         // Function to trigger the request
 * } = useLLM(extractResume, {
 *   onFinal: (data) => console.log('Final:', data),
 * });
 *
 * // Streaming usage
 * const {
 *   data,           // The final result (TFinal | null)
 *   partialData,    // The latest partial result (TPartial | null)
 *   isLoading,      // Whether the request is in progress
 *   isSuccess,      // Whether the request completed successfully
 *   error,          // Any error that occurred
 *   mutate         // Function to trigger the request
 * } = useLLM(extractResume, {
 *   stream: true,
 *   onPartial: (data) => console.log('Partial:', data),
 *   onFinal: (data) => console.log('Final:', data),
 * });
 *
 * // Trigger the request
 * await mutate({ text: "Some text to process" });
 * ```
 */
export function useLLM<TPartial, TFinal, TParams extends unknown[]>(
  serverAction:
    | StreamingServerAction<TPartial, TFinal, TParams>
    | NonStreamingServerAction<TFinal, TParams>,
  options: useLLMOptions<TPartial, TFinal> = {},
): useLLMReturn<TPartial, TFinal, TParams, typeof options> {
  const { onFinal, onError } = options;
  const onPartial = (options as useLLMStreamingOptions<TPartial, TFinal>).onPartial;
  const isStreaming = options.stream === true;

  const [state, dispatch] = useReducer(llmReducer<TPartial, TFinal>, {
    isLoading: false,
    isSuccess: false,
    error: null,
    data: null,
    partialData: null,
  });

  const mutate = useCallback(
    async (...params: TParams): Promise<TFinal | null> => {
      dispatch({ type: 'START_REQUEST' });

      try {
        if (isStreaming) {
          const streamingAction = serverAction as StreamingServerAction<
            TPartial,
            TFinal,
            TParams
          >;
          const response = await streamingAction(...params);
          const stream = response.object;
          const reader = stream.getReader();
          let done = false;

          while (!done) {
            const result = await reader.read();
            done = result.done;

            if (!done && result.value) {
              const value = result.value;
              if ("partial" in value) {
                dispatch({ type: 'SET_PARTIAL', payload: value.partial });
                onPartial?.(value.partial);
              } else if ("final" in value) {
                dispatch({ type: 'SET_FINAL', payload: value.final });
                onFinal?.(value.final);
                return value.final;
              }
            }
          }
          return null;
        }

        const nonStreamingAction = serverAction as NonStreamingServerAction<
          TFinal,
          TParams
        >;
        const response = await nonStreamingAction(...params);
        dispatch({ type: 'SET_FINAL', payload: response });
        onFinal?.(response);
        return response;
      } catch (error_) {
        const error = error_ instanceof Error ? error_ : new Error(String(error_));
        dispatch({ type: 'SET_ERROR', payload: error });
        onError?.(error);
        return null;
      }
    },
    [serverAction, isStreaming, onPartial, onFinal, onError],
  );

  const status = useMemo<"idle" | "loading" | "success" | "error">(() => {
    if (state.isLoading) return "loading";
    if (state.error) return "error";
    if (state.isSuccess) return "success";
    return "idle";
  }, [state.isLoading, state.error, state.isSuccess]);

  const result = {
    data: state.data,
    error: state.error,
    isError: state.error !== null,
    isLoading: state.isLoading,
    isSuccess: state.isSuccess,
    mutate,
    status,
  } as const;

  if (isStreaming) {
    return {
      ...result,
      partialData: state.partialData,
    } as StreamingReturnType<TPartial, TFinal, TParams>;
  }

  return result as NonStreamingReturnType<TFinal, TParams>;
}

{%- for func in funcs %}
/**
 * A specialized hook for the {{ func.name }} BAML function that handles both streaming and non-streaming responses.
 *
 * Input Types:
 * {%- for (name, optional, type) in func.args %}
 * - {{ name }}{% if optional %} (optional){% endif %}: {{ type }}
 * {%- endfor %}
 *
 * Return Type:
 * - Non-streaming: {{ func.return_type }}
 * - Streaming Partial: RecursivePartialNull<{{ func.return_type }}>
 * - Streaming Final: {{ func.return_type }}
 *
 * Common Usage Patterns:
 * 1. Non-streaming (Default)
 *    - Best for: Quick responses, simple UI updates
 *    - Avoid when: Response takes >5s or UI needs progressive updates
 *
 * 2. Streaming
 *    - Best for: Long-running operations, real-time UI feedback
 *    - Required when: Using features like chat interfaces or progress indicators
 *
 * Edge Cases & Gotchas:
 * 1. Error Handling
 *    - Network failures won't trigger onPartial/onFinal
 *    - Always implement onError for graceful degradation
 *    - Check error.message for specific failure reasons
 *
 * 2. Streaming Mode
 *    - partialData may be null even after updates (handle this case!)
 *    - Stream can end without final data (connection loss)
 *    - Partial results may be incomplete/invalid
 *
 * 3. State Management
 *    - data persists after completion (clear if needed)
 *    - isLoading stays true until final/error
 *    - Multiple rapid calls can race (latest wins)
 *
 * @param props Configuration options
 * @returns Hook state and controls
 *
 * @example
 * ```tsx
 * // 1. Basic Usage (Non-streaming)
 * const { data, error, isLoading, mutate } = use{{ func.name }}();
 *
 * // Handle the response
 * useEffect(() => {
 *   if (data) {
 *     // Type-safe access to {{ func.return_type }}
 *     console.log('Success:', data);
 *   }
 * }, [data]);
 *
 * // 2. Streaming with Progress
 * const {
 *   data,        // Type: {{ func.return_type }} | null
 *   partialData, // Type: RecursivePartialNull<{{ func.return_type }}> | null
 *   isLoading,
 *   error,
 *   mutate
 * } = use{{ func.name }}({
 *   stream: true,
 *
 *   // Handle partial updates (may be incomplete!)
 *   onPartial: (partial) => {
 *     // Type: RecursivePartialNull<{{ func.return_type }}>
 *     if (partial) {
 *       // Update UI with partial result
 *     }
 *   },
 *
 *   // Handle successful completion
 *   onFinal: (final) => {
 *     // Type: {{ func.return_type }}
 *     // Update UI with complete result
 *   },
 *
 *   // Robust error handling
 *   onError: (error) => {
 *     if (error.message.includes('network')) {
 *       // Handle connection issues
 *     } else if (error.message.includes('timeout')) {
 *       // Handle timeouts
 *     } else {
 *       // Handle other errors
 *     }
 *   }
 * });
 *
 * // 3. Making the Request
 * const handleSubmit = async () => {
 *   try {
 *     const result = await mutate({
 *       // Type-safe parameters:
{%- for (name, optional, type) in func.args %}
 *       {{ name }}: someValue as {{ type }},  // Replace someValue with your data
{%- endfor %}
 *     });
 *
 *     if (result) {
 *       // Success case
 *     }
 *   } catch (e) {
 *     // Handle any synchronous errors
 *   }
 * };
 *
 * // 4. Race Condition Handling
 * const handleMultipleCalls = async () => {
 *   // Only the latest call's results will be reflected in the UI
 *   const results = await Promise.all([
 *     mutate({
{%- for (name, optional, type) in func.args %}
 *       {{ name }}: firstValue as {{ type }},
{%- endfor %}
 *     }),
 *     mutate({
{%- for (name, optional, type) in func.args %}
 *       {{ name }}: secondValue as {{ type }},
{%- endfor %}
 *     })
 *   ]);
 *   // Check results[1] for the final state
 * };
 * ```
 */
export function use{{ func.name }}(
    props?: useLLMOptions<RecursivePartialNull<{{ func.return_type }}>, {{ func.return_type }}>
): useLLMReturn<
    RecursivePartialNull<{{ func.return_type }}>,
    {{ func.return_type }},
    [params: {
        {%- for (name, optional, type) in func.args %}
        {{ name }}{% if optional %}?{% endif %}: {{ type }}{% if !loop.last %},{% endif %}
        {%- endfor %}
    }],
    typeof props
> {
    return useLLM({{ func.name }}Action, props);
}
{% endfor -%}