# BAML Runtime

> **⚠️ IMPORTANT NOTE**
>
> This document was initially generated by an AI assistant and should be taken with a grain of salt. While it provides a good starting point, some information might be inaccurate or outdated. We encourage contributors to manually update this document and remove this note once the content has been verified and corrected by the team.
>
> If you find any inaccuracies or have improvements to suggest, please feel free to submit a PR updating this guide.

The BAML Runtime is the core execution engine for BAML, providing a high-performance, type-safe interface for executing LLM functions across multiple providers.

## Features

- High-performance Rust implementation
- Multi-provider support (OpenAI, Anthropic, etc.)
- Type-safe function execution
- Streaming support
- Retry and error handling
- Async runtime with Tokio
- Cross-platform support

## Architecture

### Components

```
baml-runtime/
├── src/
│   ├── runtime/           # Core runtime implementation
│   │   ├── engine.rs      # Execution engine
│   │   ├── types.rs       # Type system
│   │   └── providers/     # LLM provider integrations
│   ├── client/            # Client interface
│   │   ├── builder.rs     # Client configuration
│   │   └── options.rs     # Runtime options
│   └── error.rs           # Error handling
├── tests/                 # Test suite
└── examples/              # Usage examples
```

### Core Concepts

1. **Runtime Engine**
   - Function execution
   - Type validation
   - Provider management

2. **Type System**
   - Runtime type checking
   - Schema validation
   - Type conversions

3. **Provider Interface**
   - Provider abstraction
   - Connection management
   - Rate limiting

## Usage

### Basic Example

```rust
use baml_runtime::{Runtime, Config};
use baml_types::Value;

#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    // Initialize runtime
    let runtime = Runtime::new(Config::default())?;

    // Execute function
    let result = runtime
        .execute_function("ExtractUserInfo", input)
        .await?;

    println!("Result: {:?}", result);
    Ok(())
}
```

### Streaming Example

```rust
use futures::StreamExt;

async fn stream_response(runtime: &Runtime, input: Value) -> Result<()> {
    let mut stream = runtime
        .stream_function("StreamingFunction", input)
        .await?;

    while let Some(chunk) = stream.next().await {
        println!("Chunk: {:?}", chunk?);
    }
    Ok(())
}
```

### Error Handling

```rust
use baml_runtime::error::{Error, ProviderError};

match runtime.execute_function("MyFunction", input).await {
    Ok(result) => println!("Success: {:?}", result),
    Err(Error::Provider(e)) => {
        println!("Provider error: {}, status: {}", e.message, e.status)
    }
    Err(Error::Validation(e)) => {
        println!("Validation error: {:?}", e.errors)
    }
    Err(e) => println!("Other error: {}", e),
}
```

## Development

### Prerequisites

- Rust toolchain (1.70+)
- Cargo
- OpenSSL development libraries
- Protobuf compiler

### Setup

```bash
# Install dependencies
cargo build

# Run tests
cargo test

# Run examples
cargo run --example basic
```

## Adding Features

### 1. New Provider

1. Create provider module:
```rust
// src/runtime/providers/new_provider.rs

use async_trait::async_trait;
use crate::provider::{Provider, ProviderResult};

pub struct NewProvider {
    client: Client,
    config: Config,
}

#[async_trait]
impl Provider for NewProvider {
    async fn execute(
        &self,
        prompt: String,
        options: Options,
    ) -> ProviderResult<String> {
        // Implementation
    }

    async fn stream(
        &self,
        prompt: String,
        options: Options,
    ) -> ProviderResult<BoxStream<String>> {
        // Implementation
    }
}
```

2. Add provider factory:
```rust
// src/runtime/provider_factory.rs

impl ProviderFactory {
    pub fn create_provider(
        &self,
        kind: ProviderKind,
        config: Config,
    ) -> Result<Box<dyn Provider>> {
        match kind {
            ProviderKind::New => Ok(Box::new(NewProvider::new(config)?)),
            // ... other providers
        }
    }
}
```

### 2. New Runtime Feature

1. Add feature interface:
```rust
// src/runtime/features.rs

pub trait RuntimeFeature: Send + Sync {
    fn name(&self) -> &str;
    fn initialize(&self, runtime: &Runtime) -> Result<()>;
    fn cleanup(&self) -> Result<()>;
}
```

2. Implement feature:
```rust
pub struct MyFeature {
    config: FeatureConfig,
}

impl RuntimeFeature for MyFeature {
    fn name(&self) -> &str {
        "my_feature"
    }

    fn initialize(&self, runtime: &Runtime) -> Result<()> {
        // Implementation
    }

    fn cleanup(&self) -> Result<()> {
        // Implementation
    }
}
```

## Testing

### Unit Tests

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_function_execution() {
        let runtime = Runtime::new(Config::default()).unwrap();
        let result = runtime
            .execute_function("TestFunction", test_input())
            .await
            .unwrap();
        assert_eq!(result.field, "expected");
    }
}
```

### Integration Tests

```rust
#[tokio::test]
async fn test_provider_integration() {
    let runtime = setup_test_runtime().await;
    let result = runtime
        .execute_with_provider(
            Provider::OpenAI,
            "test prompt",
            default_options(),
        )
        .await
        .unwrap();
    assert!(result.is_valid());
}
```

## Performance

### Concurrency

```rust
use futures::future::join_all;

async fn process_batch(
    runtime: &Runtime,
    inputs: Vec<Value>,
) -> Result<Vec<Value>> {
    let futures: Vec<_> = inputs
        .into_iter()
        .map(|input| runtime.execute_function("BatchFunction", input))
        .collect();

    let results = join_all(futures).await;
    results.into_iter().collect()
}
```

### Connection Pooling

```rust
use baml_runtime::pool::{Pool, PoolConfig};

let pool = Pool::new(PoolConfig {
    max_size: 10,
    min_idle: 2,
    max_lifetime: Duration::from_secs(3600),
});

let runtime = Runtime::with_pool(pool);
```

## Best Practices

1. **Error Handling**
   - Use custom error types
   - Provide detailed error info
   - Handle all error cases

2. **Resource Management**
   - Use connection pooling
   - Implement proper cleanup
   - Handle timeouts

3. **Testing**
   - Write unit tests
   - Add integration tests
   - Test error cases

4. **Performance**
   - Use async/await
   - Pool connections
   - Batch operations

## Contributing

1. Read [Contributing Guide](../../CONTRIBUTING.md)
2. Follow runtime guidelines
3. Add tests for new features
4. Update documentation
5. Submit PR for review
